# About Milvus #
## What is Milvus ##


#### Introduction

This page aims to give you an overview of Milvus by answering several questions. After reading this page, you will learn what Milvus is and how it works, as well as the key concepts, why use Milvus, supported indexes and metrics, example applications, the architecture, and relevant tools.

#### What is Milvus vector database?

Milvus was created in 2019 with a singular goal: store, index, and manage massive embedding vectors generated by deep neural networks and other machine learning (ML) models. 

As a database specifically designed to handle queries over input vectors, it is capable of indexing vectors on a trillion scale. Unlike existing relational databases which mainly deal with structured data following a pre-defined pattern, Milvus is designed from the bottom-up to handle embedding vectors converted from unstructure data.

As the internet grew and evolved, unstructured data became more and more common, including emails, papers, IoT sensor data, Facebook photos, protein structures, and much more. In order for computers to understand and process unstructured data, these are converted into vectors using embedding techniques. Milvus stores and indexes these vectors. Milvus is able to analyze the correlation between two vectors by calculating their similarity distance. If the two embedding vectors are very similar, it means that the original data sources are similar as well.

#### Key concepts

In case you are new to the world of vector database and similarity search, read the following explanation of key concepts to gain a better understanding. 

Learn more about [Milvus glossary](glossary.md).

#### Unstructured data

Unstructured data, including images, video, audio, and natural language, is information that doesn't follow a predefined model or manner of organization. This data type accounts for ~80% of the world's data, and can be converted into vectors using various artificial intelligence (AI) and machine learning (ML) models.

#### Embedding vectors

An embedding vector is a feature abstraction of unstructured data, such as emails, IoT sensor data, Instagram photos, protein structures, and much more. Mathematically speaking, an embedding vector is an array of floating-point numbers or binaries. Modern embedding techniques are used to convert unstructured data to embedding vectors.

#### Vector similarity search

Vector similarity search is the process of comparing a vector to a database to find vectors that are most similar to the query vector. Approximate nearest neighbor (ANN) search algorithms are used to accelerate the searching process. If the two embedding vectors are very similar, it means that the original data sources are similar as well.

#### Why Milvus?

- High performance when conducting vector search on massive datasets.
- A developer-first community that offers multi-language support and toolchain.
- Cloud scalability and high reliability even in the event of a disruption.
- Hybrid search achieved by pairing scalar filtering with vector similarity search.

#### What indexes and metrics are supported?

Indexes are an organization unit of data. You must declare the index type and similarity metric before you can search or query inserted entities. **If you do not specify an index type, Milvus will operate brute-force search by default.** 

#### Index types

Most of the vector index types supported by Milvus use approximate nearest neighbors search (ANNS), including:

- **FLAT**: FLAT is best suited for scenarios that seeks perfectly accurate and exact search results on a small, million-scale dataset.
- **IVF_FLAT**: IVF_FLAT is a quantization-based index and is best suited for scenarios that seeks an ideal balance between accuracy and query speed.
- **IVF_SQ8**: IVF_SQ8 is a quantization-based index and is best suited for scenarios that seeks a significant reduction on disk, CPU, and GPU memory consumption as these resources are very limited.
- **IVF_PQ**: IVF_PQ is a quantization-based index and is best suited for scenarios that seeks high query speed even at the cost of accuracy. 
- **HNSW**: HNSQ is a graph-based index and is best suited for scenarios that has a high demand for search efficiency.
- **ANNOY**: ANNOY is a tree based index and is best suited for scenarios that seeks a high recall rate.

See [Selecting an Index Best Suited for Your Scenario](index_selection.md) for more details.

#### Similarity metrics

In Milvus, similarity metrics are used to measure similarities among vectors. Choosing a good distance metric helps improve classification and clustering performance significantly. Depending on the input data forms, specific similarity metric is selected for optimal performance.

The metrics that are widely used for floating point embeddings include:

- **Euclidean distance (L2)**: This metric is generally used in the field of computer vision (CV).
- **Inner product (IP)**: This metric is generally used in the field of natural language processing (NLP).
The metrics that are widely used for binary embeddings include:
- **Hamming**: This metric is generally used in the field of natural language processing (NLP).
- **Jaccard**: This metric is generally used in the field of molecular similarity search.
- **Tanimoto**: This metric is generally used in the field of molecular similarity search.
- **Superstructure**: This metric is generally used to search for similar supersturcture of a molecule.
- **Substructure**: This metric is generally used  to search for similar substructure of a molecule.

See [Similarity Metrics](metric.md#floating) for more information.

#### Example applications 

Milvus makes it easy to add similarity search to your applications. Example applications of Milvus include:

- [Image similarity search](image_similarity_search.md): Images made searchable and instantaneously return the most similar images from a massive database.
- [Video similarity search](video_similarity_search.md): By converting key frames into vectors and then feeding the results into Milvus, billions of videos can be searched and recommended in near real time.
- [Audio similarity search](audio_similarity_search.md): Quickly query massive volumes of audio data such as speech, music, sound effects, and surface similar sounds.
- [Molecular similarity search](molecular_similarity_search.md): Blazing fast similarity search, substructure search, or superstructure search for a specified molecule.
- [Recommender system](recommendation_system.md): Recommend information or products based on user behaviors and needs.
- [Question answering system](question_answering_system.md): Interactive digital QA chatbot that automatically answers user questions.
- [DNA sequence classification](dna_sequence_classification.md): Accurately sort out the classification of a gene in milliseconds by comparing similar DNA sequence.
- [Text search engine](text_search_engine.md): Help users find the information they are looking for by comparing keywords against a database of texts.

See [Milvus tutorials](https://github.com/milvus-io/bootcamp/tree/master/solutions) and [Milvus Adopters](milvus_adopters.md) for more Milvus application scenarios.

#### How is Milvus designed?

As a cloud-native vector database, Milvus 2.0 separates storage and computation by design. To enhance elasticity and flexibility, all components in Milvus 2.0 are stateless.

The system breaks down into four levels:

- Access layer: The access layer is composed of a group of stateless proxies and serves as the front layer of the system and endpoint to users.
- Coordinator service: The coordinator service assigns tasks to the worker nodes and functions as the system's brain.
- Worker nodes: The worker nodes function as arms and legs and are dumb executors that follow instructions from the coordinator service and execute user-triggerd DML/DDL commands.
- Storage: Storage is the bone of the system, and is responsible for data persistence. It comprises meta storage, log broker, and object storage.

For more information, see [Architecture Overview](architecture_overview.md).


![Architecture](../../../assets/architecture_02.jpg)

#### Developer tools

Milvus is supported by rich APIs and tools to facilitate DevOps.

#### API access

Milvus has client libraries wrapped on top of the Milvus API that can be used to insert, delete, and query data programmatically from application code:

- [PyMilvus](https://github.com/milvus-io/pymilvus)
- [Node.js SDK](https://github.com/milvus-io/milvus-sdk-node)
- [Go SDK](https://github.com/milvus-io/milvus-sdk-go)

We are working on enabling more new client libraries. If you would like to contribute, go to the corresponding repository of [the Milvus Project](https://github.com/milvus-io).

#### Milvus ecosystem tools

The Milvus ecosystem provides helpful tools including:

- [Milvus CLI](https://github.com/milvus-io/milvus_cli#overview)
- [Milvus Insight](https://github.com/milvus-io/milvus-insight), a graphical management system for Milvus. 
- [MilvusDM](https://milvus.io/docs/v2.0.0/migrate_overview.md) (Milvus Data Migration), an open-source tool designed specifically for importing and exporting data with Milvus.
- [Milvus sizing tool](https://zilliz.com/sizing-tool), which helps you estimate the raw file size, memory size, and stable disk size needed for a specified number of vectors with various index types.

#### What's next

- Get started with a 3-minute tutorial:
  - [Hello Milvus](example_code.md)
- Install Milvus for your testing or production environment:
  - [Installation Prerequisites](prerequisite-docker.md)
  - [Install Milvus Standalone](install_standalone-docker.md)
  - [Install Milvus Cluster](install_cluster-docker.md)
- If you're interested in diving deep into the design details of Milvus:
  - Read about [Milvus architecture](architecture_overview.md)


## What is New in Milvus 2.0 ##



We recommend that you try out Milvus 2.0. Here is why: 

#### Design concepts
As our next-generation cloud-native vector database, Milvus 2.0 is built around the following three principles:

**Cloud-native first:** We believe that only architectures supporting storage and computing separation can scale on demand and take full advantage of the cloud's elasticity. We'd also like to bring your attention to the microservice design of Milvus 2.0, which features read and write separation, incremental and historical data separation, and CPU-intensive, memory-intensive, and IO-intensive task separation. Microservices help optimize allocation of resources for the ever-changing heterogeneous workload.  

**Logs as data:** In Milvus 2.0, the log broker serves as the system's backbone: All data insert and update operations must go through the log broker, and worker nodes execute CRUD operations by subscribing to and consuming logs. This design reduces system complexity by moving core functions such as data persistence and flashback down to the storage layer, and log pub-sub make the system even more flexible and better positioned for future scaling.

**Unified batch and stream processing:** Milvus 2.0 implements the unified Lambda architecture, which integrates the processing of the incremental and historical data. Compared with the Kappa architecture, Milvus 2.0 introduces log backfill, which stores log snapshots and indexes in the object storage to improve failure recovery efficiency and query performance. To break unbounded (stream) data down into bounded windows, Milvus embraces a new watermark mechanism, which slices the stream data into multiple message packs according to write time or event time, and maintains a timeline for users to query by time.

#### Product highlights
The costs of running a database involve not only runtime resource consumption, but also the potential learning costs and the operational and maintenance costs. Practically speaking, the more user-friendly a database is, the more likely it is going to save such potential costs. From Milvus' calendar day one, ease of use is always put on the top of our list, and the latest Milvus 2.0 has quite a few to offer in the way of reducing such costs.

##### Always online
Data reliability and service sustainability are the basic requirements for a database, and our strategy is "fail cheap, fail small, and fail often".  
- "Fail cheap" refers to storage and computing separation, which makes the handling of node failure recovery straightforward and at a low cost. 
- "Fail small" refers to the "divide and conquer" strategy, which simplifies the design complexity by having each coordinator service handle only a small portion of read/write/incremental/historical data. 
- "Fail often" refers to the introduction of chaos testing, which uses fault injection in a testing environment to simulate situations such as hardware failures and dependency failures and accelerate bug discovery.

##### Hybrid search between scalar and vector data
To leverage the synergy between structured and unstructured data, Milvus 2.0 supports both scalar and vector data and enables hybrid search between them. Hybrid search helps users find the approximate nearest neighbors that match filter criteria. Currently, Milvus supports relational operations such as EQUAL, GREATER THAN, and LESS THAN, and logical operations such as NOT, AND, OR, and IN.

##### Tunable consistency
As a distributed database abiding by the PACELC theorem, Milvus 2.0 has to trade off between consistency and availability & latency. In most scenarios, overemphasizing data consistency in production can be overkill because allowing a small portion of data to be invisible has little impact on the overall recall but can significantly improve the query performance. Still, we believe that consistency levels, such as strong, bounded staleness, and session, have their own unique application. Therefore, Milvus supports tunable consistency at the request level. Taking testing as an example, users may require strong consistency to ensure test results are absolutely correct. 

##### Time travel
Data engineers often need to do data rollback to fix dirty data and code bugs. Traditional databases usually implement data rollback through snapshots or even data retrain. This could bring excessive overhead and maintenance costs. Milvus maintains a timeline for all data insert and delete operations, and users can specify a timestamp in a query to retrieve a data view at a specified point in time. With time travel, Milvus can also implement a lightweight data backup or data clone.

##### ORM Python SDK：
Object-relational mapping (ORM) allows users to focus more on the upper-level business model than on the underlying data model, making it easier for developers to manage relations between collections, fields, and programs. To close the gap between proof of concept (PoC) for AI algorithms and production deployment, we engineered the object-relational mapping PyMilvus APIs, which can work with an embedded library, a standalone deployment, a distributed cluster, or even a cloud service. With a unified set of APIs, we provide users with a consistent user experience and reduce code migration or adaptation costs.

![ORM_Python_SDK](../../../assets/python_orm.png)

##### Support tools
- [**Milvus Insight**](insight_overview.md) is Milvus' graphical user interface offering practical functionalities such as cluster state management, meta management, and data query. The source code of Milvus Insight will also be open sourced as an independent project. We are looking for more contributors to join this effort.

- [**Milvus CLI**](https://github.com/milvus-io/milvus_cli#overview) is Milvus' command-line interface based on [Milvus Python SDK](https://github.com/milvus-io/pymilvus), supporting database connection, data operations, and data export/import.

- **Out-of-box experience (OOBE), faster deployment:** Milvus 2.0 can be deployed using helm or Docker Compose.

- Milvus 2.0 uses Prometheus, an open-source time-series database, to store performance and monitor data, and Grafana, an open observability platform, for metrics visualization.

#### Milvus 2.0 vs. 1.x: Cloud-native, distributed architecture, highly scalable, and more

<table class="comparison">
<thead>
	<tr>
		<th class="width20">&nbsp;</th>
		<th class="width40">Milvus 2.0</th>
		<th class="width40">Milvus 1.x</th>
	</tr>
</thead>
	<tr>
		<th>Architecture</th>
		<td>Cloud native</td>
		<td>Shared storage</td>
	</tr>
<tbody>
	<tr>
		<th>Scalability</th>
		<td>500+ nodes</td>
		<td>1 to 32 read nodes with only one write node</td>
	</tr>
  	<tr>
		<th>Durability</th>
		<td><li>Object storage service (OSS)</li><li>Distributed file system (DFS)</li></td>
		<td><li>Local disk</li><li>Network file system (NFS)</li></td>
	</tr>
  	<tr>
		<th>Availability</th>
		<td>99.9%</td>
		<td>99%</td>		
	</tr>
	<tr>
		<th>Data consistency</th>
		<td>Three levels of consistency:<li>Strong</li><li>Bounded Staleness</li><li>Session</li><li>Consistent prefix</li></td>
		<td>Eventual consistency</td>
	</tr>
	<tr>
		<th>Data types supported</th>
		<td><li>Vectors</li><li>Fixed-length scalars</li><li>String and text (in planning)</li></td>
		<td>Vectors</td>
	</tr>
	<tr>
		<th>Basic operations supported</th>
		<td><li>Data insertion</li><li>Data deletion (in planning)</li><li>Data query</li><li>Approximate nearest neighbor (ANN) Search</li><li>Recurrent neural network (RNN) search (in planning)</li></td>
		<td><li>Data insertion</li><li>Data deletion</li><li>Approximate nearest neighbor (ANN) Search</li></td>
	</tr>
	<tr>
		<th>Advanced features</th>
		<td><li>Scalar filtering</li><li>Time Travel</li><li>Multi-site deployment and multi-cloud integration</li><li>Data management tools</li></td>
		<td><li>Mishards</li><li>Milvus DM</li></td>
	</tr>
	<tr>
		<th>Index types and libraries</th>
		<td><li>Faiss</li><li>Annoy</li><li>Hnswlib</li><li>RNSG</li><li>ScaNN (in planning)</li><li>On-disk index (in planning)</li></td>
		<td><li>Faiss</li><li>Annoy</li><li>Hnswlib</li><li>RNSG</li></td>
	</tr>
	<tr>
		<th>SDKs</th>
		<td><li>Python</li><li>Node.js</li><li>Go (in planning)</li><li>Java (in planning)</li><li>C++ (in planning)</li></td>
		<td><li>Python</li><li>Java</li><li>Go</li><li>RESTful</li><li>C++</li></td>
	</tr>
	<tr>
		<th>Release status</th>
		<td>Release candidate. A stable version will be released in August.</td>
		<td>Long-term support (LTS)</td>
	</tr>
</tbody>
</table>

## Milvus Adopters ##

Trusted by over 1,000 organizations worldwide, Milvus is used in almost all industries. The following table lists companies that have adopted Milvus in production.

| Company                                                 | Industry          | User story                                             |
| ------------------------------------------------------------ | ---------------------- | ------------------------------------------------------------ |
| [ambeRoad](https://amberoad.de/?lang=en) |  Software| |
| [Beike](https://investors.ke.com/about-us/default.aspx)                                                | Real estate           | [Making With Milvus: AI-Infused Proptech for Personalized Real Estate Search](https://milvus.io/blog/Making-With-Milvus-AI-Infused-Proptech-for-Personalized-Real-Estate-Search.md)                                              |                                             |
|[Deepset.ai](https://deepset.ai/)                                                    | Software         | [Semantic Search with Milvus, Knowledge Graph QA, Web Crawlers and more!](https://medium.com/deepset-ai/semantic-search-with-milvus-knowledge-graph-qa-web-crawlers-and-more-837451eae9fa)                                             |
| [DXY.cn](https://en.wikipedia.org/wiki/DXY.cn)                                                  | Medical           |
| [eBay](https://en.wikipedia.org/wiki/EBay) | Online retail| |
| [EnjoyMusic Technology](https://enjoymusic.ai/about)                                                 | Entertainment          |[Item-based Collaborative Filtering for Music Recommender System](https://milvus.io/blog/music-recommender-system-item-based-collaborative-filtering-milvus.md)                                          |
| [Getir](https://getir.com/) | Instant grocery | |
| [Hewlett-Packard (HP)](https://en.wikipedia.org/wiki/Hewlett-Packard)   | 	Information technology          |                                        |
| [iYUNDONG](http://yundong.ai/)                                                 | Sports        | [Extracting Event Highlights Using iYUNDONG Sports App](https://milvus.io/blog/Extracting-Events-Highlights-Using-iYUNDONG-Sports-App.md)                                          |
| [Juicedata](https://juicefs.com/aboutus)                                                | Software         |[Building a Milvus Cluster Based on JuiceFS](https://milvus.io/blog/building-a-milvus-cluster-based-on-juicefs.md)                  |
| [Kingsoft](https://en.wikipedia.org/wiki/Kingsoft)                                              | Software         | [Building an AI-Powered Writing Assistant for WPS Office](https://milvus.io/blog/Building-an-AI-Powered-Writing-Assistant-with-WPS-Office.md)                                              |
| [Line Plus](https://linecorp.com/en/company/info) |  Technology, software| |
| [Lucidworks](https://en.wikipedia.org/wiki/Lucidworks)                                                 | Software         | [Build Semantic Search at Speed](https://milvus.io/blog/build-semantic-search-at-speed-milvus-lucidworks.md)                                             |
| [Meetsocial Group](https://www.meetsocial.com/company.html)                                                  | Marketing         |                                              |
| [Miao Health](https://www.miao.cn/portal/about?l=en-us)                                                  | Health technology         |                                            |
| [Mozat](http://www.mozat.com/home)                                                | Online social| [Building a Wardrobe and Outfit Planning App with Milvus](https://milvus.io/blog/building-a-wardrobe-and-outfit-planning-app-with-milvus.md)          |                                             |
| [Opera](https://en.wikipedia.org/wiki/Opera_(company))                                                 | Software           |                                           |
| [Shopee](https://en.wikipedia.org/wiki/Shopee) |  Online retail| |
| [Smartnews](https://about.smartnews.com/en/) |  Media| |
| [Sohu](https://en.wikipedia.org/wiki/Sohu)                                                 |Internet         | [Building an Intelligent News Recommendation System Inside Sohu News App](https://milvus.io/blog/building-an-intelligent-news-recommendation-system-inside-sohu-news-app.md)                                             |
| [The Cleveland Museum of Art](https://en.wikipedia.org/wiki/Cleveland_Museum_of_Art)                                                | Arts         | [ArtLens AI: Share Your View](https://milvus.io/blog/ArtLens-AI-Share-Your-View.md)                                               |
| [Tokopedia](https://en.wikipedia.org/wiki/Tokopedia)                                               | Online retail           | [How we used semantic search to make our search 10x smarter](https://milvus.io/blog/How-we-used-semantic-search-to-make-our-search-10-x-smarter.md)                           |
| [TrendMicro](https://en.wikipedia.org/wiki/Trend_Micro)                                               | Software         | [Making with Milvus: Detecting Android Viruses in Real Time for Trend Micro](https://milvus.io/blog/Making-with-Milvus-Detecting-Android-Viruses-in-Real-Time-for-Trend-Micro.md)                                             |
| [Ufoto](http://www.ufotosoft.com/about_en.html)                                               | Software           |                                                |
| [Vipshop](https://en.wikipedia.org/wiki/Vipshop)                                                | Online retail| [Building a Personalized Product Recommender System with Vipshop and Milvus](https://milvus.io/blog/building-a-personalized-product-recommender-system-with-vipshop-and-milvus.md)    |                                               |
| [Vova](https://m.vova.com/en/about-us.html)                                               | Online retail        | [Building a Search by Image Shopping Experience with VOVA and Milvus](https://milvus.io/blog/building-a-search-by-image-shopping-experience-with-vova-and-milvus.md)                                             |
| [Walmart](https://en.wikipedia.org/wiki/Walmart) |  Retail| |
| [Xiaomi](https://en.wikipedia.org/wiki/Xiaomi)                                                 | Consumer electronics          | [Making with Milvus: AI-Powered News Recommendation Inside Xiaomi's Mobile Browser](https://milvus.io/blog/Making-with-Milvus-AI-Powered-News-Recommendation-Inside-Xiaomi-Mobile-Browser.md)                                |

## Milvus Roadmap ##


This page provides an overview of new benefits and feature upgrades we hope to provide for users in our upcoming releases, as well as our long-term goals. It is driven by user priorities and may change as their requirement or demand changes.

![Roadmap](../../../assets/new_roadmap.jpg)


#### Milvus 2.0 time schedule

#### Upcoming major releases:
- Milvus 2.1: November 2021
- Milvus 2.2: February 2022

#### Roadmap features

##### DDL
| Version | Feature | Owner   | Status  | Comment |
| ----------- | ----------- | ----------- | ----------- | ----------- | 
| 2.0.0-RC      | Supports numerical scalar data types	       |        | done       |        |
| 2.0   | Supports string data types        | czs007, dragondriver	     | in progress       |        |
| 2.0   | Collection alias        | lsgrep       | in progress       |        |
| 2.1   | Supports Scalar bitmap/inverted Index for string and numeric data types        |        | pending       |        |
| 2.1   | Supports data life cycle management        |        | pending       |        |
| 2.1   | Automatic data partition        |        | pending       |        |
| 2.2   | Collection rename        |        | pending       |        |



##### DML

| Version | Feature | Owner   | Status  | Comment |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| 2.0.RC      | Supports scalar filtering       |        | done       |        |
| 2.0.0-RC   | Supports for query by ID        |         | done        |         |
| 2.0   | Supports query by expression        | fishpenguin        | in progress        |         |
| 2.0   | Supports delete by ID        |     scsven    | in progress        |         |
| 2.1   | Supports search by ID        |         | pending        |         |
| 2.1   | Vector similarity search by distance        |         | pending        |         |
| 2.2   | Supports search/query result pagination	        |         | pending        |         |
| 2.2   | Supports upsert/primary key deduplication        |         | pending        |         |


##### Features

| Version | Feature | Owner   | Status  | Comment |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| 2.0.0-RC      | Supports time travel to any specified point in time	       |        | done       |        |
| 2.0.0-RC   | Offers three levels of tunable consistency: strong, session, consistent prefix        |         | done        |         |
| 2.0      | Segment compaction       | sunby       | in progress       |        |
| 2.0   | Implements dynamic load balancing        | sunby, xige-16        | in progress        |         |
| 2.0      | Implements dynamic handoff       | xige-16, bigsheeper       | in progress       |        |
| 2.0   | Calculate distance between embeddings        |         | done	        |         |
| 2.1      | Multi-tenant support and access control       |        | pending       |        |
| 2.2   | Change data capture        |         | pending        |         |
| Long Term      | Adopts incremental backup       |        | pending       |        |
| Long Term   | Supports static data encryption        |         | pending        |         |
| Long Term      | Offers embedding-as-service through data importer/transformer       |        | pending       |        |


##### Performance/Cost

| Version | Feature | Owner   | Status  | Comment |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| 2.0      | Milvus 2.0 performance benchmark and tuning       | czs007, dragondriver	       | in progress       |        |
| 2.1   | Supports GPU Index building and embedding retrieval        | shengjun1985        | pending        |         |
| 2.1      | Data bulkload       |        | pending       |        |
| 2.1   | Adopts cost-based query optimization algorithm to improve hybrid search efficiency        |         | pending        |         |
| 2.1      | Supports ScaNN Index       |        | pending       |        |
| 2.2   | Supports on-disk vector indexing        |         | pending        |         |
| Long Term      | Supports FPGA and other Heterogeneous hardware       |        | pending       |        |
| Long Term   | Automatic index optimization        |         | pending        |         |



##### Stability

| Version | Feature | Owner   | Status  | Comment |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| 2.0.0-RC      | Fully managed failure recovery and service discovery       |        | done       |        |
| 2.0.0-RC   | Python SDK test        |         | done        |         |
| 2.0      | Chaos test       |   yanliang567     | pending       |        |
| 2.0   | Pressure test        | del-zhenwu        | pending        |         |
| 2.1      | Supports segment in memory replicas       |        | pending       |        |
| 2.1   | Flow control && back pressure support        |         | pending        |         |
| 2.2      | 	Query node resource isolation       |        | pending       |        |



##### Ease Of Use

| Version | Feature | Owner   | Status  | Comment |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| 2.0.0-RC    | Helm installation       |        | done       |        |
| 2.0.0-RC    | Support of Milvus Insight, a Milvus visual management tool        |         | in progress        |         |
| 2.0      | Prometheus, Grafana and Jaeger support       | 	zwd1208       | in progress       |        |
| 2.0   | Milvus Kubernetes operator        | 	zwd1208, jeffoverflow        | pending        |         |
| 2.1      | Multi datacenter deployment and multi-cloud integration       |        | pending       |        |
| 2.2   | Embedded Milvus that runs on laptops	        |         | pending        |         |
| Long Term      | Dynamic cluster expansion/shrink       |        | pending      |      |



##### SDK


| Version | Feature | Owner   | Status  | Comment |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| 2.0.0-RC     | Python ORM-style APIs	       |        | done       |        |
| 2.0   | Merge PyMilvus ORM and PyMilvus        |         | done        |         |
| 2.0      | Supports NodeJs APIs       |        | done       |     |
| 2.0   | Supports Java SDK        |     xiaofan-luan    | in progress         |         |
| 2.0      | Supports Go SDK       | congqixia       | in progress       |        |
| 2.1   | Supports RESTful APIs        |         | pending        |         |
| 2.1      | Supports C++ SDK       |        | pending        |        |
| Long Term   | SQL-like query language        |         | pending        |         |


##### Integration

| Version | Feature | Owner   | Status  | Comment |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| 2.0      | Integrates S3	       |        | done       |        |
| 2.1  | Integrates Kafka       |       | pending        |         |
| 2.1    | Integrates JuiceFS       |        | pending       |    |
| 2.1  | Data stored over local/distributed filesystems      |         | pending         |         |
| 2.2     | Integrates distributed KV stores such as HBase/TiKV/FoundationDB     |        | pending      |        |

## Milvus Limits ##


Milvus is committed to providing the best vector databases to power AI applications and vector similarity search. However, the team is continuously working to bring in more features and the best utilities to enhance user experience. This page lists out some known limitations that the users may encounter when using Milvus.

#### Length of a resource name

| Resource      | Limit  |
| ----------- | ----------- |
| Collection      | 255 characters      |
| Field   | 255 characters        |
| Index   | 255 characters       |
| Partition   | 255  characters      |

#### Naming rules

The name of a resource can contain numbers, letters, dollar signs ($), and underscores (\_). A resource name must start with a letter or an underscore (_).

#### Number of resources

| Resource      | Limit |
| ----------- | ----------- |
| Collection     | 65,536       |
| Connection / proxy   | 65,536        |

#### Number of resources in a collection

| Resource     | Limit|
| ----------- | ----------- |
| Partition      | 4,096       |
| Shard   | 256        |
| Field   | 256        |
| Index   | 65,536        |
| Entity   | unlimited        |

#### Length of a string 
| Data type      | Limit  |
| ----------- | ----------- |
| VARCHAR      | 65,535 characters       |

<div class="alert note">
VARCHAR will be supported in the 2.0 stable version. More string data types will be supported.
</div>


#### Dimensions of a vector
| Property      | Limit |
| ----------- | ----------- |
| Dimension      | 32,768       |

#### Input per remote procedure call (RPC)
| Operation      | Limit |
| ----------- | ----------- |
| Insert      | 512 MB    |
| Search   | 512 MB     |
| Query   | 512 MB      |

#### Load limits
In current release, data to be load must be under 70% of the total memory resources of all query nodes to reserve memory resources for execution engine.

#### Search limits
| Vectors      | Limit |
| ----------- | ----------- |
| Output per input    | 16,384       |
| Input    | 16,384       |

<div class="alert note">
Due to Pulsar's limits on the log transmission size (100 MB), Milvus does not support 16,384 output vectors per input vector on high-dimensional vector searches in the current version. Milvus 2.0.0-GA will support it.
</div>

## Releases ##

#### Release Notes

Find out what’s new in Milvus! This page summarizes information about new features, improvements, known issues, and bug fixes in each release. You can find the release notes for each released version after v2.0.0-RC1 in this section. We suggest that you regularly visit this page to learn about updates.

#### v2.0.0-RC8

Release date: 2021-11-5

#### Compatibility

<table class="version">
	<thead>
	<tr>
		<th>Milvus version</th>
		<th>Python SDK version</th>
		<th>Java SDK version</th>
		<th>Go SDK version</th>
		<th>Node SDK version</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>2.0.0-RC8</td>
		<td>2.0.0rc8</td>
		<td>Coming soon</td>
		<td>Coming soon</td>
		<td>1.0.18</td>
	</tr>
	</tbody>
</table>



Milvus 2.0.0-RC8 is the last release candidate of Milvus 2.0.0-GA. It supports handoff task, primary key deduplication and search by Time Travel functionalities. The mean time to recovery (MTTR) has also been greatly reduced with the enhancement of timetick mechanism. We had run stress test on 2.0.0-RC8 with 10M datasets, and both standalone and distributed cluster survived for 84 hours.



#### Improvements

- Failure Recovery speed:
  - [#10737](https://github.com/milvus-io/milvus/pull/10737) Fixes Session checker for proxy.
  - [#10723](https://github.com/milvus-io/milvus/pull/10723 ) Fixes seek query channel error.
  - [#10907](https://github.com/milvus-io/milvus/pull/10907) Fixes `LatestPosition` option conflict with earliest patch.
  - [#10616](https://github.com/milvus-io/milvus/pull/10616) Removes Common YAML.
  - [#10771](https://github.com/milvus-io/milvus/pull/10771) Changes `SeekPosition` to the earliest of all segments.
  - [#10651](https://github.com/milvus-io/milvus/pull/10651) Fixes query coord set seek position error.
  - [#9543](https://github.com/milvus-io/milvus/pull/9543) Initializes global sealed segments and seek query channel when `AddQueryChannel`.
  - [#9684](https://github.com/milvus-io/milvus/pull/9684) Skips re-consuming timetick MsgStream when data coord restarts.

- Refactor meta snapshot:
  - [#10288](https://github.com/milvus-io/milvus/pull/10288) Reduces information saved in `SnapshotMeta`.
  - [#10703](https://github.com/milvus-io/milvus/pull/10703 ) Fixes failure when creating meta table because of compatibility issue.
  - [#9778](https://github.com/milvus-io/milvus/pull/9778) Simplifies `meta_snapshot` interface.

- [#10563](https://github.com/milvus-io/milvus/pull/10563) Changes default balance policy.

- [#10730](https://github.com/milvus-io/milvus/pull/10730) Returns segment state when getting query segment information.

- [#10534](https://github.com/milvus-io/milvus/pull/10534) Supports reading MinIO configuration from environment variables.

- [#10114](https://github.com/milvus-io/milvus/pull/10114) Sets default `gracefulTime` to `0`.

- [#9860](https://github.com/milvus-io/milvus/pull/9860) Hides `liveChn` into `sessionutil` and fix liveness initialization order.

- [#7115](https://github.com/milvus-io/milvus/pull/7115) Uses etcd to watch channel on data node.

- [#7606](https://github.com/milvus-io/milvus/pull/7606) Makes `knowhere` compile independently.

#### Features

- Handoff:   

  - [#10330](https://github.com/milvus-io/milvus/pull/10330) Adds `handoffTask`.

  - [#10084](https://github.com/milvus-io/milvus/pull/10084) Broadcasts `sealedSegmentChangeInfo` to `queryChannel`.
  - [#10619](https://github.com/milvus-io/milvus/pull/10619) Fixes removing segment when query node receives `segmentChangeInfo`.
  - [#10045](https://github.com/milvus-io/milvus/pull/10045) Watches `changeInfo` in query node.
  - [#10011](https://github.com/milvus-io/milvus/pull/10011) Updates excluded segments info when receiving `changeInfo`.
  - [#9606](https://github.com/milvus-io/milvus/pull/9606) Adds initialization information for `AddQueryChannelRequest`.
  - [#10619](https://github.com/milvus-io/milvus/pull/10619) Fixes removing segment when query node receives `segmentChangeInfo`.

- Primary Deduplication:
  - [#10834](https://github.com/milvus-io/milvus/pull/10834) Removes primary key duplicated query result in query node.
  - [#10355](https://github.com/milvus-io/milvus/pull/10355) Removes duplicated search results in proxy.
  - [#10117](https://github.com/milvus-io/milvus/pull/10117) Removes duplicated search results in segcore reduce.
  - [#10949](https://github.com/milvus-io/milvus/pull/10949) Uses primary key only to check search result duplication.
  - [#10967](https://github.com/milvus-io/milvus/pull/10967) Removes primary key duplicated query result in proxy.

- Auto-flush:
  - [#10659](https://github.com/milvus-io/milvus/pull/10659) Adds `injectFlush` method for `flushManager` interface.
  - [#10580](https://github.com/milvus-io/milvus/pull/10580) Adds injection logic for `FlushManager`.
  - [#10550](https://github.com/milvus-io/milvus/pull/10550) Merges automatic and manual flush with same segment ID.
  - [#10539](https://github.com/milvus-io/milvus/pull/10539) Allows flushed segments to trigger flush process.
  - [#10197](https://github.com/milvus-io/milvus/pull/10197) Adds a timed flush trigger mechanism.
  - [#10142](https://github.com/milvus-io/milvus/pull/10142) Applies flush manager logic in data node.
  - [#10075](https://github.com/milvus-io/milvus/pull/10075) Uses single signal channel to notify flush.
  - [#9986](https://github.com/milvus-io/milvus/pull/9986) Adds flush manager structure.

- [#10173](https://github.com/milvus-io/milvus/pull/10173) Adds binlog iterators.

- [#10193](https://github.com/milvus-io/milvus/pull/10193) Changes bloom filter use primary key.

- [#9782](https://github.com/milvus-io/milvus/pull/9782) Adds `allocIDBatch` for data node allocator.

#### Bug Fixes

- Incorrect collection loading behavior if there is not enough memory:
  - [#10796](https://github.com/milvus-io/milvus/pull/10796) Fixes get container mem usage.
  - [#10800](https://github.com/milvus-io/milvus/pull/10800) Uses `TotalInactiveFile` in `GetContainerMemUsed`.
  - [#10603](https://github.com/milvus-io/milvus/pull/10603) Increases compatibility for `EstimateMemorySize` interface.
  - [#10363](https://github.com/milvus-io/milvus/pull/10363) Adds `cgroups` to get container memory and check index memory in segment loader.
  - [#10294](https://github.com/milvus-io/milvus/pull/10294) Uses proto size to calculate request size.
  - [#9688](https://github.com/milvus-io/milvus/pull/9688) Estimates memory size with descriptor event.
  - [#9681](https://github.com/milvus-io/milvus/pull/9681) Fixes the way that binlog stores the original memory size.
  - [#9628](https://github.com/milvus-io/milvus/pull/9628) Stores original memory size of binlog file to extra information.

- Size of etcd-related request is too large:
  - [#10909](https://github.com/milvus-io/milvus/pull/10909) Fixes too many operations in `txn` request when saving `segmentInfo`.
  - [#10812](https://github.com/milvus-io/milvus/pull/10812) Fixes too large request when loading segment.
  - [#10768](https://github.com/milvus-io/milvus/pull/10768) Fixes too large request when loading collection.
  - [#10655](https://github.com/milvus-io/milvus/pull/10655) Splits watch operations into many transactions.
  - [#10587](https://github.com/milvus-io/milvus/pull/10587) Compacts `multiSegmentChangeInfo` to a single info.
  - [#10425](https://github.com/milvus-io/milvus/pull/10425) Trims `segmentinfo` binlog for `VChaninfo` usage.
  - [#10340](https://github.com/milvus-io/milvus/pull/10340) Fixes `multiSave` `childTask` failed to etcd.
  - [#10310](https://github.com/milvus-io/milvus/pull/10310) Fixes error when assigning load segment request.
  - [#10125](https://github.com/milvus-io/milvus/pull/10125) Splits large `loadSegmentReq` to multiple small requests.

- System panics:
  - [#10832](https://github.com/milvus-io/milvus/pull/10832) Adds query `mutex` to fix crash with panic.
  - [#10821](https://github.com/milvus-io/milvus/pull/10821) Index node finishes the task before index coord changed the meta.
  - [#10182](https://github.com/milvus-io/milvus/pull/10182) Fixes panic when flushing segment.
  - [#10681](https://github.com/milvus-io/milvus/pull/10681) Fixes query coord panic when upgrading `querychannelInfo`.

- RocksMQ-related issues:
  - [#10367](https://github.com/milvus-io/milvus/pull/10367) Stops retention gracefully.
  - [#9828](https://github.com/milvus-io/milvus/pull/9828) Fixes retention data race.
  - [#9933](https://github.com/milvus-io/milvus/pull/9933) Changes retention ticker time to 10 minutes.
  - [#9694](https://github.com/milvus-io/milvus/pull/9694) Deletes messages before deleting metadata in rocksmq retention.
  - [#11029](https://github.com/milvus-io/milvus/pull/11029) Fixes rocksmq `SeekToLatest`.
  - [#11057](https://github.com/milvus-io/milvus/pull/11057) Fixes `SeekToLatest` memory leakage and remove redundant logic.
  - [#11081](https://github.com/milvus-io/milvus/pull/11081) Fixes rocksdb retention ts not set.
  - [#11083](https://github.com/milvus-io/milvus/pull/11083) Adds topic lock for rocksmq `Seek`.
  - [#11076](https://github.com/milvus-io/milvus/pull/11076) Moves topic lock to the front of final delete in retention expired cleanup.

- [#10751](https://github.com/milvus-io/milvus/pull/10751) `loadIndex` keep retrying when `indexFilePathInfo` gets empty list.

- [#10583](https://github.com/milvus-io/milvus/pull/10583) `ParseHybridTs` returns type to INT64.

- [#10599](https://github.com/milvus-io/milvus/pull/10599) Delete message hash error.

- [#10314](https://github.com/milvus-io/milvus/pull/10314) Index building task mistakenly canceled by index coord by mistake.

- [#9701](https://github.com/milvus-io/milvus/pull/9701) Incorrect `CreateAlias/DropAlias/AlterAlias` implementation.

- [#9573](https://github.com/milvus-io/milvus/pull/9573) Timeout when data coord saves binlog.

- [#9788](https://github.com/milvus-io/milvus/pull/9788) Watch Channel canceled due to revision compacted.

- [#10994](https://github.com/milvus-io/milvus/pull/10994) Index node does not balances load.

- [#11152](https://github.com/milvus-io/milvus/pull/11152) Search is wrong when using Time Travel without filtering condition and call `num_entities`.

- [#11249](https://github.com/milvus-io/milvus/pull/11249) [#11277](https://github.com/milvus-io/milvus/pull/11277) Release collection block in query node.

- [#11222](https://github.com/milvus-io/milvus/pull/11222) Incorrect empty retrieve result handling.


#### v2.0.0-RC7

Release date: 2021-10-11

#### Compatibility

<table class="version">
	<thead>
	<tr>
		<th>Milvus version</th>
		<th>Python SDK version</th>
		<th>Java SDK version</th>
		<th>Go SDK version</th>
		<th>Node SDK version</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>2.0.0-RC7</td>
		<td>2.0.0rc7</td>
		<td>Coming soon</td>
		<td>Coming soon</td>
		<td>1.0.18</td>
	</tr>
	</tbody>
</table>



Milvus 2.0.0-RC7 is a preview version of Milvus 2.0.0-GA. It supports collection alias, shares `msgstream` on physical channel, and changes the default MinIO and Pulsar dependencies to cluster version. Several resource leaks and deadlocks were fixed. 

It should be noted that Milvus 2.0.0-RC7 is NOT compatible with previous versions of Milvus 2.0.0 because of some changes made to storage format. 

#### Improvements

- [#8215](https://github.com/milvus-io/milvus/pull/8215) Adds max number of retries for `interTask` in query coord.

- [#9459](https://github.com/milvus-io/milvus/pull/9459) Applies collection start position.

- [#8721](https://github.com/milvus-io/milvus/pull/8721) Adds Node ID to Log Name. 

- [#8940](https://github.com/milvus-io/milvus/pull/8940) Adds streaming segments memory to used memory in `checkLoadMemory`.

- [#8542](https://github.com/milvus-io/milvus/pull/8542) Replaces `proto.MarshalTextString` with `proto.Marshal`. 

- [#8770](https://github.com/milvus-io/milvus/pull/8770) Refactors flowgraph and related invocation.

- [#8666](https://github.com/milvus-io/milvus/pull/8666) Changes CMake version.

- [#8653](https://github.com/milvus-io/milvus/pull/8653) Updates `getCompareOpType`.

- [#8697](https://github.com/milvus-io/milvus/pull/8697) [#8682](https://github.com/milvus-io/milvus/pull/8682) [#8657](https://github.com/milvus-io/milvus/pull/8657) Applies collection start position when opening segment.

- [#8608](https://github.com/milvus-io/milvus/pull/8608) Changes segment replica structure.

- [#8565](https://github.com/milvus-io/milvus/pull/8565) Refactors buffer size calculation.  

- [#8262](https://github.com/milvus-io/milvus/pull/8262) Adds `segcore` logger.

- [#8138](https://github.com/milvus-io/milvus/pull/8138) Adds `BufferData` in `insertBufferNode`.

- [#7738](https://github.com/milvus-io/milvus/pull/7738) Implements allocating `msgstream` from pool when creating collections.

- [#8054](https://github.com/milvus-io/milvus/pull/8054) Improves codes in `insertBufferNode`.

- [#7909](https://github.com/milvus-io/milvus/pull/7909) Upgrades `pulsar-client-go` to 0.6.0.

- [#7913](https://github.com/milvus-io/milvus/pull/7913) Moves segcore rows_per_chunk configuration to query_node.yaml.

- [#7792](https://github.com/milvus-io/milvus/pull/7792) Removes `ctx` from `LongTermChecker`.

- [#9269](https://github.com/milvus-io/milvus/pull/9269) Changes `==` to `is` when comparing to None in expression.

- [#8159](https://github.com/milvus-io/milvus/pull/8159) Make `FlushSegments` async.

- [#8278](https://github.com/milvus-io/milvus/pull/8278) Refactor rocksmq close logic and improve codecov.

- [#7797](https://github.com/milvus-io/milvus/pull/7797) Uses definitional type instead of raw type.

#### Features

- [#9579](https://github.com/milvus-io/milvus/pull/9579) Uses replica memory size and `cacheSize` in `getSystemInfoMetrics`.

- [#9556](https://github.com/milvus-io/milvus/pull/9556) Adds `ProduceMark` interface to return message ID.

- [#9554](https://github.com/milvus-io/milvus/pull/9554) Supports `LoadPartial` interface for DataKV.

- [#9471](https://github.com/milvus-io/milvus/pull/9471) Supports `DescribeCollection` by collection ID.

- [#9451](https://github.com/milvus-io/milvus/pull/9451) Stores index parameters to descriptor event.

- [#8574](https://github.com/milvus-io/milvus/pull/8574) Adds a `round_decimal` parameter for precision control to search function.

- [#8947](https://github.com/milvus-io/milvus/pull/8947) Rocksmq supports `SubscriptionPositionLatest`.

- [#8919](https://github.com/milvus-io/milvus/pull/8919) Splits blob into several string rows when index file is large.

- [#8914](https://github.com/milvus-io/milvus/pull/8914) Binlog parser tool supports index files.

- [#8514](https://github.com/milvus-io/milvus/pull/8514) Refactors the index file format.

- [#8765](https://github.com/milvus-io/milvus/pull/8765) Adds `cacheSize` to prevent OOM in query node.

- [#8673](https://github.com/milvus-io/milvus/pull/8673) [#8420](https://github.com/milvus-io/milvus/pull/8420) [#8212](https://github.com/milvus-io/milvus/pull/8212) [#8272](https://github.com/milvus-io/milvus/pull/8272) [#8166](https://github.com/milvus-io/milvus/pull/8166) Supports multiple Milvus clusters sharing Pulsar and MinIO. 

- [#8654](https://github.com/milvus-io/milvus/pull/8654) Adds `BroadcastMark` for `Msgstream` returning Message IDs.

- [#8586](https://github.com/milvus-io/milvus/pull/8586) Adds Message ID return value into producers.

- [#8408](https://github.com/milvus-io/milvus/pull/8408) [#8363](https://github.com/milvus-io/milvus/pull/8363) [#8454](https://github.com/milvus-io/milvus/pull/8454) [#8064](https://github.com/milvus-io/milvus/pull/8064) [#8480](https://github.com/milvus-io/milvus/pull/8480) Adds session liveness check.

- [#8264](https://github.com/milvus-io/milvus/pull/8264) Adds description event extras.

- [#8341](https://github.com/milvus-io/milvus/pull/8341) Replaces `MarshalTextString` with `Marshal` in root coord.

- [#8228](https://github.com/milvus-io/milvus/pull/8228) Supports healthz check API.

- [#8276](https://github.com/milvus-io/milvus/pull/8276) Initializes the SIMD type when initializing an index node.

- [#7967](https://github.com/milvus-io/milvus/pull/7967) Adds knowhere.yaml to support knowhere configuration. 

- [#7974](https://github.com/milvus-io/milvus/pull/7974) Supports setting max task number of task queue.

- [#7948](https://github.com/milvus-io/milvus/pull/7948) [#7975](https://github.com/milvus-io/milvus/pull/7975) Adds `suffixSnapshot` to implement SnapshotKV.

- [#7942](https://github.com/milvus-io/milvus/pull/7942) Supports configuring SIMD type.

- [#7814](https://github.com/milvus-io/milvus/pull/7814) Supports bool field filter in search and query expression.

- [#7635](https://github.com/milvus-io/milvus/pull/7635) Supports setting segcore rows_per_chunk via configuration file.

#### Bug Fixes

- [#9572](https://github.com/milvus-io/milvus/pull/9572) Rocksdb does not delete the end key after `DeleteRange` is called.

- [#8735](https://github.com/milvus-io/milvus/pull/8735) Acked infomation takes up memory resources.

- [#9454](https://github.com/milvus-io/milvus/pull/9454) Data race in query service.

- [#8850](https://github.com/milvus-io/milvus/pull/8850) SDK raises error with a message about index when dropping collection by alias.

- [#8930](https://github.com/milvus-io/milvus/pull/8930) Flush occasionally gets stuck when `SaveBinlogPath` fails due to instant buffer removal from `insertBuf`.

- [#8868](https://github.com/milvus-io/milvus/pull/8868) Trace log catches the wrong file name and line number.

- [#8844](https://github.com/milvus-io/milvus/pull/8844) `SearchTask` result is nil.

- [#8835](https://github.com/milvus-io/milvus/pull/8835) Root coord crashes because of bug in pulsar-client-go.

- [#8780](https://github.com/milvus-io/milvus/pull/8780) [#8268](https://github.com/milvus-io/milvus/pull/8268) [#7255](https://github.com/milvus-io/milvus/pull/7255) Collection alias-related issues.

- [#8744](https://github.com/milvus-io/milvus/pull/8744) Rocksdb_kv error process.

- [#8752](https://github.com/milvus-io/milvus/pull/8752) Data race in mqconsumer.

- [#8686](https://github.com/milvus-io/milvus/pull/8686) Flush after auto-flush will not finish.

- [#8564](https://github.com/milvus-io/milvus/pull/8564) [#8405](https://github.com/milvus-io/milvus/pull/8405) [#8743](https://github.com/milvus-io/milvus/pull/8743) [#8798](https://github.com/milvus-io/milvus/pull/8798) [#9509](https://github.com/milvus-io/milvus/pull/9509) [#8884](https://github.com/milvus-io/milvus/pull/8884) rocksdb memory leak.

- [#8671](https://github.com/milvus-io/milvus/pull/8671) Objects are not removed in MinIO when dropped.

- [#8050](https://github.com/milvus-io/milvus/pull/8050) [#8545](https://github.com/milvus-io/milvus/pull/8545) [#8567](https://github.com/milvus-io/milvus/pull/8567) [#8582](https://github.com/milvus-io/milvus/pull/8582) [#8562](https://github.com/milvus-io/milvus/pull/8562) tsafe-related issues.

- [#8137](https://github.com/milvus-io/milvus/pull/8137) Time goes backward because TSO does not load last timestamp.

- [#8461](https://github.com/milvus-io/milvus/pull/8461) Potential data race in data coord.

- [#8386](https://github.com/milvus-io/milvus/pull/8386) Incomplete logic when allocating dm channel to data node.

- [#8206](https://github.com/milvus-io/milvus/pull/8206) Incorrect reduce algorithm in proxy search task. 

- [#8120](https://github.com/milvus-io/milvus/pull/8120) Potential data race in root coord.

- [#8068](https://github.com/milvus-io/milvus/pull/8068) Query node crashes when query result is empty and optional `retrieve_ret_` is not initialized.

- [#8060](https://github.com/milvus-io/milvus/pull/8060) Query task panicking.

- [#8091](https://github.com/milvus-io/milvus/pull/8091) Data race in proxy gRPC client.

- [#8078](https://github.com/milvus-io/milvus/pull/8078) Data race in root coord gRPC client.

- [#7730](https://github.com/milvus-io/milvus/pull/7730) Topic and ConsumerGroup remain after `CloseRocksMQ`.

- [#8188](https://github.com/milvus-io/milvus/pull/8188) Logic error in releasing collections.



#### v2.0.0-RC6

Release date: 2021-09-10

#### Compatibility

<table class="version">
	<thead>
	<tr>
		<th>Milvus version</th>
		<th>Python SDK version</th>
		<th>Java SDK version</th>
		<th>Go SDK version</th>
		<th>Node SDK version</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>2.0.0-RC6</td>
		<td>2.0.0rc6</td>
		<td>Coming soon</td>
		<td>Coming soon</td>
		<td>1.0.18</td>
	</tr>
	</tbody>
</table>


Milvus 2.0.0-RC6 is a preview version of Milvus 2.0.0. It supports specifying shard number when creating collections, and query by expression. It exposes more cluster metrics through API. In RC6 we increase the unit test coverage to 80%. We also fixed a series of issues involving resource leakage, system panic, etc.

#### Improvements

- Increases unit test coverage to 80%.

#### Features

- [#7482](https://github.com/milvus-io/milvus/pull/7482) Supports specifying shard number when creating a collection.
- [#7386](https://github.com/milvus-io/milvus/pull/7386) Supports query by expression.
- Exposes system metrics through API:
  - [#7400](https://github.com/milvus-io/milvus/pull/7400) Proxy metrics integrate with other coordinators.
  - [#7177](https://github.com/milvus-io/milvus/pull/7177) Exposes metrics of data node and data coord.
  - [#7228](https://github.com/milvus-io/milvus/pull/7228) Exposes metrics of root coord.
  - [#7472](https://github.com/milvus-io/milvus/pull/7472) Exposes more detailed metrics information.
  - [#7436](https://github.com/milvus-io/milvus/pull/7436) Supports caching the system information metrics.

#### Bug Fixes

- [#7434](https://github.com/milvus-io/milvus/pull/7434) Query node OOM if loading a collection that beyond the memory limit.
- [#7678](https://github.com/milvus-io/milvus/pull/7678) Standalone OOM when recovering from existing storage.
- [#7636](https://github.com/milvus-io/milvus/pull/7636) Standalone panic when sending message to a closed channel.
- [#7631](https://github.com/milvus-io/milvus/pull/7631) Milvus panic when closing flowgraph.
- [#7605](https://github.com/milvus-io/milvus/pull/7605) Milvus crashed with panic when running nightly CI tests.
- [#7596](https://github.com/milvus-io/milvus/pull/7596) Nightly cases failed because rootcoord disconnected with etcd.
- [#7557](https://github.com/milvus-io/milvus/pull/7557) Wrong search result returned when the term content in expression is not in order.
- [#7536](https://github.com/milvus-io/milvus/pull/7536) Incorrect `MqMsgStream` Seek logic.
- [#7527](https://github.com/milvus-io/milvus/pull/7527) Dataset's memory leak in `knowhere` when searching.
- [#7444](https://github.com/milvus-io/milvus/pull/7444) Deadlock of channels time ticker.
- [#7428](https://github.com/milvus-io/milvus/pull/7428) Possible deadlock when `MqMsgStream` broadcast fails.
- [#7715](https://github.com/milvus-io/milvus/pull/7715) Query request overwritten by concurrent operations on the same slice.



#### v2.0.0-RC5

Release date: 2021-08-30

#### Compatibility

<table class="version">
	<thead>
	<tr>
		<th>Milvus version</th>
		<th>Python SDK version</th>
		<th>Java SDK version</th>
		<th>Go SDK version</th>
		<th>Node SDK version</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>2.0.0-RC5</td>
		<td>2.0.0rc5</td>
		<td>Coming soon</td>
		<td>Coming soon</td>
		<td>1.0.18</td>
	</tr>
	</tbody>
</table>

Milvus 2.0.0-RC5 is a preview version of Milvus 2.0.0. It supports message queue data retention mechanism and etcd data cleanup,  exposes cluster metrics through API, and prepares for delete operation support. RC5 also made great progress on system stability. We fixed a series of resource leakage, operation hang and the misconfiguration of standalone Pulsar under Milvus cluster.

#### Improvements

- [#7226](https://github.com/milvus-io/milvus/pull/7226) Refactors data coord allocator.
- [#6867](https://github.com/milvus-io/milvus/pull/6867) Adds connection manager.
- [#7172](https://github.com/milvus-io/milvus/pull/7172) Adds a seal policy to restrict the lifetime of a segment.
- [#7163](https://github.com/milvus-io/milvus/pull/7163) Increases the timeout for gRPC connection when creating index.
- [#6996](https://github.com/milvus-io/milvus/pull/6996) Adds a minimum interval for segment flush.
- [#6590](https://github.com/milvus-io/milvus/pull/6590) Saves binlog path in `SegmentInfo`.
- [#6848](https://github.com/milvus-io/milvus/pull/6848) Removes `RetrieveRequest` and `RetrieveTask.`
- [#7102](https://github.com/milvus-io/milvus/pull/7102) Supports vector field as output.
- [#7075](https://github.com/milvus-io/milvus/pull/7075) Refactors `NewEtcdKV` API.
- [#6965](https://github.com/milvus-io/milvus/pull/6965) Adds channel for data node to watch etcd.
- [#7066](https://github.com/milvus-io/milvus/pull/7066) Optimizes search reduce logics.
- [#6993](https://github.com/milvus-io/milvus/pull/6993) Enhances the log when parsing gRPC recv/send parameters.
- [#7331](https://github.com/milvus-io/milvus/pull/7331) Changes context to correct package. 
- [#7278](https://github.com/milvus-io/milvus/pull/7278) Enables etcd auto compaction for every 1000 revision.
- [#7355](https://github.com/milvus-io/milvus/pull/7355) Clean `fmt.Println `in util/flowgraph.

#### Features

- [#7112](https://github.com/milvus-io/milvus/pull/7112) [#7174](https://github.com/milvus-io/milvus/pull/7174) Imports an embedded etcdKV (part 1).
- [#7231](https://github.com/milvus-io/milvus/pull/7231) Adds a segment filter interface.
- [#7157](https://github.com/milvus-io/milvus/pull/7157) Exposes metrics of index coord and index nodes.
- [#7137](https://github.com/milvus-io/milvus/pull/7137) [#7157](https://github.com/milvus-io/milvus/pull/7157) Exposes system topology information by proxy.
- [#7113](https://github.com/milvus-io/milvus/pull/7113) [#7157](https://github.com/milvus-io/milvus/pull/7157) Exposes metrics of query coord and query nodes.
- [#7134](https://github.com/milvus-io/milvus/pull/7134) Allows users to get vectors using memory instead of local storage.
- [#6617](https://github.com/milvus-io/milvus/pull/6617) Supports retention for rocksmq.
- [#7303](https://github.com/milvus-io/milvus/pull/7303) Adds query node segment filter.
- [#7304](https://github.com/milvus-io/milvus/pull/7304) Adds `delete` API into proto.
- [#7261](https://github.com/milvus-io/milvus/pull/7261) Adds delete node.
- [#7268](https://github.com/milvus-io/milvus/pull/7268) Constructs Bloom filter when inserting.

#### Bug Fixes

- [#7272](https://github.com/milvus-io/milvus/pull/7272) [#7352](https://github.com/milvus-io/milvus/pull/7352) [#7335](https://github.com/milvus-io/milvus/pull/7335) Failure to start new docker container with existing volumes if index was created: proxy is not healthy.
- [#7243](https://github.com/milvus-io/milvus/pull/7243) Failure to create index in a new version of Milvus for data that were inserted in an old version.
- [#7253](https://github.com/milvus-io/milvus/pull/7253) Search gets empty results after releasing a different partition.
- [#7244](https://github.com/milvus-io/milvus/pull/7244) [#7227](https://github.com/milvus-io/milvus/pull/7227) Proxy crashes when receiving empty search results.
- [#7203](https://github.com/milvus-io/milvus/pull/7203) Connection gets stuck when gRPC server is down.
- [#7188](https://github.com/milvus-io/milvus/pull/7188) Incomplete unit test logics.
- [#7175](https://github.com/milvus-io/milvus/pull/7175) Unspecific error message returns when calculating distances using collection IDs without loading.
- [#7151](https://github.com/milvus-io/milvus/pull/7151) Data node flowgraph does not close caused by missing `DropCollection`.
- [#7167](https://github.com/milvus-io/milvus/pull/7167) Failure to load IVF_FLAT index.
- [#7123](https://github.com/milvus-io/milvus/pull/7123) Timestamp go back for `timeticksync`.
- [#7140](https://github.com/milvus-io/milvus/pull/7140) `calc_distance` returns wrong results for binary vectors when using TANIMOTO metrics.
- [#7143](https://github.com/milvus-io/milvus/pull/7143) The state of memory and etcd is inconsistent if KV operation fails.
- [#7141](https://github.com/milvus-io/milvus/pull/7141) [#7136](https://github.com/milvus-io/milvus/pull/7136) Index building gets stuck when the index node pod is frequently killed and pulled up.
- [#7119](https://github.com/milvus-io/milvus/pull/7119) Pulsar `msgStream` may get stuck when subscribed with the same topic and sub name.
- [#6971](https://github.com/milvus-io/milvus/pull/6971) Exception occurs when searching with index (HNSW).
- [#7104](https://github.com/milvus-io/milvus/pull/7104) Search gets stuck if query nodes only load sealed segment without watching insert channels.
- [#7085](https://github.com/milvus-io/milvus/pull/7085) Segments do not auto flush.
- [#7074](https://github.com/milvus-io/milvus/pull/7074) Index nodes wait for index coord to start to complete.
- [#7061](https://github.com/milvus-io/milvus/pull/7061) Segment allocation does not expire if data coord does not receive timetick message from data node.
- [#7059](https://github.com/milvus-io/milvus/pull/7059) Query nodes get producer leakage.
- [#7005](https://github.com/milvus-io/milvus/pull/7005) Query nodes do not return error to query coord when `loadSegmentInternal` fails.
- [#7054](https://github.com/milvus-io/milvus/pull/7054) Query nodes return incorrect IDs when `topk` is larger than `row_num.`
- [#7053](https://github.com/milvus-io/milvus/pull/7053) Incomplete allocation logics.
- [#7044](https://github.com/milvus-io/milvus/pull/7044) Lack of check on unindexed vectors in memory before retriving vectors in local storage.
- [#6862](https://github.com/milvus-io/milvus/pull/6862) Memory leaks in flush cache of data node.
- [#7346](https://github.com/milvus-io/milvus/pull/7346) Query coord container exited in less than 1 minute when re-installing Milvus cluster.
- [#7339](https://github.com/milvus-io/milvus/pull/7339) Incorrect expression boundary.
- [#7311](https://github.com/milvus-io/milvus/pull/7311) Collection nil when adding query collection.
- [#7266](https://github.com/milvus-io/milvus/pull/7266) Flowgraph released incorrectly.
- [#7310](https://github.com/milvus-io/milvus/pull/7310) Excessive timeout when searching after releasing and loading a partition.
- [#7320](https://github.com/milvus-io/milvus/pull/7320) Port conflicts between embedded etcd and external etcd.
- [#7336](https://github.com/milvus-io/milvus/pull/7336) Data node corner cases.




#### v2.0.0-RC4

Release date: 2021-08-13

#### Compatibility

| Milvus version | Python SDK version                | Java SDK version | Go SDK version |
| ------------------ | ------------------------------------- | -------------------- | ------------------ |
| 2.0.0-RC4          | 2.0.0rc4 | Coming soon          | Coming soon        |

Milvus 2.0.0-RC4 is a preview version of Milvus 2.0.0. It mainly focuses on fixing stability issues, it also offers functionalities to retrieve vector data from object storage and specify output field by wildcard matching.

#### Improvements

- [#6984](https://github.com/milvus-io/milvus/issues/6984) [#6772](https://github.com/milvus-io/milvus/issues/6772) [#6704](https://github.com/milvus-io/milvus/issues/6704) [#6652](https://github.com/milvus-io/milvus/issues/6652) [#6536](https://github.com/milvus-io/milvus/issues/6536) [#6522](https://github.com/milvus-io/milvus/issues/6522) Unit test improvements.

- [#6859](https://github.com/milvus-io/milvus/pull/6861) Increases the `MaxCallRecvMsgSize` and `MaxCallSendMsgSize` of gRPC client.

- [#6796](https://github.com/milvus-io/milvus/pull/6807) Fixes MsgStream exponential retry.

- [#6897](https://github.com/milvus-io/milvus/pull/6897) [#6899](https://github.com/milvus-io/milvus/pull/6899) [#6681](https://github.com/milvus-io/milvus/pull/6899) [#6766](https://github.com/milvus-io/milvus/pull/6766) [#6768](https://github.com/milvus-io/milvus/pull/6768) [#6597](https://github.com/milvus-io/milvus/pull/6597) [#6501](https://github.com/milvus-io/milvus/pull/6501) [#6477](https://github.com/milvus-io/milvus/pull/6477) [#6478](https://github.com/milvus-io/milvus/pull/6478) [#6935](https://github.com/milvus-io/milvus/pull/6935) [#6871](https://github.com/milvus-io/milvus/pull/6871) [#6671](https://github.com/milvus-io/milvus/pull/6671) [#6682](https://github.com/milvus-io/milvus/pull/6682) Log improvements.

- [#6440](https://github.com/milvus-io/milvus/pull/6441) Refactors segment manager.

- [#6421](https://github.com/milvus-io/milvus/pull/6449) Splits raw vectors to several smaller binlog files when creating index.

- [#6466](https://github.com/milvus-io/milvus/pull/6467) Separates the idea of query and search.

- [#6505](https://github.com/milvus-io/milvus/pull/6506) Changes `output_fields` to `out_fields_id` for RetrieveRequest.

- [#6427](https://github.com/milvus-io/milvus/pull/6328) Refactors the logic of assigning tasks in index coord.

- [#6529](https://github.com/milvus-io/milvus/pull/6543) [#6599](https://github.com/milvus-io/milvus/pull/6600) Refactors the snapshot of timestamp statistics.

- [#6692](https://github.com/milvus-io/milvus/issues/6692) [#6343](https://github.com/milvus-io/milvus/pull/6700) Shows/Describes collections/partitions with created timestamps.

- [#6629](https://github.com/milvus-io/milvus/pull/6663) Adds the WatchWithVersion interface for etcdKV.

- [#6666](https://github.com/milvus-io/milvus/pull/6667) Refactors expression executor to use single bitsets.

- [#6664](https://github.com/milvus-io/milvus/pull/6665) Auto creates new segments when allocating rows that exceeds the maximum number of rows per segment.

- [#6786](https://github.com/milvus-io/milvus/pull/6786) Refactors `RangeExpr` and `CompareExpr`.

- [#6497](https://github.com/milvus-io/milvus/pull/6503) Looses the lower limit of dimension when searching on a binary vector field.

#### Features

- [#6706](https://github.com/milvus-io/milvus/pull/6707) Supports reading vectors from disk.

- [#6299](https://github.com/milvus-io/milvus/issues/6299) [#6598](https://github.com/milvus-io/milvus/pull/6598) Supports query vector field.

- [#5210](https://github.com/milvus-io/milvus/pull/6460) Extends the grammar of Boolean expressions.

- [#6411](https://github.com/milvus-io/milvus/pull/6510) [#6650](https://github.com/milvus-io/milvus/pull/6671) Supports wildcards and wildcard matching on search/query output fields.  

- [#6464](https://github.com/milvus-io/milvus/pull/6613) Adds a vector chunk manager to support vector file local storage.

- [#6701](https://github.com/milvus-io/milvus/pull/6702) Supports data persistence with docker compose deployments.

- [#6767](https://github.com/milvus-io/milvus/pull/6770) Adds a Grafana dashboard .json file for Milvus.

#### Bug fixes

- [#5443](https://github.com/milvus-io/milvus/pull/6976) `CalcDistance` returns wrong results when fetching vectors from collection.

- [#7004](https://github.com/milvus-io/milvus/pull/7004) Pulsar consumer causes goroutine leakage.

- [#6946](https://github.com/milvus-io/milvus/pull/6946) Data race occurs when a flow graph `close()` immediately after `start()`.

- [#6903](https://github.com/milvus-io/milvus/pull/6958) Uses proto marshal instead of marshalTextString in querycoord to avoid crash triggered by unknown field name crash.

- [#6374](https://github.com/milvus-io/milvus/issues/6374) [#6849](https://github.com/milvus-io/milvus/pull/6908) Load collection failure.

- [#6977](https://github.com/milvus-io/milvus/pull/6978) Search returns wrong limit after a partition or collection is dropped.

- [#6515](https://github.com/milvus-io/milvus/issues/6515) [#6567](https://github.com/milvus-io/milvus/issues/6567) [#6552](https://github.com/milvus-io/milvus/issues/6552) [#6483](https://github.com/milvus-io/milvus/pull/6551) Data node BackGroundGC does not work and causes memory leak.

- [#6943](https://github.com/milvus-io/milvus/pull/6944) The MinIOKV `GetObject` method does not close client and causes goroutine leaking per call.

- [#6370](https://github.com/milvus-io/milvus/pull/6935) Search is stuck due to wrong semantics offered by load partition.

- [#6831](https://github.com/milvus-io/milvus/pull/6832) Data node crashes in meta service.

- [#6469](https://github.com/milvus-io/milvus/pull/6905) Search binary results are wrong with metrics of Hamming when limit (topK) is bigger than the quantity of inserted entities.

- [#6693](https://github.com/milvus-io/milvus/pull/6870) Timeout caused by segment race condition.

- [#6097](https://github.com/milvus-io/milvus/pull/6351) Load hangs after frequently restarting query node within a short period of time.

- [#6464](https://github.com/milvus-io/milvus/pull/6465) Data sorter edge cases.

- [#6419](https://github.com/milvus-io/milvus/pull/6439) Milvus crashes when inserting empty vectors.

- [#6477](https://github.com/milvus-io/milvus/pull/6477) Different components repeatedly create buckets in MinIO.

- [#6377](https://github.com/milvus-io/milvus/pull/6377) Query results get incorrect global sealed segments from etcd.

- [#6499](https://github.com/milvus-io/milvus/pull/6500) TSO allocates wrong timestamps.

- [#6501](https://github.com/milvus-io/milvus/pull/6545) Channels are lost after data node crashes.

- [#6527](https://github.com/milvus-io/milvus/pull/6568) Task info of `watchQueryChannels` can't be deleted from etcd.

- [#6576](https://github.com/milvus-io/milvus/issues/6576) [#6526](https://github.com/milvus-io/milvus/pull/6577) Duplicate primary field IDs are added when retrieving entities.

- [#6627](https://github.com/milvus-io/milvus/issues/6627) [#6569](https://github.com/milvus-io/milvus/pull/6628) `std::sort` does not work properly to filter search results when the distance of new record is NaN.

- [#6655](https://github.com/milvus-io/milvus/pull/6656) Proxy crashes when retrieve task is called.

- [#6762](https://github.com/milvus-io/milvus/pull/6763) Incorrect created timestamp of collections and partitions.

- [#6644](https://github.com/milvus-io/milvus/pull/6658) Data node failes to restart automatically.

- [#6641](https://github.com/milvus-io/milvus/pull/6642) Failure to stop data coord when disconnecting with etcd.

- [#6621](https://github.com/milvus-io/milvus/pull/6621) Milvus throws an exception when the inserted data size is larger than the segment.

- [#6436](https://github.com/milvus-io/milvus/issues/6436) [#6573](https://github.com/milvus-io/milvus/issues/6573) [#6507](https://github.com/milvus-io/milvus/pull/6814) Incorrect handling of time synchronization.

- [#6732](https://github.com/milvus-io/milvus/pull/6871) Failure to create IVF_PQ index.




#### v2.0.0-RC2

Release date: 2021-07-13

#### Compatibility

| Milvus version | Python SDK version | Java SDK version | Go SDK version |
| :------------- | :----------------- | :--------------- | :------------- |
| 2.0.0-RC2 | 2.0.0rc2 | Coming soon            | Coming soon          |

Milvus 2.0.0-RC2 is a preview version of Milvus 2.0.0. It fixes stability and performance issues and refactors code for node and storage management.

#### Improvements

- [#6356](https://github.com/milvus-io/milvus/pull/6356) Refactors code for cluster in data coordinator. 
- [#6300](https://github.com/milvus-io/milvus/pull/6300) Refactors code for meta management in data coordinator. (#6300)
- [#6289](https://github.com/milvus-io/milvus/pull/6289) Adds `collectionID` and `partitionID` to `SegmentIndexInfo`. 
- [#6258](https://github.com/milvus-io/milvus/pull/6258) Clears the corresponding `searchMsgStream` in proxy when calling `releaseCollection()`. 
- [#6227](https://github.com/milvus-io/milvus/pull/6227) Merges codes relating to retrieve and search in query node. 
- [#6196](https://github.com/milvus-io/milvus/pull/6196) Adds candidate management for data coordinator to manage data node cluster. 
- [#6188](https://github.com/milvus-io/milvus/pull/6188) Adds Building Milvus with Docker Docs. (#6188)

#### Features

- [#6386](https://github.com/milvus-io/milvus/pull/6386) Adds the `fget_objects()` method for loading files from MinIO to the local device.
- [#6253](https://github.com/milvus-io/milvus/pull/6253) Adds the `GetFlushedSegments()` method in data coordinator.
- [#6213](https://github.com/milvus-io/milvus/pull/6213) Adds the `GetIndexStates()` method.

#### Bug fixes

- [#6184](https://github.com/milvus-io/milvus/pull/6184) Search accuracy worsens when dataset gets larger.
- [#6308](https://github.com/milvus-io/milvus/pull/6308) The server crashes if the KNNG in NSG is not full.
- [#6212](https://github.com/milvus-io/milvus/pull/6212) Search hangs after restarting query nodes. 
- [#6265](https://github.com/milvus-io/milvus/pull/6265) The server does not check node status when detecting nodes are online. 
- [#6359](https://github.com/milvus-io/milvus/pull/6359) [#6334](https://github.com/milvus-io/milvus/pull/6334) An error occurs when compiling Milvus on CentOS




#### v2.0.0-RC1


Release date: 2021-06-28

#### Compatibility



| Milvus version | Python SDK version | Java SDK version | Go SDK version |
| :------------- | :----------------- | :--------------- | :------------- |
| 2.0.0-RC1 | 2.0.0rc1 | Coming soon            | Coming soon          |



Milvus 2.0.0-RC1 is the preview version of 2.0.0. It introduces Golang as the distributed layer development language and a new cloud-native distributed design. The latter brings significant improvements to scalability, elasticity, and functionality. 

#### Architecture

Milvus 2.0 is a cloud-native vector database with storage and computation separated by design. All components in this refactored version of Milvus are stateless to enhance elasticity and flexibility.

 The system breaks down into four levels: 

- Access layer
- Coordinator service
- Worker nodes 
- Storage 

**Access layer:** The front layer of the system and endpoint to users.  It comprises peer proxies for forwarding requests and gathering results.

**Coordinator** **service:** The coordinator service assigns tasks to the worker nodes and functions as the system's brain. It has four coordinator types: root coord, data coord, query coord, and index coord.

**Worker nodes:** Worker nodes are dumb executors that follow the instructions from the coordinator service. There are three types of worker nodes, each responsible for a different job: data nodes, query nodes, and index nodes.

**Storage:** The cornerstone of the system that all other functions depend on. It has three storage types: meta storage, log broker, and object storage. Kudos to the open-source communities of etcd, Pulsar, MinIO, and RocksDB for building this fast, reliable storage.

> For more information about how the system works, see [Milvus 2.0 Architecture](architecture_overview.md).

#### New Features

**SDK**

- Object-relational mapping (ORM) PyMilvus

  The PyMilvus APIs operate directly on collections, partitions, and indexes, helping users focus on the building of an effective data model rather than the detailed implementation. 

**Core Features**

- Hybrid Search between scalar and vector data

  Milvus 2.0 supports storing scalar data. Operators such as GREATER, LESS, EQUAL, NOT, IN, AND, and OR can be used to filter scalar data before a vector search is conducted. Currently supported data types include bool, int8, int16, int32, int64, float, and double. Support for string/VARBINARY data will be offered in a later version.

- Match query

  Unlike the search operation, which returns similar results, the match query operation returns exact matches. Match query can be used to retrieve vectors by ID or by condition. 

- Tunable consistency

  Distributed databases make tradeoffs between consistency and availability/latency. Milvus offers four consistency levels (from strongest to weakest): strong, bounded staleness, session, and consistent prefix. You can define your own read consistency by specifying the read timestamp. As a rule of thumb, the weaker the consistency level, the higher the availability and the higher the performance.

- Time travel

  Time travel allows you to access historical data at any point within a specified time period, making it possible to query data in the past, restore, and backup. 

**Miscellaneous**

- Supports installing Milvus 2.0 with Helm or Docker-compose.

- Compatibility with Prometheus and Grafana for monitoring and alerts.

- Milvus Insight

  Milvus Insight is a graphical management system for Milvus. It features visualization of cluster states, meta management, data queries and more. Milvus Insight will eventually be open sourced.

#### Breaking Changes

Milvus 2.0 uses an entirely different programming language, data format, and distributed architecture compared with previous versions. This means prior versions of Milvus cannot be upgraded to 2.x. However, Milvus 1.x is receiving long-term support and data migration tools will be made available as soon as possible. 

Specific breaking changes include:

- JAVA, Go, or C++ SDK is not yet supported.

- Delete or update is not yet supported.

- PyMilvus-ORM does not support force flush.

- Data format is incompatible with all prior versions. 

- Mishards is deprecated because Milvus 2.0 is distributed and sharding middleware is no longer necessary.

- Local file system and distributed system storage are not yet supported.

# Get Started #
## Prerequisites ##


#### Environment Checklist

Before you install Milvus, check your hardware and software to see if they meet the requirements.

<div class="tab-wrapper"><a href="prerequisite-docker.md" class='active '>Install with Docker Compose</a><a href="prerequisite-helm.md" class=''>Install on Kubernetes</a></div>

#### Hardware requirements

| Component           | Requirement                                                  | Note                                                         |
| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| CPU                 | Intel CPU Sandy Bridge or later                              | Current version of Milvus does not support AMD and Apple M1 CPUs. |
| CPU instruction set | <ul><li>SSE4.2</li><li>AVX</li><li>AVX2</li><li>AVX-512</li></ul> | Vector similarity search and index building within Milvus require CPU's support of single instruction, multiple data (SIMD) extension sets. Ensure that the CPU supports at least one of the SIMD extensions listed. See [CPUs with AVX](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions#CPUs_with_AVX) for more information.                           |
| RAM                 | 8 GB or more                                                 | The size of RAM depends on the data volume.                  |
| Hard drive          | SATA 3.0 SSD or higher                                       | The size of hard drive depends on the data volume.           |

#### Software requirements

| Operating system           | Software                                                     | Note                                                         |
| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| macOS 10.14 or later       | Docker Desktop                                               | Set the Docker virtual machine (VM) to use a minimum of 2 virtual CPUs (vCPUs) and 8 GB of initial memory. Otherwise, installation might fail. <br/>See [Install Docker Desktop on Mac](https://docs.docker.com/desktop/mac/install/) for more information. |
| Linux platforms            | <ul><li>Docker 19.03 or later</li><li>Docker Compose 1.25.1 or later</li></ul> | See [Install Docker Engine](https://docs.docker.com/engine/install/) and [Install Docker Compose](https://docs.docker.com/compose/install/) for more information. |
| Windows with WSL 2 enabled | Docker Desktop                                               | We recommend that you store source code and other data bind-mounted into Linux containers in the Linux file system instead of the Windows file system.<br/>See [Install Docker Desktop on Windows with WSL 2 backend](https://docs.docker.com/desktop/windows/install/#wsl-2-backend) for more information. |

#### What's next
- If your hardware and software meet the requirements, you can:
  - [Install Milvus standalone with Docker Compose](install_standalone-docker.md)
  - [Install Milvus cluster with Docker Compose](install_cluster-docker.md)

- See [System Configuration](configuration_standalone-basic.md) for parameters you can set while installing Milvus.

## Install Milvus ##
### Milvus Standalone ###


#### Install Milvus Standalone

This topic describes how to install Milvus standalone with Docker Compose or on Kubernetes. 

[Check the requirements for hardware and software](prerequisite-docker.md) prior to your installation. 

If you run into image loading errors while installing, you can [Install Milvus Offline](install_offline-docker.md).

You can also build Milvus from source code at [GitHub](https://github.com/milvus-io/milvus#to-start-developing-milvus).


<div class="tab-wrapper"><a href="install_standalone-docker.md" class='active '>Install with Docker Compose</a><a href="install_standalone-helm.md" class=''>Install on Kubernetes</a></div>

#### Download an installation file

[Download](https://github.com/milvus-io/milvus/releases/download/v2.0.0-rc8/milvus-standalone-docker-compose.yml) `milvus-standalone-docker-compose.yml` directly or with the following command, and save it as `docker-compose.yml`.

```
$ wget https://github.com/milvus-io/milvus/releases/download/v2.0.0-rc8/milvus-standalone-docker-compose.yml -O docker-compose.yml
```

#### Configure Milvus (optional)

[Download](https://raw.githubusercontent.com/milvus-io/milvus/v2.0.0-rc8/configs/milvus.yaml) `milvus.yaml` directly or with the following command.

```
$ wget https://raw.githubusercontent.com/milvus-io/milvus/v2.0.0-rc8/configs/milvus.yaml
```

Modify the configurations to suit your needs. See [Milvus Standalone System Configurations](configuration_standalone-basic.md) for more information.


In `docker-compose.yml`, map the local path to your `milvus.yaml` file onto the corresponding docker container path to the configuration file `/milvus/configs/milvus.yaml` under the `volumes` section.

```yaml
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus
      - /local/path/to/your/file:/milvus/configs/milvus.yaml     #### Map the local path to the container path
```

<div class="alert note">
Data is stored in the <code>volumes</code> folder according to the default configuration in <code>docker-compose.yml</code>. To change the folder to store data, edit <code>docker-compose.yml</code> or run <code>$ export DOCKER_VOLUME_DIRECTORY=</code>.
</div>

#### Start Milvus

```shell
$ docker-compose up -d
```

```text
Docker Compose is now in the Docker CLI, try `docker compose up`
Creating milvus-etcd  ... done
Creating milvus-minio ... done
Creating milvus-standalone ... done
```


Check the status of the containers.
```
$ sudo docker-compose ps
```

After Milvus standalone starts, three running docker containers appear including two dependencies and one Milvus service. 
```
      Name                     Command                  State                          Ports
----------------------------------------------------------------------------------------------------------------
milvus-etcd         etcd -listen-peer-urls=htt ...   Up (healthy)   2379/tcp, 2380/tcp
milvus-minio        /usr/bin/docker-entrypoint ...   Up (healthy)   9000/tcp
milvus-standalone   /tini -- milvus run standalone   Up             0.0.0.0:19530->19530/tcp,:::19530->19530/tcp
```

#### Stop Milvus

To stop Milvus standalone, run <code>$ sudo docker-compose down</code>.

To delete data after stopping Milvus, run <code>$ sudo rm -rf  volumes</code>.

#### What's next

Having installed Milvus, you can:

- Check [Hello Milvus](example_code.md) to run an example code with different SDKs to see what Milvus can do.

- Learn the basic operations of Milvus:
  - [Connect to Milvus server](connect.md)
  - [Conduct a vector search](search.md)
  - [Conduct a hybrid search](hybridsearch.md)

- Explore [MilvusDM](migrate_overview.md), an open-source tool designed for importing and exporting data in Milvus.
- [Monitor Milvus with Prometheus](monitor.md).

### Milvus Cluster ###


#### Install Milvus Cluster

This topic describes how to install Milvus cluster with Docker Compose or on Kubernetes. 

[Check the requirements for hardware and software](prerequisite-docker.md) prior to your installation. 

If you run into image loading errors while installing, you can [Install Milvus Offline](install_offline-docker.md).

You can also build Milvus from source code at [GitHub](https://github.com/milvus-io/milvus#to-start-developing-milvus).


<div class="tab-wrapper"><a href="install_cluster-docker.md" class='active '>Docker Compose</a><a href="install_cluster-helm.md" class=''>Helm</a><a href="install_cluster-milvusoperator.md" class=''>Milvus Operator</a></div>


#### Download an installation file

[Download](https://github.com/milvus-io/milvus/releases/download/v2.0.0-rc8/milvus-cluster-docker-compose.yml) `milvus-cluster-docker-compose.yml` directly or with the following command, and save it as `docker-compose.yml`.

```
$ wget https://github.com/milvus-io/milvus/releases/download/v2.0.0-rc8/milvus-cluster-docker-compose.yml -O docker-compose.yml
```

#### Configure Milvus (optional)

[Download](https://raw.githubusercontent.com/milvus-io/milvus/v2.0.0-rc8/configs/milvus.yaml) `milvus.yaml` directly or with the following command. 

```
$ wget https://raw.githubusercontent.com/milvus-io/milvus/v2.0.0-rc8/configs/milvus.yaml
```

Modify the configurations to suit your needs. See [Milvus Cluster System Configurations](configuration_cluster-basic.md) for more information.

In `docker-compose.yml`, add a `volumes` section under each Milvus component, i.e. root coord, data coord, data node, query coord, query node, index coord, index node, and proxy. 

Map the local path to your `milvus.yaml` file onto the corresponding docker container paths to the configuration files `/milvus/configs/milvus.yaml` under all `volumes` sections.

```yaml
...
proxy:
    container_name: milvus-proxy
    image: milvusdb/milvus:v2.0.0-rc7-20211011-d567b21
    command: ["milvus", "run", "proxy"]
    volumes:       #### Add a volumes section.
      - /local/path/to/your/file:/milvus/configs/milvus.yaml   #### Map the local path to the container path
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
      PULSAR_ADDRESS: pulsar://pulsar:6650
    ports:
      - "19530:19530"
...
```

<div class="alert note">
Data is stored in the <code>/volumes</code> folder according to the default configuration in <code>docker-compose.yml</code>. To change the folder to store data, edit <code>docker-compose.yml</code> or run <code>$ export DOCKER_VOLUME_DIRECTORY=</code>.
</div>

#### Start Milvus

```Shell
$ docker-compose up -d
```

```Text
Docker Compose is now in the Docker CLI, try `docker compose up`
Creating milvus-etcd   ... done
Creating milvus-minio  ... done
Creating milvus-pulsar ... done
Creating milvus-proxy      ... done
Creating milvus-rootcoord  ... done
Creating milvus-indexcoord ... done
Creating milvus-querycoord ... done
Creating milvus-datacoord  ... done
Creating milvus-querynode  ... done
Creating milvus-indexnode  ... done
Creating milvus-datanode   ... done
```

Check the status of the containers.

```
$ sudo docker ps
```
After Milvus cluster starts, 11 running docker containers appear including three dependencies and eight Milvus services.
```
      Name                     Command                  State                          Ports
----------------------------------------------------------------------------------------------------------------
milvus-datacoord    /tini -- milvus run datacoord    Up
milvus-datanode     /tini -- milvus run datanode     Up
milvus-etcd         etcd -listen-peer-urls=htt ...   Up (healthy)   2379/tcp, 2380/tcp
milvus-indexcoord   /tini -- milvus run indexcoord   Up
milvus-indexnode    /tini -- milvus run indexnode    Up
milvus-minio        /usr/bin/docker-entrypoint ...   Up (healthy)   9000/tcp
milvus-proxy        /tini -- milvus run proxy        Up             0.0.0.0:19530->19530/tcp,:::19530->19530/tcp
milvus-pulsar       bin/pulsar standalone            Up
milvus-querycoord   /tini -- milvus run querycoord   Up
milvus-querynode    /tini -- milvus run querynode    Up
milvus-rootcoord    /tini -- milvus run rootcoord    Up
```

#### Stop Milvus

To stop Milvus cluster, run <code>$ sudo docker-compose down</code>.

To delete data after stopping Milvus, run <code>$ sudo rm -rf  volumes</code>.

#### What's next

Having installed Milvus, you can:

- Check [Hello Milvus](example_code.md) to run an example code with different SDKs to see what Milvus can do.

- Learn the basic operations of Milvus:
  - [Connect to Milvus server](connect.md)
  - [Conduct a vector search](search.md)
  - [Conduct a hybrid search](hybridsearch.md)

- Explore [MilvusDM](migrate_overview.md), an open-source tool designed for importing and exporting data in Milvus.
- [Monitor Milvus with Prometheus](monitor.md).

### Install Offline ###


#### Install Milvus Offline

This topic describes how to install Milvus in an offline environment. 

Installation of Milvus might fail due to image loading errors. You can install Milvus in an offline environment to avoid such problem.

<div class="tab-wrapper"><a href="install_offline-docker.md" class='active '>Install with Docker Compose</a><a href="install_offline-helm.md" class=''>Install on Kubernetes</a></div>

#### Download files and images

To install Milvus offline, you need to pull and save all images in an online environment first, and then transfer them to the target host and load them manually.

1. Download an installation file.

- For Milvus standalone:

```
$ wget https://github.com/milvus-io/milvus/releases/download/v2.0.0-rc8/milvus-standalone-docker-compose.yml -O docker-compose.yml

```

- For Milvus cluster:

```
$ wget https://github.com/milvus-io/milvus/releases/download/v2.0.0-rc8/milvus-cluster-docker-compose.yml -O docker-compose.yml

```

2. Download requirement and script files.

```
$ wget https://raw.githubusercontent.com/milvus-io/milvus/master/deployments/offline/requirements.txt
$ wget https://raw.githubusercontent.com/milvus-io/milvus/master/deployments/offline/save_image.py
```

3. Pull and save images.

```bash
pip3 install -r requirements.txt
python3 save_image.py --manifest docker-compose.yml
```

<div class="alert note">
  The images are stored in the <code>/images</code> folder.
  </div>


4. Load the images.

```bash
cd images/for image in $(find . -type f -name "*.tar.gz") ; do gunzip -c $image | docker load; done
```

#### Install Milvus offline

Having transferred the images to the target host, run the following command to install Milvus offline.

```bash
docker-compose -f docker-compose.yml up -d
```

#### Uninstall Milvus

To uninstall Milvus, run the following command.

```bash
docker-compose -f docker-compose.yml down
```

#### What's next

Having installed Milvus, you can:

- Check [Hello Milvus](example_code.md) to run an example code with different SDKs to see what Milvus can do.

- Learn the basic operations of Milvus:
  - [Connect to Milvus server](connect.md)
  - [Conduct a vector search](search.md)
  - [Conduct a hybrid search](hybridsearch.md)

- [Scale your Milvus cluster](scaleout.md).
- Explore [MilvusDM](migrate_overview.md), an open-source tool designed for importing and exporting data in Milvus.
- [Monitor Milvus with Prometheus](monitor.md).

## Install SDKs ##


#### Install Milvus SDK

This topic describes how to install Milvus SDK for Milvus.

Current version of Milvus supports SDKs in Python and Node.js.

<div class="tab-wrapper"><a href="install-pymilvus.md" class='active '>Install PyMilvus</a><a href="install-node.md" class=''>Install Node.js SDK</a></div>

#### Requirement

Python 3 (3.6 or later) is required.

#### Install PyMilvus via pip

PyMilvus is available in [Python Package Index](https://pypi.org/project/pymilvus/).

<div class="alert note">
It is recommended to install a PyMilvus version that matches the version of the Milvus server you installed. For example, install PyMilvus v2.0.0rc7 for Milvus 2.0.0-RC7.
</div>

```
$ python3 -m pip install pymilvus==2.0.0rc8
```

#### Verify installation

If PyMilvus is correctly installed, no exception will be raised when you run the following command.

```
$ python -c "from pymilvus import Collection"
```



#### What's next

Having installed PyMilvus, you can:

- Learn the basic operations of Milvus:
  - [Connect to Milvus server](connect.md)
  - [Conduct a vector search](search.md)
  - [Conduct a hybrid search](hybridsearch.md)

- Explore [PyMilvus API reference](/api-reference/pymilvus/v2.0.0rc8/tutorial.html)

## Hello Milvus ##


<div class="tab-wrapper"><a href="example_code.md" class='active '>Python</a><a href="example_code_node.md" class=''>Node.js</a></div>

#### Run Milvus using Python

This topic describes how to run Milvus using Python.

#### 1. Install PyMilvus

```Python
pip3 install pymilvus==2.0.0rc8
```
<div class="alert note">
Python 3.6 or later is required. See <a href="https://wiki.python.org/moin/BeginnersGuide/Download">Downloading Python</a> for more information.
</div>

#### 2. Download sample code

```Python
$ wget https://raw.githubusercontent.com/milvus-io/pymilvus/v2.0.0rc8/examples/hello_milvus.py
```

#### 3. Scan the sample
The sample code performs the following steps.

- Imports a PyMilvus package:
```Python
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection
```

- Connects to a server:
```Python
connections.connect(host='localhost', port='19530')
```

- Creates a collection:
```Python
dim = 128
default_fields = [
    FieldSchema(name="count", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="random_value", dtype=DataType.DOUBLE),
    FieldSchema(name="float_vector", dtype=DataType.FLOAT_VECTOR, dim=dim)
]
default_schema = CollectionSchema(fields=default_fields, description="test collection")

print(f"\nCreate collection...")
collection = Collection(name="hello_milvus", schema=default_schema)
```

- Inserts vectors in the collection:
```Python
import random
nb = 3000
vectors = [[random.random() for _ in range(dim)] for _ in range(nb)]
collection.insert(
    [
        [i for i in range(nb)],
        [float(random.randrange(-20,-10)) for _ in range(nb)],
        vectors
    ]
)
```

- Builds indexes and loads the collection:
```Python
default_index = {"index_type": "IVF_FLAT", "params": {"nlist": 128}, "metric_type": "L2"}
collection.create_index(field_name="float_vector", index_params=default_index)
collection.load()
```

- Performs a vector similarity search:
```Python
topK = 5
search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
#### define output_fields of search result
res = collection.search(
    vectors[-2:], "float_vector", search_params, topK,
    "count > 100", output_fields=["count", "random_value"]
)
```
To print the search results by ID and distance, run the following command.
```Python
for raw_result in res:
    for result in raw_result:
        id = result.id  #### result id
        distance = result.distance
        print(id, distance)
```
See [API Reference](/api-reference/pymilvus/v2.0.0rc8/results.html) for more information.

- Performs a hybrid search：
<div class="alert note">
    The following example performs an approximate search on entities with <code>film_id</code> ranged in [2,4,6,8].
    </div>

```Python
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType
>>> import random
>>> connections.connect()
>>> schema = CollectionSchema([
...     FieldSchema("film_id", DataType.INT64, is_primary=True),
...     FieldSchema("films", dtype=DataType.FLOAT_VECTOR, dim=2)
... ])
>>> collection = Collection("test_collection_search", schema)
>>> #### insert
>>> data = [
...     [i for i in range(10)],
...     [[random.random() for _ in range(2)] for _ in range(10)],
... ]
>>> collection.insert(data)
>>> collection.num_entities
10
>>> collection.load()
>>> #### search
>>> search_param = {
...     "data": [[1.0, 1.0]],
...     "anns_field": "films",
...     "param": {"metric_type": "L2"},
...     "limit": 2,
...     "expr": "film_id in [2,4,6,8]",
... }
>>> res = collection.search(**search_param)
>>> assert len(res) == 1
>>> hits = res[0]
>>> assert len(hits) == 2
>>> print(f"- Total hits: {len(hits)}, hits ids: {hits.ids} ")
- Total hits: 2, hits ids: [2, 4]
>>> print(f"- Top1 hit id: {hits[0].id}, distance: {hits[0].distance}, score: {hits[0].score} ")
- Top1 hit id: 2, distance: 0.10143111646175385, score: 0.101431116461

```

#### 4. Run the sample
```Python
$ python3 hello_milvus.py
```

*The returned results and query latency are shown as follows:*

<div class='result-bock'>
<p>Search...</p>
<p>(distance: 0.0, id: 2998) -20.0</p>
<p>(distance: 13.2614107131958, id: 989) -11.0</p>
<p>(distance: 14.489648818969727, id: 1763) -19.0</p>
<p>(distance: 15.295698165893555, id: 968) -20.0</p>
<p>(distance: 15.34445571899414, id: 2049) -19.0</p>
<p>(distance: 0.0, id: 2999) -12.0</p>
<p>(distance: 14.63361930847168, id: 1259) -13.0</p>
<p>(distance: 15.421361923217773, id: 2530) -15.0</p>
<p>(distance: 15.427900314331055, id: 600) -14.0</p>
<p>(distance: 15.538337707519531, id: 637) -19.0</p>
<p>search latency = 0.0549s</p>
</div>


<br/>


*Congratulations! You have started Milvus standalone and performed your first vector similarity search.*


# User Guide #
## Connect to Milvus Server ##



This topic describes how to connect to and disconnect from a Milvus server.

If you choose to operate in the Python interactive mode, type `python3` in your terminal.
 
<div class="alert note">
Parameters marked with <code>*</code> are specific to Python SDK, and those marked with <code>**</code> are specific to Node.js SDK.
</div>

#### Connect to the Milvus server

Construct a Milvus connection and register it under given alias.

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> from pymilvus import connections
>>> connections.connect("default", host='localhost', port='19530')
```

```javascript
import { MilvusClient } from "@zilliz/milvus2-sdk-node";
const milvusClient = new MilvusClient("localhost:19530");
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td><code>alias*</code></td>
		<td>Alias for the Milvus server</td>
    <td>Data type: String<br/>Mandatory</td>
	</tr>
	<tr>
		<td><code>host*</code></td>
		<td>IP address of the Milvus server</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td><code>port*</code></td>
		<td>Port of the Milvus server</td>
		<td>Mandatory</td>
	</tr>
    <tr>
		<td><code>address**</code></td>
		<td>Address of the Milvus server</td>
		<td><code>"server_IP:server_port"</code><br/>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

#### Disconnect from the Milvus server

When you no longer need Milvus services, you can disconnect from Milvus server:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> connections.disconnect("default")
```


```javascript
await milvusClient.closeConnection();
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>alias*</td>
		<td>Alias for the Milvus server</td>
		<td>Data type: String<br/>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>


## Create a Collection or Partition ##



This topic describes how to create a collection or a partition in Milvus.

<div class="alert note">
Parameters marked with <code>*</code> are specific to Python SDK, and those marked with <code>**</code> are specific to Node.js SDK.
</div>

#### Create a collection

Collections can only be created after successfully connecting to the Milvus server.

<div class="alert note">
The created collection must contain a primary key field. Int64 is the only supported data type for the primary key field for now.
</div>

1. Prepare collection parameters, including collection name and field parameters. Refer to API documents for respective languages for a detailed description of these parameters.

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
collection_name = "example_collection"
field_name = "example_field"
from pymilvus import Collection, CollectionSchema, FieldSchema, DataType
pk = FieldSchema(name="pk", dtype=DataType.INT64, is_primary=True, auto_id=True)
field = FieldSchema(name=field_name, dtype=DataType.FLOAT_VECTOR, dim=8)
schema = CollectionSchema(fields=[pk,field], description="example collection")
```

```javascript
const COLLECTION_NAME = "example_collection";
const FIELD_NAME = "example_field";

const params = {
  collection_name: COLLECTION_NAME,
  fields: [
    {
      name: FIELD_NAME,
      description: "vector field",
      data_type: DataType.FloatVector,

      type_params: {
        dim: "8",
      },
    },
    {
      name: "age",
      data_type: DataType.Int64,
      autoID: true,
      is_primary_key: true,
      description: "",
    },
  ],
};
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</th>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td><code>collection_name</code></td>
		<td>Name of the collection to create</td>
		<td>Data type: String</td>
	</tr>
	<tr>
		<td><code>field_name</code></td>
		<td>Name of the field in the collection</td>
		<td>Data type: String</td>
	</tr>
	<tr>
		<td><code>Schema</code></td>
		<td>Schema used to create a collection and the fields within. Refer to <a href="field_schema.md">field schema</a> and <a href="collection_schema.md">collection schema</a> for detailed description</td>
		<td>&nbsp;</td>
	</tr>
	<tr>
		<td><code>description</code></td>
		<td>Description of the collection</td>
		<td>Data type: String</td>
	</tr>
	</tbody>
</table>
</details>

2. Create a collection:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection = Collection(name=collection_name, schema=schema, using='default', shards_num=2)

#### Get an existing collection by its name.
collection=Collection(name=collection_name)
```

```javascript
await milvusClient.collectionManager.createCollection(params);
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</th>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>using*</td>

		<td>By specifying the server alias here, you can decide in which Milvus server you create a collection.</td>
		<td>Optional</td>
	</tr>
	<tr>
		<td>shards_num*</td>
		<td>Number of the shards for the collection to create</td>
		<td>Optional</td>
	</tr>
	</tbody>
</table>
</details>

3. Check if the collection is created successfully:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> import pymilvus
>>> pymilvus.utility.get_connection().has_collection(collection_name)
True
```

```javascript
await milvusClient.collectionManager.hasCollection({
  collection_name: COLLECTION_NAME,
});
```

4. List all created collections:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> pymilvus.utility.get_connection().list_collections()
['example_collection']
```

```javascript
await milvusClient.collectionManager.showCollections();
```

5. View collection statistics, such as row count:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.num_entities
0
```

```javascript
await milvusClient.collectionManager.getCollectionStatistics({
  collection_name: COLLECTION_NAME,
});
```

#### Create a partition

Search performance worsens as more vectors are inserted into the collection. To help mitigate declining search performance, consider creating collection partitions. Partitioning is a way to separate data. Partition names narrow a search to a specific number of vectors, improving query performance. To improve search efficiency, divide a collection into several partitions by name.

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> partition_name = "example_partition"
>>> partition = collection.create_partition(partition_name)
```

```javascript
await milvusClient.partitionManager.createPartition({
  collection_name: COLLECTION_NAME,
  partition_name: "example_partition",
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</th>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>partition_name</td>
		<td>Name of the partition to create</td>
		<td>Data type: String</td>
	</tr>
	</tbody>
</table>
</details>

Milvus creates a default partition name, `_default`, for new collections. After creating a partition, you have two partition names, `example_partition` and `_default`.

List all partitions in a collection:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.partitions
[{"name": "_default", "description": "", "num_entities": 0}, {"name": "example_partition", "description": "", "num_entities": 0}]
```

```javascript
await milvusClient.partitionManager.showPartitions({
  collection_name: COLLECTION_NAME,
});
```

Check if a partition is successfully created:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.has_partition(partition_name)
True
```

```javascript
await milvusClient.partitionManager.hasPartition({
  collection_name: COLLECTION_NAME,
  partition_name: "example_partition",
});
```

## Insert Data ##


#### Insert Vectors

This topic describes how to insert vectors into a collection or partition.

<div class="alert note">
Parameters marked with <code>*</code> are specific to Python SDK, and those marked with <code>**</code> are specific to Node.js SDK.
</div>

1. Generate random vectors:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> import random
>>> vectors = [[random.random() for _ in range(8)] for _ in range(10)]
>>> entities = [vectors]
```

```javascript
const entities = Array.from({ length: 10 }, () => ({
  [FIELD_NAME]: Array.from({ length: 8 }, () => Math.floor(Math.random() * 10)),
}));
```

2. Insert the random vectors to the newly created collection. Milvus automatically assigns IDs to the inserted vectors, similar to AutoID in a relational database.

_Milvus returns the value of MutationResult, which contains the corresponding primary_keys of the inserted vectors._

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> mr = collection.insert(entities)
#### Get the primary keys of the `MutationResult`
>>> mr.primary_keys
[425790736918318406, 425790736918318407, 425790736918318408, ...]
```

```javascript
await milvusClient.dataManager.insert({{
  collection_name: COLLECTION_NAME,
  fields_data: entities,
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td><code>data</code></td>
		<td>Data to insert into Milvus</td>
		<td>Mandatory</td>
	</tr>
 	<tr>
		<td><code>collection_name**</code></td>
		<td>Name of the collection to insert data into</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td><code>partition_name</code></td>
		<td>Name of the partition to insert data into</td>
		<td>Optional</td>
	</tr>
	</tbody>
</table>
</details>

3. By specifying `partition_name` when inserting, you can insert vectors to a specified partition:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.insert(data=entities, partition_name=partition_name)
```

```javascript
await milvusClient.dataManager.insert({{
  collection_name: COLLECTION_NAME,
  partition_name: partition_name
  fields_data: entities,
});
```

4. Milvus temporarily stores the inserted vectors in the memory. To flush them to the disk, run:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> pymilvus.utility.get_connection().flush([collection_name])
```

```javascript
await milvusClient.dataManager.flush({ collection_names: [COLLECTION_NAME] });
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
 	<tr>
		<td>collection_name</td>
		<td>Name of the collection to flush</td>
		<td>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>


## Build an Index ##



This topic describes how to build an index for a field. See [Vector Index](index.md) for more information about setting index parameters.

<div class="alert note">
Parameters marked with <code>*</code> are specific to Python SDK, and those marked with <code>**</code> are specific to Node.js SDK.
</div>

1. Prepare the index parameters:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> index_param = {
        "metric_type":"L2",
        "index_type":"IVF_FLAT",
        "params":{"nlist":1024}
    }
```

```javascript
const index_param = {
  metric_type: "L2",
  index_type: "IVF_FLAT",
  params: JSON.stringify({ nlist: 1024 }),
};
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td><code>metric_type</code></td>
		<td>Metrics used to measure similarity of vectors</td>
		<td>Find more options in <a href="metric.md">Simlarity Metrics</a>.<br/>Mandatory</td>
	</tr>
	<tr>
		<td><code>index_type</code></td>
		<td>Type of index used to accelerate the vector search</td>
		<td>Find more options in <a href="index_selection.md">Index Selection</a>.<br/>Mandatory</td>
	</tr>
	<tr>
		<td><code>params</code></td>
		<td>Building parameter(s) specific to the index</td>
		<td>Find more parameter details of different indexes in <a href="index_selection.md">Index Selection</a>.<br/>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

2. Build an index:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.create_index(field_name=field_name, index_params=index_param)
Status(code=0, message='')
```

```javascript
await milvusClient.indexManager.createIndex({
  collection_name: COLLECTION_NAME,
  field_name: FIELD_NAME,
  extra_params: index_param,
});
```

3. View index details:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.index().params
{'metric_type': 'L2', 'index_type': 'IVF_FLAT', 'params': {'nlist': 1024}}
```

```javascript
await milvusClient.indexManager.describeIndex({
  collection_name: COLLECTION_NAME,
});
```

## Drop Collection/Partition/Index ##


#### Drop Operations

This topic describes how to drop an index, a partition, or a collection.

The drop operations affect data already inserted into Milvus. Think twice before you delete.

<div class="alert note">
Parameters marked with <code>*</code> are specific to Python SDK, and those marked with <code>**</code> are specific to Node.js SDK.
</div>

#### Drop an index

Drop the index of a specified field in a specified collection:

<div class="alert note">
Current release of Milvus only supports building and dropping index on vector field. Future version of Milvus will supports these operations on scalar field.
</div>

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.drop_index()
```

```javascript
await milvusClient.indexManager.dropIndex({
  collection_name: COLLECTION_NAME,
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td><code>collection_name**</code></td>
		<td>Name of the collection to drop index from</td>
		<td>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

#### Drop a partition

Remove a partition and all vectors under it:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.drop_partition(partition_name=partition_name)
```

```javascript
await milvusClient.partitionManager.dropPartition({
  collection_name: COLLECTION_NAME,
  partition_name: PARTITION_NAME,
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
 	<tr>
		<td>partition_name</td>
		<td>Name of the partition to drop</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td>collection_name**</td>
		<td>Name of the collection to drop partition from</td>
		<td>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

#### Drop a collection

When you no longer need a collection, you can delete it.

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.drop()
```

```javascript
await milvusClient.collectionManager.dropCollection({
  collection_name: COLLECTION_NAME,
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>collection_name**</td>
		<td>Name of the collection to drop</td>
		<td>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

## Delete an Entity ##



<div class="alert note">
This feature is still under development and will be available when a stable version of Milvus 2.0 is released.
</div>

## Search and Query ##
### Search ###


#### Audio Similarity Search

This tutorial demonstrates how to use Milvus, the open-source vector database to build an audio similarity search system.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/audio_similarity_search/audio_similarity_search.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/audio_similarity_search/quick_deploy)
The ML model and third-party software used include:
- PANNs (Large-Scale Pretrained Audio Neural Networks)
- MySQL

</br>

Speech, music, sound effects, and other types of audio search makes it possible to quickly query massive volumes of audio data and surface similar sounds. Applications of audio similarity search systems include identifying similar sound effects, minimizing IP infringement, and more. Audio retrieval can be used to search and monitor online media in real-time to crack down on infringement of intellectual property rights. It also assumes an important role in the classification and statistical analysis of audio data.

</br>

In this tutorial, you will learn how to build an audio similarity search system that can return similar sound clips. The uploaded audio clips are converted into vectors using PANNs. These vectors are stored in Milvus which automatically generates a unique ID for each vector. Then users can conduct a vector similarity search in Milvus and query the audio clip data path corresponding to th unique vector ID returned by Milvus.

<br/>

![Audio_search](../../../assets/audio_search.png)
![Audio_search_demo](../../../assets/audio_search_demo.png)

### Hybrid Search ###


#### Conduct a Hybrid Search

This topic describes how to conduct a hybrid search.

In addition to vectors, Milvus supports data types such as boolean, integers, floating-point numbers, and more. A collection in Milvus can hold multiple fields for accommodating different data features or properties. Milvus is a flexible vector database that pairs scalar filtering with powerful vector similarity search.

<div class="alert note">
Parameters marked with <code>*</code> are specific to Python SDK, and those marked with <code>**</code> are specific to Node.js SDK.
</div>

A hybrid search is a vector similarity search, during which you can filter the scalar data by specifying a [boolean expression](boolean.md).

1. Connect to the Milvus server:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
from pymilvus import connections
connections.connect("default", host='localhost', port='19530')
```

```javascript
import { MilvusClient } from "@zilliz/milvus2-sdk-node";
const milvusClient = new MilvusClient("localhost:19530");
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td><code>alias*</code></td>
		<td>Alias for the Milvus server</td>
    <td>Data type: String<br/>Mandatory</td>
	</tr>
	<tr>
		<td><code>host*</code></td>
		<td>IP address of the Milvus server</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td><code>port*</code></td>
		<td>Port of the Milvus server</td>
		<td>Mandatory</td>
	</tr>
    <tr>
		<td><code>address**</code></td>
		<td>Address of the Milvus server</td>
		<td><code>"server_IP:server_port"</code><br/>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

2. Prepare collection parameters and create a collection:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> from pymilvus import Collection, FieldSchema, CollectionSchema, DataType
>>> collection_name = "test_collection_search"
>>> schema = CollectionSchema([
...     FieldSchema("film_id", DataType.INT64, is_primary=True),
...     FieldSchema("films", dtype=DataType.FLOAT_VECTOR, dim=2)
... ])
>>> collection = Collection(collection_name, schema, using='default', shards_num=2)
```

```javascript
const COLLECTION_NAME = "test_collection_search";
milvusClient.collectionManager.createCollection({
  collection_name: COLLECTION_NAME,
  fields: [
    {
      name: "films",
      description: "vector field",
      data_type: DataType.FloatVector,
      type_params: {
        dim: "2",
      },
    },
    {
      name: "film_id",
      data_type: DataType.Int64,
      autoID: false,
      is_primary_key: true,
      description: "",
    },
  ],
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>collection_name</td>
		<td>Name of the collection to create</td>
		<td>Data type: String</td>
	</tr>
	<tr>
		<td>field_name</td>
		<td>Name of the field in the collection</td>
		<td>Data type: String</td>
	</tr>
	<tr>
		<td>Schema</td>
		<td>Schema used to create a collection and the fields within. Refer to <a href="field_schema.md">field schema</a> and <a href="collection_schema.md">collection schema</a> for detailed description</td>
		<td>&nbsp;</td>
	</tr>
	<tr>
		<td>description</td>
		<td>Description of the collection</td>
		<td>Data type: String</td>
	</tr>
  	<tr>
		<td>using*</td>
		<td>By specifying the srever alias here, you can decide in which Milvus server you create a collection</td>
		<td>Optional</td>
	</tr>
	<tr>
		<td>shards_num*</td>
		<td>Number of the shards for the collection to create</td>
		<td>Optional</td>
	</tr>
	</tbody>
</table>
</details>

3. Insert random vectors to the newly created collection:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> import random
>>> data = [
...     [i for i in range(10)],
...     [[random.random() for _ in range(2)] for _ in range(10)],
... ]
>>> collection.insert(data)
>>> collection.num_entities
10
```

```javascript
let id = 1;
const entities = Array.from({ length: 10 }, () => ({
  films: Array.from({ length: 2 }, () => Math.random() * 10),
  film_id: id++,
}));

await milvusClient.collectionManager.insert({
  collection_name: COLLECTION_NAME,
  fields_data: entities,
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>data</td>
		<td>Data to insert into Milvus</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td>partition_name</td>
		<td>Name of the partition to insert data into</td>
		<td>Optional</td>
	</tr>
	<tr>
		<td>timeout*</td>
		<td>Timeout (in seconds) to allow for RPC. Clients wait until server responds or error occurs when it is set to None</td>
		<td>Optional</td>
	</tr>
	</tbody>
</table>
</details>

4. Load the collection to memory and conduct a vector similarity search:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.load()
>>> search_param = {
...     "data": [[1.0, 1.0]],
...     "anns_field": "films",
...     "param": {"metric_type": "L2"},
...     "limit": 2,
...     "expr": "film_id in [2,4,6,8]",
... }
>>> res = collection.search(**search_param)
```

```javascript
await milvusClient.collectionManager.loadCollection({
  collection_name: COLLECTION_NAME,
});
await milvusClient.dataManager.search({
  collection_name: COLLECTION_NAME,
  // partition_names: [],
  expr: "film_id in [1,4,6,8]",
  vectors: [entities[0].films],
  search_params: {
    anns_field: "films",
    topk: "4",
    metric_type: "L2",
    params: JSON.stringify({ nprobe: 10 }),
  },
  vector_type: 100, // float vector -> 100
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>collection_name**</td>
		<td>Name of the collection to load and search</td>
		<td>Mandatory</td>
	</tr>
    <tr>
		<td>vectors</td>
		<td>Vectors to search with. Length of the data represents the number of query <code>nq</code>.</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td>anns_field</td>
		<td>Name of the field to search on</td>
		<td>Mandatory</td>
	</tr>
    <tr>
		<td>params*</td>
		<td>Search parameter(s) specific to the index</td>
		<td>Find more parameter details of different indexes in <a href="index_selection.md">Index Selection</a>.<br/>Mandatory</td>
	<tr>
		<td>limit*</td>
		<td>Number of the most similar results to return</td>
		<td>Mandatory</td>
	</tr>
  <tr>
		<td>expr</td>
		<td>Boolean expression used to filter attribute</td>
		<td>Find more expression details in <a href="boolean.md">Boolean Expression Rules</a>.<br/>Optional</td>
	</tr>
  <tr>
		<td>partition_names</td>
		<td>Name of the partition to search on</td>
		<td>Optional</td>
	</tr>
  <tr>
		<td>output_fields</td>
		<td>Name of the field to return (vector field not support in current release)</td>
		<td>Optional</td>
	</tr>
  <tr>
		<td>timeout*</td>
		<td>Timeout (in seconds) to allow for RPC. Clients wait until server responds or error occurs when it is set to None</td>
		<td>Optional</td>
	</tr>
  <tr>
		<td>vector_type**</td>
		<td>Pre-check of binary/float vectors. <code>100</code> for binary vectors and <code>101</code> for float vectors</td>
		<td>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

<div class="alert warning">
In current release, data to be load must be under 70% of the total memory resources of all query nodes to reserve memory resources for execution engine.
</div>

5. Check the returned results:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> assert len(res) == 1>>> hits = res[0]>>> assert len(hits) == 2>>> print(f"- Total hits: {len(hits)}, hits ids: {hits.ids} ")- Total hits: 2, hits ids: [2, 4]>>> print(f"- Top1 hit id: {hits[0].id}, distance: {hits[0].distance}, score: {hits[0].score} ")- Top1 hit id: 2, distance: 0.10143111646175385, score: 0.101431116461
```

```javascript
// search result will be like:{  status: { error_code: 'Success', reason: '' },  results: [    { score: 0, id: '1' },    { score: 9.266796112060547, id: '4' },    { score: 28.263811111450195, id: '8' },    { score: 41.055686950683594, id: '6' }  ]}
```

### Query ###



This topic describes how to conduct a query.

In addition to vectors, Milvus supports data types such as boolean, integers, floating-point numbers, and more.

A query is a search on all existing data. In Milvus, you can run a query which will return all the results that meet your specified requirements. Use [boolean expression](boolean.md) to specify the requirements.

<div class="alert note">
Parameters marked with <code>*</code> are specific to Python SDK, and those marked with <code>**</code> are specific to Node.js SDK.
</div>

1. Connect to the Milvus server:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> from pymilvus import connections
>>> connections.connect("default", host='localhost', port='19530')
```

```javascript
import { MilvusClient } from "@zilliz/milvus2-sdk-node";
const milvusClient = new MilvusClient("localhost:19530");
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td><code>alias*</code></td>
		<td>Alias for the Milvus server</td>
    <td>Data type: String<br/>Mandatory</td>
	</tr>
	<tr>
		<td><code>host*</code></td>
		<td>IP address of the Milvus server</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td><code>port*</code></td>
		<td>Port of the Milvus server</td>
		<td>Mandatory</td>
	</tr>
    <tr>
		<td><code>address**</code></td>
		<td>Address of the Milvus server.</td>
		<td><code>"server_IP:server_port"</code><br/>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

2. Prepare collection parameters and create a collection:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> from pymilvus import Collection, FieldSchema, CollectionSchema, DataType
>>> collection_name = "test_collection_search"
>>> schema = CollectionSchema([
...     FieldSchema("film_id", DataType.INT64, is_primary=True),
...     FieldSchema("film_date", DataType.INT64),
...     FieldSchema("films", dtype=DataType.FLOAT_VECTOR, dim=2)
... ])
>>> collection = Collection(collection_name, schema, using='default', shards_num=2)
```

```javascript
const COLLECTION_NAME = "example_collection";
const FIELD_NAME = "example_field";

const params = {
  collection_name: COLLECTION_NAME,
  fields: [
    {
      name: "films",
      description: "vector field",
      data_type: DataType.FloatVector,

      type_params: {
        dim: "8",
      },
    },
    {
      name: "film_id",
      data_type: DataType.Int64,
      autoID: false,
      is_primary_key: true,
      description: "",
    },
  ],
};

await milvusClient.collectionManager.createCollection(params);
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>collection_name</td>
		<td>Name of the collection to create</td>
		<td>Data type: String</td>
	</tr>
	<tr>
		<td>field_name</td>
		<td>Name of the field in the collection</td>
		<td>Data type: String</td>
	</tr>
	<tr>
		<td>Schema</td>
		<td>Schema used to create a collection and the fields within. Refer to <a href="field_schema.md">field schema</a> and <a href="collection_schema.md">collection schema</a> for detailed description. </td>
		<td>&nbsp;</td>
	</tr>
	<tr>
		<td>description</td>
		<td>Description of the collection</td>
		<td>Data type: String</td>
	</tr>
  	<tr>
		<td>using*</td>
		<td>By specifying the srever alias here, you can decide in which Milvus server you create a collection.</td>
		<td>Optional</td>
	</tr>
	<tr>
		<td>shards_num*</td>
		<td>Number of the shards for the collection to create</td>
		<td>Optional</td>
	</tr>
	</tbody>
</table>
</details>

3. Insert random vectors to the newly created collection:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> import random
>>> data = [
...     [i for i in range(10)],
...     [1990 + i for i in range(10)],
...     [[random.random() for _ in range(2)] for _ in range(10)],
... ]
>>> collection.insert(data)
>>> collection.num_entities
10
```

```javascript
let id = 1;
const entities = Array.from({ length: 10 }, () => ({
  films: Array.from({ length: 2 }, () => Math.random() * 10),
  film_id: id++,
}));

await milvusClient.dataManager.insert({{
  collection_name: COLLECTION_NAME,
  fields_data: entities,
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>data</td>
		<td>Data to insert into Milvus</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td>partition_name</td>
		<td>Name of the partition to insert data into</td>
		<td>Optional</td>
	</tr>
	<tr>
		<td>timeout*</td>
		<td>Timeout (in seconds) to allow for RPC. Clients wait until server responds or error occurs when it is set to None.</td>
		<td>Optional</td>
	</tr>
	</tbody>
</table>
</details>

4. Load the collection to memory and run a query:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> collection.load()
>>> expr = "film_id in [2,4,6,8]"
>>> output_fields = ["film_id", "film_date"]
>>> res = collection.query(expr, output_fields)
```

```javascript
await milvusClient.collectionManager.loadCollection({
  collection_name: COLLECTION_NAME,
});

await milvusClient.dataManager.query({
  collection_name: COLLECTION_NAME,
  expr: "film_id in [2,4,6,8]",
  output_fields: ["film_id"],
});
```

<details>
  <summary><b>Detailed Description</b></summary>
<table class="params">
	<thead>
	<tr>
		<th>Parameter</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>collection_name**</td>
		<td>Name of the collection to load and query</td>
		<td>Mandatory</td>
	</tr>
	<tr>
		<td>expr</td>
		<td>Boolean expression used to filter attribute</td>
		<td>Find more expression details in <a href="boolean.md">Boolean Expression Rules</a>.<br/>Optional</td>
	</tr>
	<tr>
		<td>output_fields</td>
		<td>Name of the field to return (vector field not support in current release)</td>
		<td>Mandatory</td>
	</tr>
	</tbody>
</table>
</details>

<div class="alert warning">
In current release, data to be load must be under 70% of the total memory resources of all query nodes to reserve memory resources for execution engine.
</div>

5. Check the returned results:

<div class="multipleCode">
  <a href="?python">Python </a>
  <a href="?javascript">Node</a>
</div>


```python
>>> sorted_res = sorted(res, key=lambda k: k['film_id'])
>>> sorted_res
[{'film_id': 2, 'film_date': 1992},
 {'film_id': 4, 'film_date': 1994},
 {'film_id': 6, 'film_date': 1996},
 {'film_id': 8, 'film_date': 1998}]
```

```javascript
// query result
[{ film_id: "2" }, { film_id: "4" }, { film_id: "6" }, { film_id: "8" }];
```

# Administration Guide #
## Storage ##


#### Set Up Storage

Milvus supports using [Amazon Simple Storage Service (S3)](https://aws.amazon.com/s3/) as persistent storage for log and index files. This topic describes how to set up S3 for Milvus. 

You can set up S3 with [Docker Compose](https://docs.docker.com/get-started/overview/) or on K8s. 

#### Set up with Docker Compose

#### 1. Configure S3
[MinIO](https://min.io/product/overview) is compatible with S3. To set up S3 with Docker Compose, provide your values for the <code>minio</code> section in the <code>milvus.yaml</code> file on the milvus/configs path.

```yaml
minio:
  address: <your_s3_endpoint>
  port: <your_s3_port>
  accessKeyID: <your_s3_access_key_id>
  secretAccessKey: <your_s3_secret_access_key>
  useSSL: <true/false>
  bucketName: "<your_bucket_name>"
```
See [MinIO/S3 Configurations](configuration_standalone-advanced.md#MinIOS3-Configurations) for more information.


#### 2. Run Milvus
Run the following command to start Milvus that uses the S3 configurations.
```shell
docker-compose up
```
<div class="alert note">Configurations only take effect after Milvus starts. See <a herf=https://milvus.io/docs/v2.0.0/install_cluster-docker.md#2-Start-Milvus>Start Milvus</a> for more information.</div>

#### Set up on K8s

For Milvus clusters on K8s, you can configure S3 in the same command that starts Milvus. Alternatively, you can configure S3 using the <code>values.yml</code> file on the /charts/milvus path in the [milvus-helm](https://github.com/milvus-io/milvus-helm) repository before you start Milvus.

 The following table lists the keys for configuring S3 in the YAML file.
| Key             | Description                          | Value                                 |
| --------------------- | ------------------------------------ | ------------------------------------ |
| <code>externalS3.enabled</code>    | Enables or disables S3.     | <code>true</code>/<code>false</code> |
| <code>externalS3.host</code>       | The endpoint to access S3.    |                                      |
| <code>externalS3.port</code>       | The port to access S3.     |                                      |
| <code>externalS3.accessKey</code>  | The access key ID for S3. |                                      |
| <code>externalS3.secretKey</code>  | The secret access key for S3.            |                                      |
| <code>externalS3.bucketName</code> | The name of the S3 bucket.                  |                                      |
| <code>minio.enabled</code>         | Enables or disables MinIO.       |  <code>true</code>/<code>false</code> |


#### Using the YAML file

1. Configure the <code>minio</code> section in the <code>values.yaml</code> file.

```yaml
minio:
  enabled: false
```

2. Configure the <code>externalS3</code> section using your values in the <code>values.yaml</code> file.

```yaml
externalS3:
  enabled: true
  host: "<your_s3_endpoint>"
  port: "<your_s3_port>"
  accessKey: "<your_s3_access_key_id>"
  secretKey: "<your_s3_secret_key>"
  useSSL: <true/false>
  bucketName: "<your_bucket_name>"
```

3. After configuring the preceding sections and saving the <code>values.yaml</code> file, run the following command to install Milvus that uses the S3 configurations.

```shell
helm install <your_release_name> milvus/milvus -f values.yaml
```
#### Using a command

To install Milvus and configure S3, run the following command using your values.

```shell
helm install <your_release_name> milvus/milvus --set cluster.enabled=true --set externalS3.enabled=true --set externalS3.host='<your_s3_endpoint>' --set externalS3.port=<your_s3_port> --set externalS3.accessKey=<your_s3_access_key_id> --set externalS3.secretKey=<your_s3_secret_key> --set externalS3.bucketName=<your_bucket_name> --set minio.enabled=false
```
#### What's next

If you want to learn how to use storage from other cloud providers:
- [Use Google Cloud Storage](https://milvus.io/docs/v2.0.0/gcp.md#Use-Google-Cloud-Storage)
- [Use Azure Blob Storage](https://milvus.io/docs/v2.0.0/azure.md#Use-Azure-Blob-Storage)

## Scale a Milvus Cluster ##



Milvus supports horizontal scaling of its components. This means you can either increase or decrease  the number of worker nodes of each type according to your own need. 

This topic describes how to scale out and scale in a Milvus cluster. We assume that you have already [installed a Milvus cluster](install_cluster-helm.md) before scaling. Also, we recommend familiarizing yourself with the [Milvus architecture](architecture_overview.md) before you begin.  

This tutorial takes scaling out three query nodes as an example. To scale out other types of nodes, replace `queryNode` with the corresponding node type in the command line.

#### What is horizontal scaling?

Horizontal scaling includes scaling out and scaling in.

#### Scaling out 
Scaling out refers to increasing the number of nodes in a cluster. Unlike scaling up, scaling out does not require you to allocate more resources to one node in the cluster. Instead, scaling out expands the cluster horizontally by adding more nodes. 

![Scaleout](../../../assets/scale_out.jpg)

![Scaleup](../../../assets/scale_up.jpg)

According to the [Milvus architecture](architecture_overview.md), stateless worker nodes include query node, data node, index node, and proxy. Therefore, you can scale out these type of nodes to suit your business needs and application scenarios. You can either scale out the Milvus cluster manually or automatically.

Generally, you will need to scale out the Milvus cluster you created if it is over-utilized. Below are some typical situations where you may need to scale out the Milvus cluster:
- The CPU and memory utilization is high for a period of time.
- The query throughput becomes higher.
- Higher speed for indexing is required.
- Massive volumes of large datasets need to be processed.
- High availability of the Milvus service needs to be ensured.


#### Scaling in
Scaling in refers to decreasing the number of nodes in a cluster. Generally, you will need to scale in the Milvus cluster you created if it is under-utilized. Below are some typical situations where you need to scale in the Milvus cluster:
- The CPU and memory utilization is low for a period of time.
- The query throughput becomes lower.
- Higher speed for indexing is not required.
- The size of the dataset to be processed is small.

<div class="alert note">
We do not recommend reducing the number of workers nodes dramatically. For example, if there are five data nodes in the cluster, we recommend reducing one data node at a time to ensure service availability. If the service is available after the first attempt of scaling in, you can continue to further reduce the number of the data node.
</div>

#### Prerequisites

Run kubectl get pods to get a list of the components and their working status in the Milvus cluster you created.

```
NAME                                            READY   STATUS       RESTARTS   AGE
my-release-etcd-0                               1/1     Running      0          1m
my-release-milvus-datacoord-7b5d84d8c6-rzjml    1/1     Running      0          1m
my-release-milvus-datanode-665d4586b9-525pm     1/1     Running      0          1m
my-release-milvus-indexcoord-9669d5989-kr5cm    1/1     Running      0          1m
my-release-milvus-indexnode-b89cc5756-xbpbn     1/1     Running      0          1m
my-release-milvus-proxy-7cbcc8ffbc-4jn8d        1/1     Running      0          1m
my-release-milvus-pulsar-6b9754c64d-4tg4m       1/1     Running      0          1m
my-release-milvus-querycoord-75f6c789f8-j28bg   1/1     Running      0          1m
my-release-milvus-querynode-7c7779c6f8-pnjzh    1/1     Running      0          1m
my-release-milvus-rootcoord-75585dc57b-cjh87    1/1     Running      0          1m
my-release-minio-5564fbbddc-9sbgv               1/1     Running      0          1m 
```

<div class="alert note">
Milvus only supports adding the worker nodes and does not support adding the coordinator components.
</div>

#### Scale a Milvus cluster 

You can scale in your Milvus cluster either manually or automatically. If autoscaling is enabled, the Milvus cluster will shrink or expand automatically when CPU and memory resources consumption reaches the value you have set.  

#### Manual scaling

##### Scaling out

Run `helm upgrade my-release milvus/milvus --set queryNode.replicas=3 --reuse-values` to manually scale out the query node.

If successful, three running pods on the query node are added as shown in the following example.

```
NAME                                            READY   STATUS    RESTARTS   AGE
my-release-etcd-0                               1/1     Running   0          2m
my-release-milvus-datacoord-7b5d84d8c6-rzjml    1/1     Running   0          2m
my-release-milvus-datanode-665d4586b9-525pm     1/1     Running   0          2m
my-release-milvus-indexcoord-9669d5989-kr5cm    1/1     Running   0          2m
my-release-milvus-indexnode-b89cc5756-xbpbn     1/1     Running   0          2m
my-release-milvus-proxy-7cbcc8ffbc-4jn8d        1/1     Running   0          2m
my-release-milvus-pulsar-6b9754c64d-4tg4m       1/1     Running   0          2m
my-release-milvus-querycoord-75f6c789f8-j28bg   1/1     Running   0          2m
my-release-milvus-querynode-7c7779c6f8-czq9f    1/1     Running   0          5s
my-release-milvus-querynode-7c7779c6f8-jcdcn    1/1     Running   0          5s
my-release-milvus-querynode-7c7779c6f8-pnjzh    1/1     Running   0          2m
my-release-milvus-rootcoord-75585dc57b-cjh87    1/1     Running   0          2m
my-release-minio-5564fbbddc-9sbgv               1/1     Running   0          2m
```

##### Scaling in

Run `helm upgrade my-release milvus/milvus --set queryNode.replicas=1 --reuse-values` to scale in the query node.

If successful, three running pods on the query node are reduced to one as shown in the following example.

```
NAME                                            READY   STATUS    RESTARTS   AGE
my-release-etcd-0                               1/1     Running   0          2m
my-release-milvus-datacoord-7b5d84d8c6-rzjml    1/1     Running   0          2m
my-release-milvus-datanode-665d4586b9-525pm     1/1     Running   0          2m
my-release-milvus-indexcoord-9669d5989-kr5cm    1/1     Running   0          2m
my-release-milvus-indexnode-b89cc5756-xbpbn     1/1     Running   0          2m
my-release-milvus-proxy-7cbcc8ffbc-4jn8d        1/1     Running   0          2m
my-release-milvus-pulsar-6b9754c64d-4tg4m       1/1     Running   0          2m
my-release-milvus-querycoord-75f6c789f8-j28bg   1/1     Running   0          2m
my-release-milvus-querynode-7c7779c6f8-pnjzh    1/1     Running   0          2m
my-release-milvus-rootcoord-75585dc57b-cjh87    1/1     Running   0          2m
my-release-minio-5564fbbddc-9sbgv               1/1     Running   0          2m
```

#### Autoscaling

Run the following command to enable autoscaling for query node. You also need to configure the value for CPU and memory resource to trigger autoscaling.

```
helm upgrade my-release milvus/milvus --set queryNode.autoscaling.enabled=true --reuse-values
```

#### What's next

- If you want to learn how to monitor the Milvus services and create alerts:
  - Learn [Monitor Milvus 2.0 with Prometheus Operator on Kubernetes](monitor.md)

- If you are ready to deploy your cluster on clouds:
  - Learn how to [Deploy Milvus on AWS with Terraform and Ansible](aws.md)
  - Learn how to [Deploy Milvus on Amazon EKS with Terraform](eks.md)
  - Learn how to [Deploy Milvus Cluster on GCP with Kubernetes](gcp.md)
  - Learn how to [Deploy Milvus on Microsoft Azure With Kubernetes](azure.md)

- If you are looking for instructions on how to allocate resources:
  - [Allocate Resources on Kubernetes](allocate.md#standalone)


## Deploy on Clouds ##
### AWS ###
#### Amazon EC2 ####


#### Deploy a Milvus Cluster on EC2

This topic describes how to deploy a Milvus cluster on [Amazon EC2](https://docs.aws.amazon.com/ec2/) with Terraform and Ansible.

####  Provision a Milvus cluster

This section describes how to use Terraform to provision a Milvus cluster. 

[Terraform](https://www.terraform.io/) is an infrastructure as code (IaC) software tool. With Terraform, you can provision infrastructure by using declarative configuration files.

#### Prerequisites

- Install and configure [Terraform](https://www.terraform.io/downloads.html)

- Install and configure [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)

#### Prepare configuration

You can download template configuration files at [Google Drive](https://drive.google.com/file/d/1jLQV0YkseOVj5X0exj17x9dWQjLCP7-1/view).

- ```main.tf```

  This file contains the configuration for provisioning a Milvus cluster.

- ```variables.tf```

  This file allows quick editing of variables used to set up or update a Milvus cluster.

- ```output.tf``` and ```inventory.tmpl```

  These files store the metadata of a Milvus cluster. The metadata used in this topic is the ```public_ip``` for each node instance, ```private_ip``` for each node instance, and all EC2 instance IDs. 

##### Prepare variables.tf

This section describes the configuration that a ```variables.tf``` file that contains.

- Number of nodes

  The following template declares an ```index_count``` variable used to set the number of index nodes.

  <div class="alert note">The value of <code>index_count</code> must be greater than or equal to one.</div>

  ```variables.tf
  variable "index_count" {
    description = "Amount of index instances to run"
    type        = number
    default     = 5
  }
  ```

- Instance type for a node type

  The following template declares an ```index_ec2_type``` variable used to set the [instance type](https://aws.amazon.com/ec2/instance-types/) for index nodes.

  ```variables.tf
  variable "index_ec2_type" {
    description = "Which server type"
    type        = string
    default     = "c5.2xlarge"
  }
  ```

- Access permission

  The following template declares a ```key_name``` variable and a ```my_ip``` variable. The ```key_name``` variable represents the AWS access key. The ```my_ip``` variable represents the IP address range for a security group.

  ```variables.tf
  variable "key_name" {
    description = "Which aws key to use for access into instances, needs to be uploaded already"
    type        = string
    default     = ""
  }
  
  variable "my_ip" {
    description = "my_ip for security group. used so that ansible and terraform can ssh in"
    type        = string
    default     = "x.x.x.x/32"
  }
  ```

##### Prepare main.tf

This section describes the configurations that a ```main.tf``` file that contains.

- Cloud provider and region

  The following template uses the ```us-east-2``` region. See [Available Regions](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions) for more information.

  ```main.tf
  provider "aws" {
    profile = "default"
    region  = "us-east-2"
  }
  ```

- Security group

  The following template declares a security group that allows incoming traffic from the CIDR address range represented by ```my_ip``` declared in ```variables.tf```.

  ```main.tf
  resource "aws_security_group" "cluster_sg" {
    name        = "cluster_sg"
    description = "Allows only me to access"
    vpc_id      = aws_vpc.cluster_vpc.id
  
    ingress {
      description      = "All ports from my IP"
      from_port        = 0
      to_port          = 65535
      protocol         = "tcp"
      cidr_blocks      = [var.my_ip]
    }
  
    ingress {
      description      = "Full subnet communication"
      from_port        = 0
      to_port          = 65535
      protocol         = "all"
      self             = true
    }
  
    egress {
      from_port        = 0
      to_port          = 0
      protocol         = "-1"
      cidr_blocks      = ["0.0.0.0/0"]
      ipv6_cidr_blocks = ["::/0"]
    }
  
    tags = {
      Name = "cluster_sg"
    }
  }
  ```

- VPC

  The following template specifies a VPC with the 10.0.0.0/24 CIDR block on a Milvus cluster.

  ```main.tf
  resource "aws_vpc" "cluster_vpc" {
    cidr_block = "10.0.0.0/24"
    tags = {
      Name = "cluster_vpc"
    }
  }
  
  resource "aws_internet_gateway" "cluster_gateway" {
    vpc_id = aws_vpc.cluster_vpc.id
  
    tags = {
      Name = "cluster_gateway"
    }
  }
  ```

- Subnets (Optional)

  The following template declares a subnet whose traffic is routed to an internet gateway. In this case, the size of the subnet's CIDR block is the same as the VPC's CIDR block.

  ```main.tf
  resource "aws_subnet" "cluster_subnet" {
    vpc_id                  = aws_vpc.cluster_vpc.id
    cidr_block              = "10.0.0.0/24"
    map_public_ip_on_launch = true
  
    tags = {
      Name = "cluster_subnet"
    }
  }
  
  resource "aws_route_table" "cluster_subnet_gateway_route" {
    vpc_id       = aws_vpc.cluster_vpc.id
  
    route {
      cidr_block = "0.0.0.0/0"
      gateway_id = aws_internet_gateway.cluster_gateway.id
    }
  
    tags = {
      Name = "cluster_subnet_gateway_route"
    }
  }
  
  resource "aws_route_table_association" "cluster_subnet_add_gateway" {
    subnet_id      = aws_subnet.cluster_subnet.id
    route_table_id = aws_route_table.cluster_subnet_gateway_route.id
  }
  
  ```

- Node instances (Nodes)

  The following template declares a MinIO node instance. The ```main.tf``` template file declares nodes of 11 node types. For some node types, you need to set ```root_block_device```. See [EBS, Ephemeral, and Root Block Devices](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance#ebs-ephemeral-and-root-block-devices) for more information.

  ```main.tf
  resource "aws_instance" "minio_node" {
    count         = var.minio_count
    ami           = "ami-0d8d212151031f51c"
    instance_type = var.minio_ec2_type
    key_name      = var.key_name
    subnet_id     = aws_subnet.cluster_subnet.id 
    vpc_security_group_ids = [aws_security_group.cluster_sg.id]
  
    root_block_device {
      volume_type = "gp2"
      volume_size = 1000
    }
    
    tags = {
      Name = "minio-${count.index + 1}"
    }
  }
  ```

#### Apply the configuration

1. Open a terminal and navigate to the folder that stores ```main.tf```.

2. To initialize the configuration, run ```terraform init```.

3. To apply the configuration, run ```terraform apply``` and enter ```yes``` when prompted.

You have now provisioned a Milvus cluster with Terraform.

#### Start the Milvus cluster

This section describes how to use Ansible to start the Milvus cluster that you have provisioned.

[Ansible](https://www.ansible.com/overview/how-ansible-works) is a configuration management tool used to automate cloud provisioning and configuration management.

#### Prerequisites 

- Install and configure [Ansible](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html)

#### Prepare configuration

You can download template configuration files at [Google Drive](https://drive.google.com/file/d/1jLQV0YkseOVj5X0exj17x9dWQjLCP7-1/view).

- Files in the ```yaml_files``` folder

  This folder stores Jinja2 files for each node type. Ansible uses Jinja2 templating. See [Introduction](https://jinja2docs.readthedocs.io/en/stable/intro.html) for more information about Jinja2.

- ```playbook.yaml```

  This file performs a set of tasks on specific sets of nodes. The template begins with installing Docker and Docker Compose on all node instances on the Milvus cluster.

  <div class="alert note">A playbook runs in sequence from top to bottom. Within each play, tasks also run in sequence from top to bottom.</div>
  
  ```playbook.yaml
  - name: All Servers
    hosts: etcd_ips_public:pulsar_ips_public:minio_ips_public:data_ips_public:index_ips_public:query_ips_public:proxy_ips_public:root_coordinator_ips_public:data_coordinator_ips_public:query_coordinator_ips_public:index_coordinator_ips_public
    remote_user: ec2-user
    become: true
    tags:
      - start
    tasks:
    - name: Install docker
      ansible.builtin.yum:
        name: docker
        state: present
    - name: Run docker
      ansible.builtin.service:
        name: docker
        state: started
  
    - name: Install or upgrade docker-compose
      get_url: 
        url : "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-Linux-x86_64"
        dest: /usr/local/bin/docker-compose
        mode: 'a+x'
        force: yes
    - name: Create symbolic link for docker-compose
      file:
        src: "/usr/local/bin/docker-compose"
        dest: "/usr/bin/docker-compose"
        state: link
   
  ```

  After Docker and Docker Compose are installed on all node instances,  ```playbook.yaml``` starts containers for all node instances in sequence.
  
  ```playbook.yaml
  - name: etcd
    hosts: etcd_ips_public
    remote_user: ec2-user
    become: true
    tags:
      - start
  
    tasks:
    - name: Copy etcd config
      ansible.builtin.template:
        src: ./yaml_files/etcd.j2
        dest: /home/ec2-user/docker-compose.yml
        owner: ec2-user
        group: wheel
        mode: '0644'
  
    - name: Run etcd node
      shell: docker-compose up -d
      args:
        chdir: /home/ec2-user/
       
  ```

#### Apply the configuration

1. Open a terminal and navigate to the folder that stores ```playbook.yaml```.

2. Run ```ansible-playbook -i inventory playbook.yaml --tags "start"```. 

3. If successful, all node instances start.

You have now started a Milvus cluster with Ansible.

#### Stop nodes

You can stop all nodes after you do not need a Milvus cluster any longer.

<div class="alert note"> Ensure that the <code>terraform</code> binary is available on your <code>PATH</code>. </div>

1. Run ```terraform destroy``` and enter ```yes``` when prompted.

2. If successful, all node instances are stopped. 

#### What's next

If you want to learn how to deploy Milvus on other clouds:
- [Deploy a Milvus Cluster on EKS](https://milvus.io/docs/v2.0.0/eks.md)
- [Deploy Milvus Cluster on GCP with Kubernetes](https://milvus.io/docs/v2.0.0/gcp.md)
- [Guide to Deploying Milvus on Microsoft Azure With Kubernetes](https://milvus.io/docs/v2.0.0/azure.md)


#### Amazon EKS ####


#### Deploy a Milvus Cluster on EKS

This topic describes how to deploy a Milvus cluster on [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html). 

<div class="alert note">This topic assumes that you have a basic understanding of AWS access management. If you're not familiar with it, see <a href=https://docs.aws.amazon.com/iam/?id=docs_gateway>AWS Identity and Access Management Documentation</a>.</div>

#### Prerequisites

#### Software requirements

- [Terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli)
- [Helm](https://helm.sh/docs/intro/install/)
- [kubectl](https://kubernetes.io/docs/tasks/tools/)
- [AWS CLI version 2](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)

#### Cloud security

- Access to EKS, EC2, and S3
- Access key ID
- Security access key

#### Deploy a Milvus cluster

You can download template configuration files at [Google Drive](https://drive.google.com/file/d/1jLQV0YkseOVj5X0exj17x9dWQjLCP7-1/view).

1. Provision a Milvus cluster. See [Provision a Milvus cluster](https://milvus.io/docs/v2.0.0/aws.md#provision-a-milvus-cluster) for more information.

2. After a Milvus cluster is provisioned, run the following command with a region and name for the cluster.

   ```shell
   aws eks --region ${aws-region} update-kubeconfig --name ${cluster-name}
   ```
3. Create a kubeconfig file and run ```kubectl get svc```.  If successful, a cluster appears in the output.

   ```shell
   NAME          TYPE      CLUSTER-IP    EXTERNAL-IP                                PORT(S)             AGE
   kubernetes       ClusterIP   172.20.0.1    <none>                                  443/TCP             106m
   ```

4. Run the following command to start the Milvus cluster that you have provisioned. The access key and an S3 bucket are required to use S3 as storage.

```shell
helm upgrade --install --set cluster.enabled=true --set externalS3.enabled=true --set externalS3.host='s3.us-east-2.amazonaws.com' --set externalS3.port=80 --set externalS3.accessKey=${access-key} --set externalS3.secretKey=${secret-key} --set externalS3.bucketName=${bucket-name} --set minio.enabled=False --set service.type=LoadBalancer milvus milvus/milvus
```

5. Run ```kubectl get svc ``` again to retrieve the IP address of the load balancer and use it as the IP address of the Milvus cluster.

<div class="alert note"> Run <code>kubectl get pods</code> to view the running pods on the cluster.</div>

#### Scale the Milvus cluster

Currently, a Milvus cluster can only be scaled manually. Run the following command to modify the numbers of node instances with different types.

<div class ="alert note">See <a href="https://milvus.io/docs/v2.0.0/four_layers.md#StorageComputing-Disaggregation">Storage/Computing Disaggregation</a> for more information about the data node, index node, query node, and proxy.</div>

```shell
helm upgrade --install --set cluster.enabled=true --set dataNode.replicas=1 --set indexNode.replicas=1 --set queryNode.replicas=1 --set proxy.replicas=1 --set externalS3.enabled=true --set externalS3.host='s3.us-east-2.amazonaws.com' --set externalS3.port=80 --set externalS3.accessKey=${access-key} --set externalS3.secretKey=${secret-key} --set externalS3.bucketName=${bucket-name} --set minio.enabled=False --set service.type=LoadBalancer milvus milvus/milvus
```

After running the preceding command, you can run ```kubectl get pods``` to view the newly created node instances.

#### What's next

If you want to learn how to deploy Milvus on other clouds:
- [Deploy a Milvus Cluster on EC2](https://milvus.io/docs/v2.0.0/aws.md)
- [Deploy Milvus Cluster on GCP with Kubernetes](https://milvus.io/docs/v2.0.0/gcp.md)
- [Guide to Deploying Milvus on Microsoft Azure With Kubernetes](https://milvus.io/docs/v2.0.0/azure.md)

### GCP ###


#### Deploy a Milvus Cluster on GCP

This topic describes how to deploy a Milvus cluster on [Google Cloud Platform](https://console.cloud.google.com/) (GCP).

#### Prerequisites
Determine the Google Cloud project that you want to work with. If you are not sure which one to use, ask your GCP administrators to create a new one. See [Creating and managing projects](https://cloud.google.com/resource-manager/docs/creating-managing-projects) for more information. The project used in this topic is named <code>milvus-testing-nonprod</code>. Replace it with your project name in commands.


#### Software requirements
- [Cloud SDK](https://cloud.google.com/sdk/docs/quickstart#installing_the_latest_version)
- [kubectl](https://kubernetes.io/docs/tasks/tools/)
- [Helm](https://helm.sh/docs/intro/install/)
  
Alternatively, you can use [Cloud Shell](https://cloud.google.com/shell) which has the GCP SDK, kubectl, and Helm preinstalled.

<div class="alert note">After you install the Cloud SDK, ensure that you are properly authenticated.</div>

#### Set up network

Ensure that you create a virtual private cloud (VPC) before creating a firewall rule for Milvus.
<br>
If you already have a VPC that you want to use, proceed to [Create a firewall rule for Milvus ](gcp.md#Create-a-firewall-rule-for-Milvus).


#### Create a VPC

Open a terminal and run the following command to create a VPC.

<div class="alert note">
Replace <code>milvus-testing-nonprod</code> with your project name.
</div>

```shell
gcloud compute networks create milvus-network --project=milvus-testing-nonprod --subnet-mode=auto --mtu=1460 --bgp-routing-mode=regional
```

Run the following commands to create firewall rules to allow ICMP, internal, RDP, and SSH traffic.

```shell
gcloud compute firewall-rules create milvus-network-allow-icmp --project=milvus-testing-nonprod --network=projects/milvus-testing-nonprod/global/networks/milvus-network --description=Allows\ ICMP\ connections\ from\ any\ source\ to\ any\ instance\ on\ the\ network. --direction=INGRESS --priority=65534 --source-ranges=0.0.0.0/0 --action=ALLOW --rules=icmp

gcloud compute firewall-rules create milvus-network-allow-internal --project=milvus-testing-nonprod --network=projects/milvus-testing-nonprod/global/networks/milvus-network --description=Allows\ connections\ from\ any\ source\ in\ the\ network\ IP\ range\ to\ any\ instance\ on\ the\ network\ using\ all\ protocols. --direction=INGRESS --priority=65534 --source-ranges=10.128.0.0/9 --action=ALLOW --rules=all

gcloud compute firewall-rules create milvus-network-allow-rdp --project=milvus-testing-nonprod --network=projects/milvus-testing-nonprod/global/networks/milvus-network --description=Allows\ RDP\ connections\ from\ any\ source\ to\ any\ instance\ on\ the\ network\ using\ port\ 3389. --direction=INGRESS --priority=65534 --source-ranges=0.0.0.0/0 --action=ALLOW --rules=tcp:3389

gcloud compute firewall-rules create milvus-network-allow-ssh --project=milvus-testing-nonprod --network=projects/milvus-testing-nonprod/global/networks/milvus-network --description=Allows\ TCP\ connections\ from\ any\ source\ to\ any\ instance\ on\ the\ network\ using\ port\ 22. --direction=INGRESS --priority=65534 --source-ranges=0.0.0.0/0 --action=ALLOW --rules=tcp:22
```

#### Create a firewall rule for Milvus 

Create a firewall rule to allow incoming traffic on the ```19530``` port used by Milvus.

```Apache
gcloud compute --project=milvus-testing-nonprod firewall-rules create allow-milvus-in --description="Allow ingress traffic for Milvus on port 19530" --direction=INGRESS --priority=1000 --network=projects/milvus-testing-nonprod/global/networks/milvus-network --action=ALLOW --rules=tcp:19530 --source-ranges=0.0.0.0/0
```

#### Provision a Kubernetes cluster

We use Google Kubernetes Engine (GKE) to provision a K8s cluster. In this topic, we create a cluster that has two nodes. The nodes are in the ```use-west1-a``` zone, are with the ```e2-standard-4``` machine type, and use the ```cos_containerd``` node image.

<div class="alert note">
Modify the preceding options as needed.
</div>

#### Select a machine type

In this topic, we use the ```e2-standard-4``` machine type, which has 4 vCPUs and 16 GB of memory.

<div class="alert note">
You can select machine types as you need. However, we recommend that you select machine types that have a minimum of 16 GB of memory to ensure stability.
</div>

```shell
gcloud beta container --project "milvus-testing-nonprod" clusters create "milvus-cluster-1" --zone "us-west1-a" --no-enable-basic-auth --cluster-version "1.20.8-gke.900" --release-channel "regular" --machine-type "e2-standard-4" --image-type "COS_CONTAINERD" --disk-type "pd-standard" --disk-size "100" --max-pods-per-node "110" --num-nodes "2" --enable-stackdriver-kubernetes --enable-ip-alias --network "projects/milvus-testing-nonprod/global/networks/milvus-network" --subnetwork "projects/milvus-testing-nonprod/regions/us-west1/subnetworks/milvus-network"
```

Creating a cluster might take several minutes. After the cluster is created, run the following command to fetch credentials for the cluster.

```shell
gcloud container clusters get-credentials milvus-cluster-1
```

The preceding command points ```kubectl``` at the cluster.

#### Deploy Milvus 

After provisioning a cluster, you can deploy Milvus. If you switch to a different terminal, run the following command again to fetch credentials.

```shell
gcloud container clusters get-credentials milvus-cluster-1
```

1. Run the following command to add the Milvus Helm chart repository.
```shell
helm repo add milvus https://milvus-io.github.io/milvus-helm/
```

2. Run the following command to update your Milvus Helm chart.
```Apache
helm repo update
```

3. Run the following command to deploy Milvus. 

<div class="alert note">
This topic uses the <code>my-release</code> release name. Replace it with your release name.
</div>

```shell
helm install my-release milvus/milvus --set service.type=LoadBalancer
```

Starting pods might take several minutes. Run <code>kubectl get services</code> to view services. If successful, a list of services is shown as follows.


![GCP](../../../../assets/gcp.png)


<div class="alert note">

<code>34.145.26.89</code> in the the <code>EXTERNAL-IP</code> column is the IP address of the load balancer. The IP address is used to connect to Milvus.
</div>

#### Use Google Cloud Storage
Google Cloud Storage (GCS) is Google Cloud's version of AWS Simple Storage Service (S3).

MinIO GCS Gateway allows accessing GCS. Essentially, MinIO GCS Gateway translates and forwards all connections to GCS by using APIs. You can use MinIO GCS Gateway instead of a MinIO server.

#### Set variables

Set variables before you use MinIO GCS Gateway. Modify the default values as needed.

##### Secrets

To access GCS resources, MinIO GCS Gateway requires both GCP service account credentials and MinIO credentials. Store the credentials in a K8s secret. The credentials are listed as follows.

- `accesskey`: The MinIO access key.
- `secretkey`: The MinIO secret key.
- `gcs_key.json`: The GCP service account credentials file.

##### Example

```shell
$ kubectl create secret generic mysecret --from-literal=accesskey=minioadmin --from-literal=secretkey=minioadmin --from-file=gcs_key.json=/home/credentials.json
```

<div class="alert note">
If you choose <code>accesskey</code> and <code>secretkey</code> values other than the default <code>minioadmin/minioadmin</code>, you need to update the <code>minio.accessKey</code> and <code>minio.secretKey</code> metadata variables as well.
</div>


##### Metadata 

##### Configuration

|Option|Description|Default|
|:---|:---|:---|
|`minio.gcsgateway.enabled`|Set the value to ```true``` to enable MinIO GCS Gateway.|`false`|
|`minio.gcsgateway.projectId`|The ID of the GCP project.|`""`|
|`minio.existingSecret`|The name of the previously defined secret.|`""`|
|`externalGcs.bucketName`|The name of the GCS bucket to use. Unlike an S3/MinIO bucket, a GCS bucket must be globally unique.|`""`|

##### Defaults

|Option|Description|Default|
|:---|:---|:---|
|`minio.gcsgateway.replicas`|The number of replica nodes to use for the gateway. We recommend that you use one because MinIO does not support well for more than one replica.|`1`|
|`minio.gcsgateway.gcsKeyJson`|The file path to GCS service account access credentials file. Do **not** modify the default value.|`/etc/credentials/gcs_key.json`|

Continue to use all normal MinIO metadata variables.

##### Example
```shell
$ helm install my-release milvus/milvus --set minio.existingSecret=mysecret --set minio.gcsgateway.enabled=true --set minio.gcsgateway.projectId=milvus-testing-nonprod --set externalGcs.bucketName=milvus-bucket-example
```

#### What's next

If you want to learn how to deploy Milvus on other clouds:
- [Deploy a Milvus Cluster on EC2](https://milvus.io/docs/v2.0.0/aws.md)
- [Deploy a Milvus Cluster on EKS](https://milvus.io/docs/v2.0.0/eks.md)
- [Deploy a Milvus Cluster on Azure](https://milvus.io/docs/v2.0.0/azure.md)

### Azure ###


#### Guide to Deploying Milvus on Microsoft Azure With Kubernetes

This guide is a set of instructions for deploying Milvus cluster on Microsoft Azure.

#### Prerequisites

1. Confirm that your Azure project is set up properly and that you have access to the resources you would like to use. Contact your Azure administrator if you are unsure about your permissions. 
2. Install Azure CLI and confirm that you are properly authenticated. 
3. Install kubectl and helm. You can also use the Azure Cloud Shell from your browser, which offers a choice of Bash or PowerShell. 

<div class="alert note">
Azure Cloud Shell has Azure CLI, kubectl, and helm all pre-installed. 
</div>

#### Provision a Kubernetes cluster with Azure Kubernetes Service (AKS)
This guide uses [Azure Portal](https://docs.microsoft.com/en-us/azure/aks/kubernetes-walkthrough-portal) to create a cluster and AKS to provision a Kubernetes cluster. You can access the AKS creation interface [here](https://portal.azure.com/#create/microsoft.aks).

1. Select the appropriate options.

**Basics**

- Project Details
  - Subscription: Contact your organization's Azure Administrator to determine which subscription you should use.

  - Resource group: Contact your organization's Azure Administrator to determine which resource group you should use.

- Cluster Details
  - Kubernetes cluster name: A cluster name of your own choice.

  - Region: A region of your own choice. 

  - Availability zones: Pick a number of [availability zones](https://docs.microsoft.com/en-us/azure/aks/availability-zones#overview-of-availability-zones-for-aks-clusters) based on your needs. For production clusters, we recommend you to use multiple availability zones. But for testing purposes, it is unnecessary to use more than one availability zone.

- Primary Node Pool

  - Node size: We strongly recommend choosing a node type with at least **16 GiB of RAM** available. Depending on your data scale, you can also pick a node type with more resources.
  
    <div class="alert note">    
    You may select different machine types to better suit your work case, but we strongly recommend that worker nodes all have at least 16 GB of memory to ensure minimum stable operation.
    </div>

  - Scale Method: A scaling method of your own choice.

  - Node Count: The number of nodes of your own choice.

**Node Pools**

- Enable Virtual Nodes: Whether to enable virtual nodes is of your own choice.

- Enable Virtual Machine Scale Sets: We recommend choosing `enabled`.

**Networking**

- Network configuration: We recommend choosing `Kubenet`.

- DNS name prefix: A DNS name prefix of your own choice.

- Traffic Routing

  - Load Balancer: `Standard`

  - HTTP application routing: `Not Needed`

2. After selecting the appropriate options, review and create a cluster. Allow several minutes for the cluster to spin up before proceeding to the next step. 

#### Deploy Milvus with Helm

After setting up the cluster, we can now deploy Milvus with Helm. 

##### Before you begin

1. Connect your shell to the newly created Kubernetes cluster. 
Navigate to your Kubernetes Cluster under the Azure resources panel. Get the requisite connection info by selecting the "connect button" under the "overview" tab. See screenshot below. 

![Azure](../../../../assets/azure.png)

2. Use the Azure Cloud Shell or Azure CLI to set your subscription and configure your cluster credentials with the information in the "connect" tab.

```
az account set --subscription EXAMPLE-SUBSCRIPTION-ID
```

```
az aks get-credentials --resource-group YOUR-RESOURCE-GROUP --name YOUR-CLUSTER-NAME
```

<div class="alert note">
Use the same shell for helm deployment. If you change or close your shell, repeat the above two commands before proceeding to deployment.
</div>

##### Deploy

1. Add the Milvus chart repository.

```
helm repo add milvus https://milvus-io.github.io/milvus-helm/
```

2. Update your Milvus chart.

```
helm repo update
```

3. Run helm to deploy Milvus. 

<div class="alert note">
In this guide, we pick the name <code>my-release</code>, but you can change the name.
</div>

```
helm install my-release milvus/milvus --set cluster.enabled=true --set service.type=LoadBalancer
```

Allow several minutes for the pods to start up. Run `kubectl get services` to check on the services. If the services are successfully booted, you can see a set of services listed out. 

![Results](../../../../assets/azure_results.png)

<div class="alert note">
Note that the IP listed under the EXTERNAL-IP column for the load balancer is the IP for connecting to Milvus. The default Milvus port is 19530. 
</div>

#### Use Azure Blob Storage

##### Overview

Azure Blob Storage is one of Microsoft Azure's cloud storage offerings, sharing many features with competitors such as AWS's S3 storage.

The Azure gateway node is an alternative running method for the MinIO server which behaves the same from the client's perspective, but translates and forwards all connections to Azure Blob Storage with the according Azure connection API.

##### How to use

You need to set a number of variables before using the Azure gateway node. Most of the variables are set to appropriate default settings, but you still need to alter some variables.

**Metadata that you must set**

- `minio.azuregateway.enabled`: Must be set to `true` to enable operation.

  -  Default is false. 

- `minio.accessKey`: Name of the Azure storage account to use.

- `minio.secretKey`: Access key for the Azure storage account.

- `externalAzure.bucketName`: Name of the Azure storage bucket to use. Unlike S3/MinIO buckets, Azure buckets must be *globally* unique. Therefore the default value is unset.

  - Default is unset.

**Metadata that should be left as default**

- `minio.azuregateway.replicas`: Number of replica nodes to use for the Azure gateway. We highly recommend using only one replica node because MinIO does not have good support for higher numbers. 

  - Default is 1.

- You should also inherit all of the normal MinIO metadata variables.

Example helm install:

```
helm install my-release ./milvus --set cluster.enabled=true --set service.type=LoadBalancer --set minio.persistence.enabled=false --set externalAzure.bucketName=milvusbuckettwo --set minio.azuregateway.enabled=true --set minio.azuregateway.replicas=1 --set minio.accessKey=milvusstorage --set minio.secretKey=your-azure-key
```


## Monitor and Alert ##
### Monitoring Architecture ###


#### Milvus monitoring framework overview

This topic explains how Milvus uses Prometheus to monitor metrics and Grafana to visualize metrics and create alerts.

#### Prometheus in Milvus
[Prometheus](https://prometheus.io/docs/introduction/overview/) is an open-source monitoring and alerting toolkit for Kubernetes implementations. It collects and stores metrics as time-series data. This means that metrics are stored with timestamps when recorded, alongside with optional key-value pairs called labels. 
Currently Milvus uses the following components of Prometheus:
- Prometheus endpoint to  pull data from endpoints set by exporters.
- Prometheus operator to effectively manage Prometheus monitoring instances.
- Kube-prometheus to provide easy to operate end-to-end Kubernetes cluster monitoring.

#### Grafana in Milvus
[Grafana](https://grafana.com/docs/grafana/latest/introduction/) is a visualizing stack. It features a dashboard that can help you visualize all the data and metrics you need. With the Grafana dashboard, you can query, understand, and analyze your data.



#### What's next
After learning about the basic workflow of monitoring and alerting, learn:
- [Deploy monitoring services](monitor.md)
- [Visualize Milvus metrics](visualize.md)
- [Create an alert](alert.md)

### Deploy Monitoring Services ###


#### Deploying Monitoring Services on Kubernetes

This topic describes how to use Prometheus to deploy monitoring services for a Milvus cluster on Kubernetes.

#### Monitor metrics with Prometheus
Metrics are indicators providing information about the running status of your system. For example, with metrics, you can understand how much memory or CPU resources are consumed by a data node in Milvus. Being aware of the performance and status of the components in your Milvus cluster makes you well-informed and hence making better decisions and adjusting resource allocation in a more timely manner.

Generally, metrics are stored in a time series database (TSDB), like [Prometheus](https://prometheus.io/), and the metrics are recorded with a timestamp. In the case of monitoring Milvus services, you can use Prometheus to pull data from endpoints set by exporters. Prometheus then exports metrics of each Milvus component at `http://<component-host>:9091/metrics`. 

However, you might have several replicas for one component, which makes manual configuration of Prometheus too complicated. Therefore, you can use [Prometheus Operator](https://github.com/prometheus-operator/prometheus-operator), an extension to Kubernetes, for automated and effective management of Prometheus monitoring instances. Using Prometheus Operator saves you the trouble of manually adding metric targets and service providers.

The ServiceMonitor Custom Resource Definition (CRD) enables you to declaratively define how a dynamic set of services are monitored. It also allows selecting which services to monitor with the desired configuration using label selections. With Prometheus Operator, you can introduce conventions specifying how metrics are exposed. New services can be automatically discovered following the convention you set without the need for manual reconfiguration.

The following image illustrates Prometheus workflow.

![Prometheus_architecture](../../../../assets/prometheus_architecture.png)

#### Prerequisites

This tutorial uses [kube-prometheus](https://github.com/prometheus-operator/kube-prometheus) to save you the trouble of installing and manually configuring each monitoring and alerting component.

Kube-prometheus collects Kubernetes manifests, [Grafana](http://grafana.com/) dashboards, and [Prometheus rules](https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/) combined with documentation and scripts.

Before deploying monitoring services, you need to create a monitoring stack by using the configuration in the kube-prometheus manifests directory.

```
git clone https://github.com/prometheus-operator/kube-prometheus.git
kubectl create -f manifests/setupuntil kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo ""; done
kubectl create -f manifests/
```

To delete a stack, run `kubectl delete --ignore-not-found=true -f manifests/ -f manifests/setup`.

#### Deploy monitoring services on Kubernetes

#### 1. Access the dashboards

You can access Prometheus via `http://localhost:9090`.

```
kubectl --namespace monitoring port-forward svc/prometheus-k8s 9090
```

#### 2. Enable ServiceMonitor

The ServiceMonitor is not enabled for Milvus Helm by default. After installing the Prometheus Operator in the Kubernetes cluster, you can enable it by adding the parameter `metrics.serviceMontior.enabled=true`.

```
helm install my-release milvus/milvus --set metrics.serviceMonitor.enabled=true
```

When the installation completes, use `kubectl` to check the ServiceMonitor resource.

```
kubectl get servicemonitor
```
```
NAME                           AGE
my-release-milvus              54s
```

#### What's next

- If you have deployed monitoring services for the Milvus cluster, you might also want to learn to:
  - [Visualize Milvus metrics in Grafana](visualize.md)
  - [Create an Alert for Milvus Services](alert.md)
  - Adjust your [resource allocation](allocate.md)
- If you are looking for information about how to scale a Milvus cluster:
  - Learn [scale a Milvus cluster](scaleout.md)
- If you are interested in upgrading the Milvus 2.0 version,
  - Read the [upgrading guide](upgrade.md)

### Visualize Milvus Metrics ###


#### Visualize Milvus metrics in Grafana

This topic describes how to visualize Milvus metrics using Grafana.

As described in the [monitoring guide](monitor.md), metrics contain useful information such as how much memory is used by a specific Milvus component. Monitoring metrics helps you better understand Milvus performance and its running status so that you can adjust resource allocation timely. 

Visualization is a chart showing the change of resource usage across time, which makes it easier for you to quickly see and notice the changes to resource usage especially when an event occurs.

This tutorial uses Grafana, an open-source platform for time-series analytics, to visualize various performance metrics of Milvus.

#### Prerequisites

You need to [configure Prometheus](monitor.md) to monitor and collect metrics before using Grafana to visualize the metrics. If the setup is successful, you can access Grafana at `http://localhost:3000`. Or you can also access Grafana using the default Grafana `user:password` of `admin:admin`.

#### Visualize metrics using Grafana

#### 1. Download and import dashboard

Download and import Milvus dashboard from the JSON file.

```
wget https://raw.githubusercontent.com/milvus-io/milvus/master/deployments/monitor/grafana/milvus-dashboard.json
```

![Download_and_import](../../../../assets/import_dashboard.png)

#### 2. View metrics

Select the Milvus instance you want to monitor. Then you can see the Milvus components panel.


![Select_instance](../../../../assets/grafana_select.png)

![Grafana_panel](../../../../assets/grafana_panel.png)


#### What's next
- If you have set Grafana to visualize Milvus metrics, you might also want to:
  - Learn how to [create an alert for Milvus services](alert.md)
  - Adjust your [resource allocation](allocate.md)
  - [Scale out or scale in a Milvus cluster](scaleout.md)
- If you are interested in upgrading the Milvus 2.0 version,
  - Read the [upgrading guide](upgrade.md)

### Create an Alert ###


#### Create an Alert for Milvus Services

This topic introduces the alert mechanism for Milvus services and explains why, when, and how to create alerts in Milvus.

By creating alerts, you can receive notifications when the value of a specific metric exceeds the threshold you have predefined. 

For example, you create an alert and set 80 MB as the maximum value for memory usage by Milvus components. If the actual usage exceeds the predefined number, you will receive alerts reminding you that the memory usage by Milvus component surpasses 80 MB. Upon the alert, you can then adjust the allocation of resources accordingly and timely to ensure service availability.

#### Scenarios for creating alerts.

Below are some common scenarios where you need to create an alert for.

- CPU or memory usage by Milvus components is too high.
- Milvus component pods are running low on disk space.
- Milvus component pods are restarting too frequently.

The following metrics are available for alerting configuration:

| Metric   | Description  | Unit of measure  |
| --------  | --------- | -------------- |
| CPU Usage   | CPU usage by Milvus components that is indicated by the running time of CPU.  | Second    |
| Memory      | Memory resources consumed by Milvus components.  | MB    |
| Goroutines   | Concurrent executing activities in GO language.  |  /   |
| OS Threads   | Threads, or lightweight processes in an operating system.  |   / |
| Process Opened Fds   | The current number of used file descriptors.  | /    |

#### Set up alerts
This guide takes the example of creating an alert for the memory usage of Milvus components. To create other types of alerts, please adjust your commands accordingly. If you encounter any problems during the process, feel free to ask in the [Milvus forum](https://discuss.milvus.io/) or initiate a discussion on [Slack](https://join.slack.com/t/milvusio/shared_invite/zt-e0u4qu3k-bI2GDNys3ZqX1YCJ9OM~GQ).

#### Prerequisites
This tutorial assumes that you have Grafana installed and configured. If not, we recommend reading the [monitoring guide](monitor.md). 

#### 1. Add a new query
To add an alert for the memory usage of Milvus components, edit the Memory panel. Then, add a new query with the metric: `process_resident_memory_bytes{app_kubernetes_io_name="milvus", app_kubernetes_io_instance=~"my-release", namespace="default"}`

![Alert_metric](../../../../assets/alert_metric.png)

#### 2. Save the dashboard
Save the dashboard, and wait for a few minutes to see the alert.

![Alert_dashboard](../../../../assets/alert_dashboard.png)

Grafana alert query does not support template variables. Therefore, you should add a second query without any template variables in the labels. The second query is named as "A" by default. You can rename it by clicking on the dropdown.

![Alert_query](../../../../assets/alert_query.png)

#### 3. Add alert notifications
To receive alert notifications, add a "notification channel". Then, specify the channel in the field "Send to".

![Alert_notification](../../../../assets/alert_notification.png)

If the alert is successfully created and triggered, you will receive the notification as shown in the screenshot below.

![Notification_message](../../../../assets/notification_message.png)

To delete an alert, go to the "Alert" panel and click the delete button.

![Delete_alert](../../../../assets/delete_alert.png)

#### What's next

- If you need to start monitoring services for Milvus:
  - Read the [monitoring guide](monitor.md)
  - Learn how to [visualize monitoring metrics](visualize.md)
- If you have created alerts for memory usage by Milvus components:
  - Learn how to [allocate resources](allocate.md#standalone)
- If you are looking for information about how to scale a Milvus cluster:
  - Learn [scale a Milvus cluster](scaleout.md)


## Allocate Resources ##


#### Allocate Resources on Kubernetes

Generally, the resources you allocate to a Milvus cluster in production should be proportionate to the machine workload. You should also consider the machine type when allocating resources. Although you can update the configurations when the cluster is running, we recommend you to set the values before deploying the cluster.

<div class="alert note">
Run <code>kubectl describe nodes</code> to view the available resources on the instances that you have provisioned.
</div>

#### Allocate memory and CPU resources

Use Helm to allocate CPU and memory resources to Milvus components.

<div class="alert warning">
Using Helm to upgrade resources will cause the running pods to perform rolling update.
</div>


You need to set the resource variables for each Milvus component if you use `--set` to update the resource configurations. 

<div class="filter">
<a href="#standalone">Milvus standalone</a> <a href="#cluster">Milvus cluster</a>
</div>

<div class="table-wrapper filter-standalone" markdown="block">

```Shell
helm upgrade my-release milvus/milvus --reuse-values --set standalone.resources.limits.cpu=2 --set standalone.resources.limits.memory=4Gi --set standalone.resources.requests.cpu=0.1 --set standalone.resources.requests.memory=128Mi
```

</div>

<div class="table-wrapper filter-cluster" markdown="block">

```Shell
helm upgrade my-release milvus/milvus --reuse-values --set dataNode.resources.limits.cpu=2 --set dataNode.resources.limits.memory=4Gi --set dataNode.resources.requests.cpu=0.1 --set dataNode.resources.requests.memory=128Mi
```

</div>

You can also allocate CPU and memory resources by specifying the parameters `resources.requests` and `resources.limits` in the **resources.yaml** file:

```Yaml
dataNode:
  resources:
    limits:
      cpu: "4"
      memory: "16Gi"
    requests:
      cpu: "1"
      memory: "4Gi"
queryNode:
  resources:
    limits:
      cpu: "4"
      memory: "16Gi"
    requests:
      cpu: "1"
      memory: "4Gi"
```

#### Apply the new configuration to the cluster

```Shell
helm upgrade my-release milvus/milvus --reuse-values -f resources.yaml
```
<div class="alert note">
If <code>resources.limits</code> is not specified, the pods will consume all the CPU and memory resources available. Therefore, please specify <code>resources.requests</code> and <code>resources.limits</code> to avoid overallocation of resources when there are other tasks on the same instance that require more memory consumption.
</div>
 
 

## Migrate ##
### HDF5 to Milvus ###


#### Migrate Data from HDF5 to Milvus

This topic describes how to import data in HDF5 files into Milvus using [MilvusDM](migrate_overview.md), an open-source tool specifically designed for Milvus data migration. 

#### Prerequisites

You need to [install MilvusDM](milvusdm_install.md) before migrating Milvus data.

#### 1. Download YAML file

Download the `M2H.yaml` file.

```
$ wget https://raw.githubusercontent.com/milvus-io/milvus-tools/main/yamls/M2H.yaml
```

#### 2. Set the parameters

Configuration parameters include:

| Parameter                 | Description                               | Example                      |
| ------------------------- | ----------------------------------------- | ---------------------------- |
| `milvus_version`          |  Version of Milvus.                       | 2.0.0                       |
| `data_path`               |  Path to the HDF5 files. Set either `data_path` or `data_dir`.                      | - /Users/zilliz/float_1.h5 <br/> - /Users/zilliz/float_2.h5                   |
| `data_dir`         |  Directory of the HDF5 files. Set either `data_path` or `data_dir`.                      | '/Users/zilliz/Desktop/HDF5_data'                     |
| `dest_host`          |  Milvus server address.                      | '127.0.0.1'     |
| `dest_port`          |  Milvus server port.                       | 19530                      |
| `mode`         |  Mode of migration, including `skip`, `append`, and `overwrite`. This parameter works only when the specified collection name exists in the Milvus library. <br/> <li>`skip` refers to skipping data migration if the specified collection or partition already exists.</li> <li>`append` refers to appending data if the specified collection or partition already exists.</li> <li>`overwrite` refers to deleting existing data before insertion if the specified collection or partition already exists.</li>                    | 'append'                     |
| `dest_collection_name`          | Name of the collection to import data to.                      | 'test_float'                       |
| `dest_partition_name` (optional)        |  Name of the partition to import data to.                   | 'partition_1'                 |
| `collection_parameter`         |  Collection-specific information including vector dimension, index file size, and similarity metric.                      | "dimension: 512 <br/> index_file_size: 1024 <br/> metric_type: 'HAMMING'"                     |


The following two examples of configuration are for your reference. The first example sets the parameter `data_path` while the second sets `data_dir`. You can set either `data_path` or `data_dir` according to your need.

#### Example 1

```
H2M:
  milvus-version: 2.0.0
  data_path:
    - /Users/zilliz/float_1.h5
    - /Users/zilliz/float_2.h5
  data_dir:
  dest_host: '127.0.0.1'
  dest_port: 19530
  mode: 'overwrite'        #### 'skip/append/overwrite'
  dest_collection_name: 'test_float'
  dest_partition_name: 'partition_1'
  collection_parameter:
    dimension: 128
    index_file_size: 1024
    metric_type: 'L2'
```

#### Example 2

```
H2M:
  milvus_version: 2.0.0
  data_path:
  data_dir: '/Users/zilliz/HDF5_data'
  dest_host: '127.0.0.1'
  dest_port: 19530
  mode: 'append'        #### 'skip/append/overwrite'
  dest_collection_name: 'test_binary'
  dest_partition_name: 
  collection_parameter:
    dimension: 512
    index_file_size: 1024
    metric_type: 'HAMMING'
```

#### 3. Migrate data from HDF5 to Milvus

Run MilvusDM to import data in HDF5 files into Milvus with the following command.

```
$ milvusdm --yaml H2M.yaml
```



#### What's next
- If you are interested in migrating data in other forms into Milvus,
  - Learn how to [Migrate Data from Faiss to Milvus](f2m.md).
- If you are looking for information about how migrate data from Milvus 1.x to Milvus 2.0,
  - Learn [version migration](m2m.md).
- If you are interested in learning more about the data migration tool,
  - Read the overview of [MilvusDM](migrate_overview.md).

### Faiss to Milvus  ###


#### Migrate Data from Faiss to Milvus

This topic describes how to import data from Faiss to Milvus using [MilvusDM](migrate_overview.md), an open-source tool specifically designed for Milvus data migration. 

#### Prerequisites

You need to [install MilvusDM](milvusdm_install.md) before migrating Milvus data.

#### 1. Download YAML file

Download the `F2M.yaml` file.

```
$ wget https://raw.githubusercontent.com/milvus-io/milvus-tools/main/yamls/F2M.yaml
```

#### 2. Set the parameters

Configuration parameters include:

| Parameter                 | Description                               | Example                      |
| ------------------------- | ----------------------------------------- | ---------------------------- |
| `milvus_version`          |  Version of Milvus.                       | 2.0.0                     |
| `data_path`               | Path to the data in Faiss.                   | '/home/user/data/faiss.index'                   |
| `data_dir`         |  Directory of the HDF5 files. Set either `data_path` or `data_dir`.                      | '/Users/zilliz/Desktop/HDF5_data'                     |
| `dest_host`          |  Milvus server address.                      | '127.0.0.1'     |
| `dest_port`          |  Milvus server port.                       | 19530                      |
| `mode`         |  Mode of migration, including `skip`, `append`, and `overwrite`. This parameter works only when the specified collection name exists in the Milvus library. <br/> <li>`skip` refers to skipping data migration if the specified collection or partition already exists.</li> <li>`append` refers to appending data if the specified collection or partition already exists.</li> <li>`overwrite` refers to deleting existing data before insertion if the specified collection or partition already exists.</li>                    | 'append'                     |
| `dest_collection_name`          | Name of the collection to import data to.                      | 'test'                       |
| `dest_partition_name` (optional)        |  Name of the partition to import data to.                   | 'partition'                 |
| `collection_parameter`         |  Collection-specific information including vector dimension, index file size, and similarity metric.                      | "dimension: 512 <br/> index_file_size: 1024 <br/> metric_type: 'HAMMING'"                     |

#### Example 

The following example of configuration is for your reference. 

```
F2M:
  milvus_version: 2.0.0
  data_path: '/home/data/faiss1.index'
  dest_host: '127.0.0.1'
  dest_port: 19530
  mode: 'append'
  dest_collection_name: 'test'
  dest_partition_name: ''
  collection_parameter:
    dimension: 256
    index_file_size: 1024
    metric_type: 'L2'
```


#### 3. Migrate data from HDF5 to Milvus

Run MilvusDM to import data from Faiss to Milvus with the following command.

```
$ milvusdm --yaml F2M.yaml
```



#### What's next
- If you are interested in migrating data in other forms into Milvus,
  - Learn how to [Migrate Data from HDF5 to Milvus](h2m.md).
- If you are looking for information about how migrate data from Milvus 1.x to Milvus 2.0,
  - Learn [version migration](m2m.md).
- If you are interested in learning more about the data migration tool,
  - Read the overview of [MilvusDM](migrate_overview.md).

### Milvus 1.x to 2.0 ###


#### Version Migration
This topic describes how to migrate data from Milvus 1.x to Milvus 2.0 using [MilvusDM](migrate_overview.md), an open-source tool specifically designed for Milvus data migration. 

<div class="alert note">
MilvusDM does not support migrating data from Milvus 2.0 standalone to Milvus 2.0 cluster.
</div>


#### Prerequisites

You need to [install MilvusDM](milvusdm_install.md) before migrating Milvus data.

#### 1. Download YAML file

Download the `M2M.yaml` file.

```
$ wget https://raw.githubusercontent.com/milvus-io/milvus-tools/main/yamls/M2M.yaml
```

#### 2. Set the parameters

Configuration parameters include:

| Parameter                 | Description                               | Example                      |
| ------------------------- | ----------------------------------------- | ---------------------------- |
| `milvus_version`          |  Version of Milvus.                       | 2.0.0                       |
| `data_path`               |  Path to the HDF5 files. Set either `data_path` or `data_dir`.                      | - /Users/zilliz/float_1.h5 <br/> - /Users/zilliz/float_2.h5                   |
| `data_dir`         |  Directory of the HDF5 files. Set either `data_path` or `data_dir`.                      | '/Users/zilliz/Desktop/HDF5_data'                     |
| `dest_host`          |  Milvus server address.                      | '127.0.0.1'     |
| `dest_port`          |  Milvus server port.                       | 19530                      |
| `mode`         |  Mode of migration, including `skip`, `append`, and `overwrite`. This parameter works only when the specified collection name exists in the Milvus library. <br/> <li>`skip` refers to skipping data migration if the specified collection or partition already exists.</li> <li>`append` refers to appending data if the specified collection or partition already exists.</li> <li>`overwrite` refers to deleting existing data before insertion if the specified collection or partition already exists.</li>                    | 'append'                     |
| `dest_collection_name`          | Name of the collection to import data to.                      | 'test_float'                       |
| `dest_partition_name` (optional)         |  Name of the partition to import data to.                  | 'partition_1'                 |
| `collection_parameter`         |  Collection-specific information including vector dimension, index file size, and similarity metric.                      | "dimension: 512 <br/> index_file_size: 1024 <br/> metric_type: 'HAMMING'"                     |


The following two examples of configuration are for your reference. The first example involves setting `mysql_parameter`. If you do not use MySQL for managing vector IDs in Milvus 1.x, refer to the second example.

#### Example 1

```
M2M:
  milvus_version: 2.0.0
  source_milvus_path: '/home/user/milvus'
  mysql_parameter:
    host: '127.0.0.1'
    user: 'root'
    port: 3306
    password: '123456'
    database: 'milvus'
  source_collection: #### specify the 'partition_1' and 'partition_2' partitions of the 'test' collection.
    test:
      - 'partition_1'
      - 'partition_2'
  dest_host: '127.0.0.1'
  dest_port: 19530
  mode: 'skip' #### 'skip/append/overwrite'
```

#### Example 2

```
M2M:
  milvus_version: 2.0.0
  source_milvus_path: '/home/user/milvus'
  mysql_parameter:
  source_collection: #### specify the collection named 'test'
    test:
  dest_host: '127.0.0.1'
  dest_port: 19530
  mode: 'skip' #### 'skip/append/overwrite'
```

#### 3. Migrate data from Milvus to Milvus

Run MilvusDM to import data from Milvus 1.x to Milvus 2.0 with the following command.

```
$ milvusdm --yaml M2M.yaml
```



#### What's next
- If you are interested in migrating data in other forms into Milvus,
  - Learn how to [Migrate Data from Faiss to Milvus](f2m.md).
  - Learn how to [Migrate from HDF5 to Milvus](h2m.md).
- If you are interested in learning more about the data migration tool,
  - Read the overview of [MilvusDM](migrate_overview.md).

## Upgrade ##


#### Upgrade Milvus Using Helm Chart

You can easily upgrade Milvus 2.0 with Helm Chart. This guide uses the example of upgrading from Milvus v2.0.0-rc4 to v2.0.0-rc5-hotfix1.

<div class="alert note">
Helm Chart does not support upgrading from Milvus 2.0 standalone to Milvus 2.0 cluster or vice versa.
Versions prior to v2.0.0-rc7 does not support upgrading to v2.0.0-rc7.
</div>

#### Upgrade Milvus standalone

1. Run the following command to check your Milvus version:

```
helm list
NAME              NAMESPACE        REVISION        UPDATED                                     STATUS          CHART               APP VERSION
my-release        default          1               2021-09-06 14:46:33.920893 +0800 CST        deployed        milvus-2.1.5        2.0.0-rc.4
```

You can see the `APP VERSION` is **2.0.0-rc4**.

2. Check the running pods:

```
kubectl get pods
NAME                                            READY   STATUS    RESTARTS   AGE
my-release-etcd-0                               1/1     Running   0          110s
my-release-milvus-standalone-66f985d5cd-q5qhj   1/1     Running   0          110s
my-release-minio-5564fbbddc-dw77v               1/1     Running   0          110s
```

3. Check the image tag for the pod `my-release-milvus-standalone-66f985d5cd-q5qhj`:

```
kubectl get pods my-release-milvus-standalone-66f985d5cd-q5qhj -o=jsonpath='{$.spec.containers[0].image}'
milvusdb/milvus:v2.0.0-rc4-20210811-bdb8396
```

You can see the Milvus standalone version is **v2.0.0-rc4**.

4. Run the following commmand to check new Milvus versions:

```
helm search repo milvus --versions
NAME                 CHART VERSION        APP VERSION               DESCRIPTION
milvus/milvus        2.1.14               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.13               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.12               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.11               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.10               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.9                2.0.0-rc.5                Milvus is an open-source vector database built ...
milvus/milvus        2.1.8                2.0.0-rc.5                Milvus is an open-source vector database built ...
milvus/milvus        2.1.7                2.0.0-rc.5                Milvus is an open-source vector database built ...
milvus/milvus        2.1.6                2.0.0-rc.5                Milvus is an open-source vector database built ...
milvus/milvus        2.1.5                2.0.0-rc.4                Milvus is an open-source vector database built ...
milvus/milvus        2.1.4                2.0.0-rc.4                Milvus is an open-source vector database built ...
milvus/milvus        2.1.3                2.0.0-rc.3                Milvus is an open-source vector database built ...
milvus/milvus        2.1.2                2.0.0-rc.2                Milvus is an open-source vector database built ...
```

You can see there are several new versions after **v2.0.0-rc4**.

5. Upgrade to **v2.0.0-rc5-hotfix1**:

```
helm repo update
helm upgrade my-release milvus/milvus
helm list
NAME              NAMESPACE        REVISION        UPDATED                                     STATUS          CHART                APP VERSION
my-release        default          2               2021-09-06 15:01:24.570561 +0800 CST        deployed        milvus-2.1.14        2.0.0-rc.5-hotfix1
```

You can see the new pods:

```
kubectl get pods
NAME                                            READY   STATUS    RESTARTS   AGE
my-release-etcd-0                               1/1     Running   0          46m
my-release-milvus-standalone-546649bcdf-xqjd5   1/1     Running   0          31m
my-release-minio-744dd9586f-drjnr               1/1     Running   0          31m
```

<div class="alert note">
To upgrade Milvus standalone, old pods will be deleted first. Therefore, the service may be offline for a short period of time.
</div>

6. Check the image version and you can see it is **v2.0.0-rc5-hotfix1**.

```
kubectl get pods my-release-milvus-standalone-546649bcdf-xqjd5 -o=jsonpath='{$.spec.containers[0].image}'
milvusdb/milvus:v2.0.0-rc5-hotfix1-20210901-9e0b2cc
```

#### Upgrade Milvus cluster

1. Run the following command to check your Milvus version:

```
helm list
NAME              NAMESPACE        REVISION        UPDATED                                     STATUS          CHART               APP VERSION
my-release        default              1               2021-09-06 15:54:26.352545 +0800 CST        deployed        milvus-2.1.5        2.0.0-rc.4
```

You can see the `APP VERSION` is **2.0.0-rc4**.

2. Check the running pods:

```
kubectl get pods
NAME                                            READY   STATUS    RESTARTS   AGE
my-release-etcd-0                               1/1     Running   0          45s
my-release-milvus-datacoord-7bb8dff5d4-927mg    1/1     Running   0          45s
my-release-milvus-datanode-6686c99547-29mgt     1/1     Running   0          45s
my-release-milvus-indexcoord-6cdc5f6475-2lrhk   1/1     Running   0          45s
my-release-milvus-indexnode-76f58c956d-6kzl4    1/1     Running   0          45s
my-release-milvus-proxy-84dcb766c9-l8srs        1/1     Running   0          45s
my-release-milvus-pulsar-6b9754c64d-qvsdk       1/1     Running   0          45s
my-release-milvus-querycoord-568595ccbd-pbhbr   1/1     Running   0          45s
my-release-milvus-querynode-5f75d8dbcd-5ns8j    1/1     Running   0          45s
my-release-milvus-rootcoord-746bf864b8-8twzl    1/1     Running   0          45s
my-release-minio-5564fbbddc-l92wt               1/1     Running   0          45s
```

3. Check the image tag for the pod `my-release-milvus-proxy-84dcb766c9-l8srs`:

```
kubectl get pods my-release-milvus-proxy-84dcb766c9-l8srs -o=jsonpath='{$.spec.containers[0].image}'
milvusdb/milvus:v2.0.0-rc4-20210811-bdb8396
```

You can see the version of Milvus cluster is **v2.0.0-rc4**.

4. Run the following command to check new Milvus versions:

```
helm search repo milvus --versions
NAME                 CHART VERSION        APP VERSION               DESCRIPTION
milvus/milvus        2.1.14               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.13               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.12               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.11               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.10               2.0.0-rc.5-hotfix1        Milvus is an open-source vector database built ...
milvus/milvus        2.1.9                2.0.0-rc.5                Milvus is an open-source vector database built ...
milvus/milvus        2.1.8                2.0.0-rc.5                Milvus is an open-source vector database built ...
milvus/milvus        2.1.7                2.0.0-rc.5                Milvus is an open-source vector database built ...
milvus/milvus        2.1.6                2.0.0-rc.5                Milvus is an open-source vector database built ...
milvus/milvus        2.1.5                2.0.0-rc.4                Milvus is an open-source vector database built ...
milvus/milvus        2.1.4                2.0.0-rc.4                Milvus is an open-source vector database built ...
milvus/milvus        2.1.3                2.0.0-rc.3                Milvus is an open-source vector database built ...
milvus/milvus        2.1.2                2.0.0-rc.2                Milvus is an open-source vector database built ...
```

You can see there are several new versions after **2.0.0-rc4**.

5. Upgrade to **v2.0.0-rc5-hotfix1**:

```
helm repo update
helm upgrade my-release milvus/milvus --set cluster.enabled=true
NAME              NAMESPACE        REVISION        UPDATED                                     STATUS          CHART                APP VERSION
my-release        default          2               2021-09-06 16:18:40.021412 +0800 CST        deployed        milvus-2.1.14        2.0.0-rc.5-hotfix1
```

You can see the new pods:

```
kubectl get pods
my-release-etcd-0                               1/1     Running   0          30m
my-release-milvus-datacoord-84cf6cccf5-7r68v    1/1     Running   0          79s
my-release-milvus-datanode-5bcc4978c6-5pjvg     1/1     Running   0          79s
my-release-milvus-indexcoord-5b999ddcd8-mktjz   1/1     Running   0          79s
my-release-milvus-indexnode-689f94657f-gbj8m    1/1     Running   0          79s
my-release-milvus-proxy-99fb7bc58-r4xpf         1/1     Running   0          79s
my-release-milvus-pulsar-769745f67b-t6tcz       1/1     Running   0          78s
my-release-milvus-querycoord-764b6599b7-shlxp   1/1     Running   0          78s
my-release-milvus-querynode-c7f875b57-96qp8     1/1     Running   0          78s
my-release-milvus-rootcoord-79cd9cf4c5-tnxdk    1/1     Running   0          78s
my-release-minio-744dd9586f-gdxwj               1/1     Running   0          6m13s
```

6. Check the image version and you can see it is **v2.0.0-rc5**.

```
kubectl get pods my-release-milvus-proxy-99fb7bc58-r4xpf -o=jsonpath='{$.spec.containers[0].image}'
milvusdb/milvus:v2.0.0-rc5-hotfix1-20210901-9e0b2cc
```

## Tools ##
### Milvus CLI ###
#### Overview ####

#### Milvus Command-Line Interface
Milvus Command-Line Interface (CLI) is a command-line tool that supports database connection, data operations, and import and export of data. Based on [Milvus Python SDK](https://github.com/milvus-io/pymilvus), it allows the execution of commands through a terminal using interactive command-line prompts.
#### Recommended version
In the following table, you can find the recommended versions of PyMilvus and Milvus CLI according to the version of Milvus that you use.

|Milvus| PyMilvus| Milvus CLI|
|:----:|:----:|:----:|
| 1.0.x | 1.0.1 | x |
| 1.1.x | 1.1.2 | x |
| 2.0.0-RC1 | 2.0.0rc1 | x |
| 2.0.0-RC2 | 2.0.0rc2 | 0.1.3 |
| 2.0.0-RC4 | 2.0.0rc4 | 0.1.4 |
| 2.0.0-RC5 | 2.0.0rc5 | 0.1.5 |
| 2.0.0-RC6 | 2.0.0rc6 | 0.1.6 |
|2.0.0-RC7  | 2.0.0rc7 | 0.1.7|

<div class="alert note">Milvus 2.0.0-RC7 is not backward compatible due to changes made to storage formats.</div>

#### Current version

The current version of Milvus CLI is 0.1.7. 
To find your installed version and see if you need to update, run ```shell milvus_cli --version```.


#### Installation ####

#### Install Milvus CLI
The current version of Milvus CLI is 0.1.7. To find your installed version and see if you need to update, run ```shell milvus_cli --version```.

#### Prerequisites

  - Install [Python 3.8.5](https://www.python.org/downloads/release/python-385/) or later
  - Install [pip](https://pip.pypa.io/en/stable/installation/)
#### Install 
You can install Milvus CLI from [PyPI](https://pypi.org/project/milvus-cli/) or source code. We recommend that you install Milvus CLI from PyPI.

#### Install from PyPI

Run the following command to install Milvus CLI.
```shell
pip install milvus-cli
```
#### Install from source code

1. Run the following command to download an installation package.

```shell
git clone https://github.com/milvus-io/milvus_cli.git
```
<div class ="alert note">You can also download it at <a href="https://github.com/milvus-io/milvus_cli/releases"> GitHub</a>. </div>

2. Run the following command to enter the milvus_cli folder.

```shell
cd milvus_cli
```
3. Run the following command to install Milvus CLI.

```shell
python -m pip install --editable .
```


#### Commands ####

#### Milvus CLI Command Reference

Milvus Command-Line Interface (CLI) is a command-line tool that supports database connection, data operations, and import and export of data. 

This topic introduces all supported commands and the corresponding options. Some examples are also included for your reference.

#### calc
Calculates the distance between two vector arrays.
#### Syntax
```shell
calc
```
#### Options
|Option|Full name|Description|
|:---|:---|:---|
|--help|n/a|Displays help for using the command.|

#### Example
To calculate the distance between two vector arrays and be prompted for the required input:
```shell
milvus_cli > calc

Import left operator vectors from existing collection? [y/N]: n

The vector's type (float_vectors, bin_vectors): float_vectors

Left vectors:
    [[0.083, 0.992, 0.931, 0.433, 0.93, 0.706, 0.668, 0.481, 0.255, 0.088, 
    0.121, 0.701, 0.935, 0.142, 0.012, 0.197, 0.066, 0.864, 0.263, 0.732, 
    0.445, 0.672, 0.184, 0.675, 0.361, 0.115, 0.396, 0.206, 0.084, 0.274, 
    0.523, 0.958, 0.071, 0.646, 0.864, 0.434, 0.212, 0.5, 0.319, 0.608, 
    0.356, 0.745, 0.672, 0.488, 0.221, 0.485, 0.193, 0.557, 0.546, 0.626, 
    0.593, 0.526, 0.404, 0.795, 0.076, 0.156, 0.231, 0.1, 0.18, 0.796, 
    0.716, 0.752, 0.816, 0.363], [0.284, 0.135, 0.172, 0.198, 0.752, 0.174, 
    0.314, 0.18, 0.672, 0.727, 0.062, 0.611, 0.921, 0.851, 0.238, 0.648, 
    0.794, 0.177, 0.639, 0.339, 0.402, 0.977, 0.887, 0.528, 0.768, 0.16, 
    0.698, 0.016, 0.906, 0.261, 0.902, 0.93, 0.547, 0.146, 0.65, 0.072, 
    0.876, 0.645, 0.303, 0.922, 0.807, 0.093, 0.063, 0.344, 0.667, 0.81, 
    0.662, 0.147, 0.242, 0.641, 0.903, 0.714, 0.637, 0.365, 0.512, 0.267, 
    0.577, 0.809, 0.698, 0.62, 0.768, 0.402, 0.922, 0.592]] 

Import right operator vectors from existing collection? [y/N]: n

The vector's type (float_vectors, bin_vectors): float_vectors

Right vectors: 
    [[0.518, 0.034, 0.786, 0.251, 0.04, 0.247, 0.55, 0.595, 0.638, 0.957, 
    0.303, 0.023, 0.007, 0.712, 0.841, 0.648, 0.807, 0.429, 0.402, 0.904, 
    0.002, 0.882, 0.69, 0.268, 0.732, 0.511, 0.942, 0.202, 0.749, 0.234, 
    0.666, 0.517, 0.787, 0.399, 0.565, 0.457, 0.57, 0.937, 0.712, 0.981, 
    0.928, 0.678, 0.154, 0.775, 0.754, 0.532, 0.074, 0.493, 0.288, 0.229, 
    0.9, 0.657, 0.936, 0.184, 0.478, 0.587, 0.592, 0.84, 0.793, 0.985, 
    0.826, 0.595, 0.947, 0.175], [0.704, 0.02, 0.937, 0.249, 0.431, 0.99, 
    0.779, 0.855, 0.731, 0.665, 0.773, 0.647, 0.135, 0.44, 0.621, 0.329, 
    0.718, 0.003, 0.927, 0.511, 0.515, 0.359, 0.744, 0.828, 0.31, 0.161, 
    0.605, 0.539, 0.331, 0.077, 0.503, 0.668, 0.275, 0.72, 0.172, 0.035, 
    0.88, 0.762, 0.646, 0.727, 0.83, 0.001, 0.085, 0.188, 0.583, 0.709, 
    0.134, 0.683, 0.246, 0.214, 0.863, 0.109, 0.168, 0.539, 0.451, 0.303, 
    0.064, 0.575, 0.547, 0.85, 0.75, 0.789, 0.681, 0.735], [0.648, 0.769, 
    0.525, 0.716, 0.752, 0.199, 0.095, 0.222, 0.767, 0.029, 0.244, 0.527, 
    0.496, 0.691, 0.487, 0.83, 0.546, 0.102, 0.845, 0.096, 0.744, 0.758, 
    0.092, 0.289, 0.139, 0.005, 0.204, 0.245, 0.528, 0.607, 0.446, 0.029, 
    0.686, 0.558, 0.705, 0.451, 0.87, 0.404, 0.824, 0.727, 0.058, 0.283, 
    0.512, 0.682, 0.027, 0.026, 0.809, 0.669, 0.241, 0.103, 0.101, 0.225, 
    0.989, 0.662, 0.917, 0.972, 0.93, 0.447, 0.318, 0.434, 0.437, 0.036, 
    0.009, 0.96], [0.726, 0.418, 0.404, 0.244, 0.618, 0.356, 0.07, 0.842, 
    0.137, 0.967, 0.465, 0.811, 0.027, 0.704, 0.935, 0.546, 0.92, 0.125, 
    0.917, 0.089, 0.463, 0.929, 0.289, 0.721, 0.368, 0.837, 0.14, 0.431, 
    0.495, 0.75, 0.484, 0.083, 0.431, 0.392, 0.177, 0.303, 0.013, 0.317, 
    0.593, 0.047, 0.695, 0.185, 0.633, 0.825, 0.203, 0.619, 0.597, 0.152, 
    0.899, 0.061, 0.512, 0.67, 0.82, 0.52, 0.743, 0.07, 0.99, 0.119, 
    0.949, 0.284, 0.529, 0.65, 0.523, 0.059]]

Supported metric type. Default is "L2" (L2, IP, HAMMING, TANIMOTO) [L2]:
L2

sqrt [False]: True

Timeout(optional) []:

======
Return type:
Assume the vectors_left: L_1, L_2, L_3
Assume the vectors_right: R_a, R_b
Distance between L_n and R_m we called "D_n_m"
The returned distances are arranged like this:
[[D_1_a, D_1_b],
[D_2_a, D_2_b],
[D_3_a, D_3_b]]

Note: if some vectors do not exist in collection, the returned distance is "-1.0"
======

Result:

[[3.625464916229248, 3.234992742538452, 3.568333148956299, 3.694913148880005], [2.556027889251709, 2.8901233673095703, 3.385758399963379, 3.3239054679870605]]
```
#### clear
Clears the screen.

<h2 id="clear">Syntax</h2>

```shell
clear
```
<h2 id="clear">Options</h2>

|Option|Full name|Description|
|:---|:---|:---|
|--help|n/a|Displays help for using the command.|

#### connect 
Connects to Milvus.

<h2 id="connect">Syntax</h2>

```shell
connect [-h (text)] [-p (int)] [-a (text)]
```
<h2 id="connect">Options</h2>

|Option|Full name|Description
|:---|:---|:---|
|-h|--host|(Optional) The host name. The default is "127.0.0.1".
|-p|--port|(Optional) The port number. The default is "19530".|
|-a|--alias|(Optional) The alias name of the Milvus link. The default is "default".|
|--help|n/a|Displays help for using the command.|

<h2 id="connect"> Example</h2>

```shell
milvus_cli > connect -h 127.0.0.1 -p 19530 -a default
```
#### create alias
Specifies unique aliases for a collection.
<div class="alert note">A collection can have multiple aliases. However, an alias corresponds to a maximum of one collection.</div>

#### Syntax
```shell
create alias -c (text) -a (text) [-A] [-t (float)]
```

#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|-a|--alias-name|The alias.|
|-A|--alter|(Optional) Flag to transfer the alias to a specified collection.|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|--help|n/a|Displays help for using the command.|

#### Examples
##### Example 1

The following example creates the <code>carAlias1</code> and <code>carAlias2</code> aliases for the <code>car</code> collection.
```shell
milvus_cli > create alias -c car -a carAlias1 -a carAlias2
```
##### Example 2

<div class="alert note">Example 2 is based on Example 1.</div>

The following example transfers the <code>carAlias1</code> and <code>carAlias2</code> aliases from the <code>car</code> collection to the <code>car2</code> collection.
```shell
milvus_cli > create alias -c car2 -A -a carAlias -a carAlias2
```

#### create collection
Creates a collection.
#### Syntax
```shell
create collection -c (text) -f (text) -p (text) [-a] [-d (text)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The nam of the collection.|
|-f|--schema-field|(Multiple) The field schema in the    ```<fieldName>:<dataType>:<dimOfVector/desc>``` format.|
|-p|--schema-primary-field|The name of the primary key field.|
|-a|--schema-auto-id|(Optional) Flag to generate IDs automatically.|
|-d|--schema-description|(Optional) The description of the collection.|
|--help|n/a|Displays help for using the command.


#### Example
```shell
milvus_cli > create collection -c car -f id:INT64:primary_field -f vector:FLOAT_VECTOR:128 -f color:INT64:color -f brand:INT64:brand -p id -a -d 'car_collection'
```

#### create partition
Creates a partition.
#### Syntax
```shell
create partition -c (text) -p (text) [-d (text)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|-p|--partition|The partition name.|
|-d|--description|(Optional) The description of the partition.|
|--help|n/a|Displays help for using the command.|


#### Example
```shell
milvus_cli > create partition -c car -p new_partition -d test_add_partition
```

#### create index
Creates an index for a field.

<div class="alert note"> Currently, a collection supports a maximum of one index.</div>

#### Syntax
```shell
create index
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|--help|n/a|Displays help for using the command.|

#### Example
To create an index for a field and be prompted for the required input:
```shell
milvus_cli > create index

Collection name (car, car2): car2

The name of the field to create an index for (vector): vector

Index type (FLAT, IVF_FLAT, IVF_SQ8, IVF_PQ, RNSG, HNSW, ANNOY): IVF_FLAT

Index metric type (L2, IP, HAMMING, TANIMOTO): L2

Index params nlist: 2

Timeout []:
```
#### delete alias
Deletes an alias for a collection.
#### Syntax
```shell
delete alias -c (text) -a (text) [-t (float)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|-a|--alias-name|The alias.|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|--help|n/a|Displays help for using the command.|


#### delete collection
Deletes a collection.
#### Syntax
```shell
delete collection -c (text) [-t (float)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection to be deleted.|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|--help|n/a|Displays help for using the command.|

#### Example
```shell
milvus_cli > delete collection -c car
```

#### delete partition
Deletes a partition.

#### Syntax
```shell
delete partition -c (text) -p (text) [-t (float)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection that the partition to be deleted belongs to.|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|-p|--partition|The name of the partition to be deleted.|
|--help|n/a|Displays help for using the command.|

#### Example
```shell
milvus_cli > delete partition -c car -p new_partition
```

#### delete index
Deletes an index and the corresponding index files.

<div class="alert note"> Currently, a collection supports a maximum of one index.</div>

#### Syntax
```shell
delete index -c (text) [-t (float)]
```

#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|--help|n/a|Displays help for using the command.|

#### Example
```shell
milvus_cli > delete index -c car
```
#### delete entities (available in Milvus 2.0.0-GA)
Deletes entities.

#### Syntax
``` shell
delete entities -c (text) [-p (text)] [-t (float)]
```

#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|-p|--partition|(Optional) The name of the partition that the entities belong to.|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|--help|n/a|Displays help for using the command.|

#### Example

```shell
milvus_cli > delete entities -c car

The expression to specify entities to be deleted, such as "film_id in [0, 1 ]": film_id in [ 0, 1 ]

You are trying to delete the entities of collection. This action cannot be undone!

Do you want to continue? [y/N]: y
```

#### describe collection
Shows the detailed information of a collection.

#### Syntax
```shell
describe collection -c (text)
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|--help|n/a|Displays help for using the command.|

#### Example
```shell
milvus_cli > describe collection -c test_collection_insert
```
#### describe  partition
Shows the detailed information of a partition.

#### Syntax
```shell
describe partition -c (text) -p (text)
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection that the partition belongs to.|
|-p|--partition|The name of the partition.|
|--help|n/a|Displays help for using the command.|

#### Example
```shell
milvus_cli > describe partition -c test_collection_insert -p _default
```
#### describe index
Shows the detailed information of an index.
<div class="alert note">Currently, a collection supports a maximum of one index.</div>

#### Syntax
```shell
describe index -c (text)
```

#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|--help|n/a|Displays help for using the command.|

#### exit
Closes the command line window.

#### Syntax
```shell
exit
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|--help|n/a|Displays help for using the command.|

#### help
Displays help for using a command.

#### Syntax
```shell
help <command>
```
|Command|Description
|:---|:---|
|calc|Calculates the distance between two vector arrays.|
|clear|Clears the screen.|
|connect|Connects to Milvus.|
|create|Creates a collection, partition, index, or alias.|
|delete|Deletes a collection, partition, index, entity, or alias.|
|describe|Describes a collection, partition, or index.|
|exit|Closes the command line window.|
|help|Displays help for using a command. |
|import|Imports data into a partition.|
|list|Lists collections, partitions, or indexes.|
|load|Loads a collection or partition.|
|query|Shows query results that match all the criteria that you enter.|
|release|Releases a collection or partition.|
|search|Performs a vector similarity search or hybrid search.|
|show|Shows the current collection, progress of entity loading, progress of entity indexing, or segment information. |
|version|Shows the version of Milvus CLI.|

#### import
Imports data into a partition.

#### Syntax
```shell
import -c (text)[-p (text)][-t (float)] <file_path>
```

#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection that the data is inserted into.|
|-p|--partition|(Optional) The name of the partition that the data is inserted into. Not passing this partition option indicates choosing the "_default" partition.|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|--help|n/a|Displays help for using the command.|

#### Example
```shell
milvus_cli > import -c car 'examples/import_csv/vectors.csv'

Reading csv file...  [####################################]  100%

Column names are ['vector', 'color', 'brand']

Processed 50001 lines.

Inserting ...

Insert successfully.
--------------------------  ------------------
Total insert entities:                   50000
Total collection entities:              150000
Milvus timestamp:           428849214449254403
--------------------------  ------------------
```
#### list collections
Lists all collections.

#### Syntax
```shell
list collections [-t (float)][-l (boolean)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|-l|--show-loaded|(Optional) Shows the loaded collections only.|
|--help|n/a|Displays help for using the command.|

#### list indexes
Lists all indexes for a collection.
<div class="alert note"> Currently, a collection supports a maximum of one index. </div>

#### Syntax
```shell
list indexes -c (text)
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|--help|n/a|Displays help for using the command.|

#### list partitions
Lists all partitions of a collection.
#### Syntax
```shell
list partitions -c (text)
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|--help|n/a|Displays help for using the command.|

#### load
Loads a collection or partition from hard drive space into RAM.
#### Syntax
```shell
load -c (text) [-p (text)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection that the partition belongs to.|
|-p|--partition|(Optional/Multiple) The name of the partition.|
|--help|n/a|Displays help for using the command.|


#### query

Shows query results that match all the criteria that you enter.
#### Syntax
```shell
query
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|--help|n/a|Displays help for using the command.|

#### Example
To perform a query and be prompted for the required input:
```shell
milvus_cli > query

Collection name: car

The query expression(field_name in [x,y]): id in [ 427284660842954108, 427284660842954199 ]

Name of partitions that contain entities(split by "," if multiple) []: default

A list of fields to return(split by "," if multiple) []: color, brand
```
#### release
Releases a collection or partition from RAM.
#### Syntax
```shell
release -c (text) [-p (text)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection that the partition belongs to.|
|-p|--partition|(Optional/Multiple) The name of the partition.|
|--help|n/a|Displays help for using the command.|

#### search
Performs a vector similarity search or hybrid search.
#### Syntax
```shell
search
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|--help|n/a|Displays help for using the command.|

#### Examples
##### Example 1
To perform a search on a csv file and be prompted for the required input:
```shell
milvus_cli > search

Collection name (car, test_collection): car

The vectors of search data(the length of data is number of query (nq), the dim of every vector in data must be equal to vector field’s of collection. You can also import a csv file 
out headers): examples/import_csv/search_vectors.csv

The vector field used to search of collection (vector): vector

Metric type: L2

Search parameter nprobe's value: 10

The max number of returned record, also known as topk: 2

The boolean expression used to filter attribute []: id > 0

The names of partitions to search (split by "," if multiple) ['_default'] []: _default

timeout []:

Guarantee Timestamp(It instructs Milvus to see all operations performed before a provided timestamp. If no such timestamp is provided, then Milvus will search all operations performed to date) [0]: 

Travel Timestamp(Specify a timestamp in a search to get results based on a data view) [0]:
```
##### Example 2
To perform a search on an indexed collection and be prompted for the required input:
```shell
milvus_cli > search

Collection name (car, test_collection): car

The vectors of search data(the length of data is number of query (nq), the dim of every vector in data must be equal to vector field’s of collection. You can also import a csv file without headers):
    [[0.71, 0.76, 0.17, 0.13, 0.42, 0.07, 0.15, 0.67, 0.58, 0.02, 0.39, 
    0.47, 0.58, 0.88, 0.73, 0.31, 0.23, 0.57, 0.33, 0.2, 0.03, 0.43, 
    0.78, 0.49, 0.17, 0.56, 0.76, 0.54, 0.45, 0.46, 0.05, 0.1, 0.43, 
    0.63, 0.29, 0.44, 0.65, 0.01, 0.35, 0.46, 0.66, 0.7, 0.88, 0.07, 
    0.49, 0.92, 0.57, 0.5, 0.16, 0.77, 0.98, 0.1, 0.44, 0.88, 0.82, 
    0.16, 0.67, 0.63, 0.57, 0.55, 0.95, 0.13, 0.64, 0.43, 0.71, 0.81, 
    0.43, 0.65, 0.76, 0.7, 0.05, 0.24, 0.03, 0.9, 0.46, 0.28, 0.92, 
    0.25, 0.97, 0.79, 0.73, 0.97, 0.49, 0.28, 0.64, 0.19, 0.23, 0.51, 
    0.09, 0.1, 0.53, 0.03, 0.23, 0.94, 0.87, 0.14, 0.42, 0.82, 0.91, 
    0.11, 0.91, 0.37, 0.26, 0.6, 0.89, 0.6, 0.32, 0.11, 0.98, 0.67, 
    0.12, 0.66, 0.47, 0.02, 0.15, 0.6, 0.64, 0.57, 0.14, 0.81, 0.75, 
    0.11, 0.49, 0.78, 0.16, 0.63, 0.57, 0.18]]

The vector field used to search of collection (vector): vector

Metric type: L2

Search parameter nprobe's value: 10

The specified number of decimal places of returned distance [-1]: 5

The max number of returned record, also known as topk: 2

The boolean expression used to filter attribute []: id > 0

The names of partitions to search (split by "," if multiple) ['_default'] []: _default

timeout []:

Guarantee Timestamp(It instructs Milvus to see all operations performed before a provided timestamp. If no such timestamp is provided, then Milvus will search all operations performed to date) [0]: 

Travel Timestamp(Specify a timestamp in a search to get results based on a data view) [0]:
```
##### Example 3
To perform a search on a non-indexed collection and be prompted for the required input:
```shell
milvus_cli > search

Collection name (car, car2): car

The vectors of search data(the length of data is number of query (nq), the dim of every vector in data must be equal to vector field’s of collection. You can also import a csv file without headers): examples/import_csv/search_vectors.csv

The vector field used to search of collection (vector): vector

The specified number of decimal places of returned distance [-1]: 5

The max number of returned record, also known as topk: 2

The boolean expression used to filter attribute []:

The names of partitions to search (split by "," if multiple) ['_default'] []:

timeout []:

Guarantee Timestamp(It instructs Milvus to see all operations performed before a provided timestamp. If no such timestamp is provided, then Milvus will search all operations performed to date) [0]: 

Travel Timestamp(Specify a timestamp in a search to get results based on a data view) [0]:
```
#### show connection
Shows the current connection.
#### Syntax
```shell
show connection [-a]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-a|--all|（Optional) Flag to show all connections.|
|--help|n/a|Displays help for using the command.|

#### show index_progress
Shows the progress of entity indexing.
#### Syntax
```shell
show index_progress -c (text) [-i (text)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection that the entities belong to.|
|-i|--index|(Optional) The name of the index.|
|--help|n/a|Displays help for using the command.|

#### show loading_progress
Shows the progress of entity loading.
#### Syntax
```shell
show loading_progress -c (text) [-p (text)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection that the entities belong to.|
|-p|--partition|(Optional/Multiple) The name of the loading partition.|
|--help|n/a|Displays help for using the command.|

#### show query_segment
Shows the segment information of a collection.
#### Syntax
```shell
show query_segment -c (text) [-t (float)]
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|-c|--collection-name|The name of the collection.|
|-t|--timeout|(Optional) The maximum allowed duration in seconds of an RPC call. Not passing this option indicates that the client keeps waiting until the server responds or an error occurs.|
|--help|n/a|Displays help for using the command.|

#### version
Shows the version of Milvus CLI.

#### Syntax
```shell
version
```
#### Options
|Option|Full name|Description
|:---|:---|:---|
|--help|n/a|Displays help for using the command.|

<div class="alert note"> You can also check the version of Milvus CLI in a shell as shown in the following example. In this case, <code>milvus_cli --version</code> acts as a command.</div>

#### Example
```shell
$ milvus_cli --version
Milvus Cli v0.1.7
```


### MilvusDM ###
#### Overview ####


[MilvusDM](https://github.com/milvus-io/milvus-tools) (Milvus Data Migration) is an open-source tool designed specifically for importing and exporting data with Milvus. MilvusDM allows you to migrate data in a specific collection or partition. To substantially improve data management efficiency and reduce DevOps costs, MilvusDM supports the following migration channels: 

- [Milvus to Milvus](m2m.md): Migrates data between instances of Milvus.
- [Faiss to Milvus](f2m.md): Imports unzipped data from Faiss to Milvus.
- [HDF5 to Milvus](h2m.md): Imports HDF5 files into Milvus.
- [Milvus to HDF5](m2h.md): Saves the data in Milvus as HDF5 files.

![MilvusDM](../../../assets/milvusdm.jpeg)

MilvusDM is hosted on GitHub. To install MilvusDM, run: 
```
pip3 install pymilvusdm
```

#### MilvusDM File Structure
The flow chart below shows how MilvusDM performs different tasks according to the .yaml file it receives:

![File structure](../../../assets/file_structure.png)

MilvusDM file structure:

- pymilvusdm
  - core
    - **milvus_client.py**: Performs client operations in Milvus.
    - **read_data.py**: Reads the HDF5 files on your local drive. (Add your code here to support reading data files in other formats.)
    - **read_faiss_data.py**: Reads Faiss data files. 
    - **read_milvus_data.py**: Reads Milvus data files. 
    - **read_milvus_meta.py**: Reads Milvus metadata. 
    - **data_to_milvus.py**: Creates collections or partitions as specified in .yaml files and imports vectors and the corresponding IDs into Milvus.
    - **save_data.py**: Saves data as HDF5 files.
    - **write_logs.py**: Writes `debug`/`info`/`error` logs during runtime.
  - **faiss_to_milvus.py**: Imports Faiss data into Milvus.
  - **hdf5_to_milvus.py**: Imports HDF5 files into Milvus.
  - **milvus_to_milvus.py**: Migrates data from a source Milvus to a target Milvus.
  - **milvus_to_hdf5.py**: Saves Milvus data as HDF5 files.
  - **main.py**: Executes tasks as specified by the received .yaml file.
  - **setting.py**: Stores configurations for MilvusDM operation.
- **setup.py**: Creates and uploads pymilvusdm file packages to PyPI (Python Package Index).
#### Enhancement Plan
In future releases, MilvusDM will provide more new features including MilvusDump and MilvusRestore to support exporting all Milvus data, restoring data in specified collections and partitions, resuming interrupted download and more.


<div class="alert note">
The MilvusDM project is open sourced on <a href="https://github.com/milvus-io/milvus-tools">GitHub</a>. Any contribution to the project is welcome. Give it a star 🌟, and feel free to <a href="https://github.com/milvus-io/milvus-tools/issues">file an issue</a> or submit your own code! 
</div>

#### Installation ####


#### Install MilvusDM

MilvusDM is an open-source tool designed specifically for importing and exporting data with Milvus. This page shows you how to install MilvusDM.

<div class="alert note">
  The pymilvusdm2.0 is used for migrating data <b>from Milvus(0.10.x or 1.x) to Milvus2.x</b>.
</div>

#### Before you begin

Ensure you meet the requirements for operating system and software before installing MilvusDM.


| Operating system | Supported versions |
| ---------------  |  ----------------- |
| CentOS           | 7.5 or higher      |
| Ubuntu LTS       | 18.04 or higher    |


| Software                     | Version                        |
|  --------------------------- |  ----------------------------- |
| [Milvus](https://milvus.io/) | 0.10.x or 1.x or 2.x                          |
| Python3                      | 3.7 or higher                  |
| pip3                         | Should be in correspondence to the Python version. |

#### Install MilvusDM

1. Add the following two lines to the **~/.bashrc** file:

```bash
export MILVUSDM_PATH='/home/$user/milvusdm'
export LOGS_NUM=0
```

- `MILVUSDM_PATH`: This parameter defines the working path of MilvusDM. Logs and data generated by MilvusDM will be stored in this path.  The default value is `/home/$user/milvusdm`.

- `LOGS_NUM`： MilvusDM generates one log file each day. This parameter defines the number of log files you would like to save. The default value is 0, which means all log files are saved.

2. Configure environment variables：

```shell
$ source ~/.bashrc
```

3. Install MilvusDM with `pip`:

```shell
$ pip3 install pymilvusdm==2.0
```



### Milvus Insight ###
#### Overview ####



[Milvus Insight](https://github.com/milvus-io/milvus-insight) is an efficient open-source management tool for Milvus. It features an intuitive graphical user interface (GUI), allowing you to easily interact with your databases. With just a few clicks, you can visualize your cluster status, manage metadata, perform data queries, and much more.

![Insight_overview](../../../../assets/insight_overview.png)

#### Features
Milvus Insight is under rapid development and new features are added on a weekly basis. We will release a new version every time when a new feature is ready. 

Below is the features we have to offer:

- View milvus cluster statistics in a glance. (TBD)

![view_cluster_statistics](../../../../assets/view_cluster_statistics.png)

- Browse, query, and manage collections in a simple and straightforward way.

![manage_collections](../../../../assets/manage_collections.png)

- Perform CRUD or bulk operations with just a few clicks. 

![insight_operations](../../../../assets/insight_operations.png)

- Create vector index instantly.

![insight_create_index](../../../../assets/insight_create_index.png)

- Conduct vector searches in a brand new way.

![insight_conduct_search](../../../../assets/insight_conduct_search.png)

- New code-mode provides a better user experience for you.

![code_mode](../../../../assets/code_mode.png)

Learn more about how to [install Milvus Insight](insight_install.md).


#### Contribution
Milvus Insight is an open-source project. All contributions are welcome. Pleae read our [Contribute guide](https://github.com/milvus-io/milvus-insight#-building-and-running-milvus-insight-andor-contributing-code) before making contributions.

If you find a bug or want to request a new feature, please create a [GitHub Issue](https://github.com/milvus-io/milvus-insight/issues/new/choose), and make sure that the same issue has not been created by someone else.


#### Installation ####


#### Install Milvus Insight

Milvus Insight is an efficient open-source management tool for Milvus. This page will show you how to install Milvus Insight to manage your Milvus service.

#### Before you begin

Ensure you have Milvus installed on [your server](https://milvus.io/docs/install_standalone-docker.md) or [cluster](https://milvus.io/docs/install_cluster-docker.md).

<div class="alert note">
Milvus Insight only supports Milvus 2.x.
</div>

####  Start a Milvus Insight instance

```Apache
docker run -p 8000:3000 -e HOST_URL=http://{ your machine IP }:8000 -e MILVUS_URL={your machine IP}:19530 milvusdb/milvus-insight:latest
```

Once you start the docker, open the browser and type `http://{ your machine IP }:8000` to access Milvus Insight.

![Insight_install](../../../../assets/insight_install.png)

#### Contribution
Milvus Insight is an open-source project. All contributions are welcome. Pleae read our [Contribute guide](https://github.com/milvus-io/milvus-insight#-building-and-running-milvus-insight-andor-contributing-code) before making contributions.

If you find a bug or want to request a new feature, please create a [GitHub Issue](https://github.com/milvus-io/milvus-insight/issues/new/choose), and make sure that the same issue has not been created by someone else.


# Reference #
## Architecture ##
### Overview ###


#### Milvus Architecture Overview

Built on top of popular vector search libraries including Faiss, Annoy, HNSW, and more, Milvus was designed for similarity search on dense vector datasets containing millions, billions, or even trillions of vectors. Before proceeding, familiarize yourself with the [basic principles](glossary.md) of embedding retrieval. 

Milvus also supports data sharding, data persistence, streaming data ingestion, hybrid search between vector and scalar data, time travel, and many other advanced functions. The platform offers performance on demand and can be optimized to suit any embedding retrieval scenario. We recommend deploying Milvus using Kubernetes for optimal availability and elasticity. 

Milvus adopts a shared-storage architecture featuring storage and computing disaggregation and horizontal scalability for its computing nodes. Following the principle of data plane and control plane disaggregation, Milvus comprises [four layers](four_layers.md): access layer, coordinator service, worker node, and storage. These layers are mutually independent when it comes to scaling or disaster recovery.

![Architecture_diagram](../../../../assets/architecture_diagram.png)


For more details about Milvus' architecture, see [Computing/Storage Disaggregation](four_layers.md) and [Main Components](main_components.md).

### Storage/Computing ###


#### Storage/Computing Disaggregation



Following the principle of data plane and control plane disaggregation, Milvus comprises four layers that are mutually independent in terms of scalability and disaster recovery.

#### Access layer

Composed of a group of stateless proxies, the access layer is the front layer of the system and endpoint to users. It validates client requests and reduces the returned results: 

- Proxy is in itself stateless. It provides a unified service address using load balancing components such as Nginx, Kubernetes Ingress, NodePort, and LVS. 
- As Milvus employs a massively parallel processing (MPP) architecture, the proxy aggregates and post-process the intermediate results before returning the final results to the client.  

#### Coordinator service

The coordinator service assigns tasks to the worker nodes and functions as the system's brain. The tasks it takes on include cluster topology management, load balancing, timestamp generation, data declaration, and data management. 

There are four coordinator types: root coordinator (root coord), data coordinator (data coord), query coordinator (query coord), and index coordinator (index coord).

#### Root coordinator (root coord)

Root coord handles data definition language (DDL) and data control language (DCL) requests, such as create or delete collections, partitions, or indexes, as well as manage TSO (timestamp Oracle) and time ticker issuing.

#### Query coordinator (query coord)

Query coord manages topology and load balancing for the query nodes, and handoff from growing segments to sealed segments.

#### Data coordinator (data coord)

Data coord manages topology of the data nodes, maintains metadata, and triggers flush, compact, and other background data operations. 

#### Index coordinator (index coord)

Index coord manages topology of the index nodes, builds index, and maintains index metadata.

#### Worker nodes

The arms and legs. Worker nodes are dumb executors that follow instructions from the coordinator service and execute data manipulation language (DML) commands from the proxy. Worker nodes are stateless thanks to separation of storage and computation, and can facilitate system scale-out and disaster recovery when deployed on Kubenetes. There are three types of worker nodes: 

#### Query node

Query node retrieves incremental log data and turn them into growing segments by subscribing to the log broker, loads historical data from the object storage, and runs hybrid search between vector and scalar data. 

#### Data node

Data node retrieves incremental log data by subscribing to the log broker, processes mutation requests, and packs log data into log snapshots and stores them in the object storage. 

#### Index node

Index node builds indexes.  Index nodes do not need to be memory resident, and can be implemented with the serverless framework. 

#### Storage

Storage is the bone of the system, responsible for data persistence. It comprises meta storage, log broker, and object storage.

#### Meta storage

Meta storage stores snapshots of metadata such as collection schema, node status, and message consumption checkpoints. Storing metadata demands extremely high availability, strong consistency, and transaction support, so Milvus chose etcd for meta store. Milvus also uses etcd for service registration and health check. 

#### Object storage

Object storage stores snapshot files of logs, index files for scalar and vector data, and intermediate query results. Milvus uses MinIO as object storage and can be readily deployed on AWS S3 and Azure Blob, two of the world's most popular, cost-effective storage services. However, object storage has high access latency and charges by the number of queries. To improve its performance and lower the costs, Milvus plans to implement cold-hot data separation on a memory- or SSD-based cache pool.

#### Log broker 

The log broker is a pub-sub system that supports playback. It is responsible for streaming data persistence, execution of reliable asynchronous queries, event notification, and return of query results. It also ensures integrity of the incremental data when the worker nodes recover from system breakdown. Milvus cluster uses Pulsar as log broker; Milvus standalone uses RocksDB as log broker. Besides, the log broker can be readily replaced with streaming data storage platforms such as Kafka and Pravega. 

Milvus is built around log broker and follows the "log as data" principle, so Milvus 2.0 does not maintain a physical table but guarantees data reliability through logging persistence and snapshot logs. 

![Log_mechanism](../../../../assets/log_mechanism.png)

The log broker is the backbone of Milvus 2.0. It is responsible for data persistence and read-write disaggregation, thanks to its innate pub-sub mechanism. The above illustration shows a simplified depiction of the mechanism, where the system is divided into two roles, log broker (for maintaining the log sequence) and log subscriber. The former records all operations that change collection states; the latter subscribes to the log sequence to update the local data and provides services in the form of read-only copies. The pub-sub mechanism also makes room for system extendability in terms of change data capture (CDC) and globally-distributed deployment. 


For more details about Milvus' architecture, see [Main Components](main_components.md).

### Main Components ###



There are two modes for running Milvus: Standalone and Cluster. These two modes share the same features. You can choose a mode that best fits your dataset size, traffic data, and more. For now, Milvus standalone cannot be "online" upgraded to Milvus cluster. 

#### Milvus standalone

 Milvus standalone includes three components:

- **Milvus:** The core functional component. 

- **etcd:** The metadata engine, which accesses and stores metadata of Milvus' internal components, including proxies, index nodes, and more. 

- **MinIO:** The storage engine, which is responsible for data persistence for Milvus.

![Standalone_architecture](../../../../assets/standalone_architecture.jpg)

#### Milvus cluster

**Milvus cluster** includes eight microservice components and three third-party dependencies. All microservices can be deployed on Kubernetes, independently from each other. 

#### Microservice components

- Root coord
- Proxy 
- Query coord 
- Query node 
- Index coord 
- Index node 
- Data coord 
- Data node

#### Third-party dependencies

- **etcd:** Stores metadata for various components in the cluster. 
- **MinIO:**  Responsible for data persistence of large files in the cluster, such as index and binary log files. 
- **Pulsar:** Manages logs of recent mutation operations, outputs streaming log, and provides log publish-subscribe services.

![Distributed_architecture](../../../../assets/distributed_architecture.jpg)

For more details about Milvus' architecture, see [Computing/Storage Disaggregation](four_layers.md).

### Data Processing ###



This article provides a detailed description of the implementation of data insertion, index building, and data query in Milvus.

#### Data insertion

You can specify a number of shards for each collection in Milvus, each shard corresponding to a virtual channel (*vchannel*). As the following figure shows, Milvus 2.0 assigns each vchannel in the log broker a physical channel (*pchannel*). Any incoming insert/delete request is routed to shards based on the hash value of primary key.

Validation of DML requests is moved forward to proxy because Milvus does not have complicated transactions. Proxy would request a timestamp for each insert/delete request from TSO (Timestamp Oracle), which is the timing module that colocates with the root coordinator. With the older timestamp being overwritten by the newer one, timestamps are used to determine the sequence of data requests being processed. Proxy retrieves information in batches from data coord including entities' segments and rowIDs to increase overall throughput and avoid overburdening the central node. 

![Channels 1](../../../../assets/channels_1.jpg)

Both DML (data manipulation language) operations and DDL (data definition language) operations are written to the log sequence, but DDL operations are only assigned one channel because of their low frequency of occurrence. 

![Channels 2](../../../../assets/channels_2.jpg)

*Vchannels* are maintained in the underlying log broker nodes. Each channel is physically indivisible and available for any but only one node. When data ingestion rate reaches bottleneck, consider two things: Whether the log broker node is overloaded and needs to be scaled, and whether there are sufficient shards to ensure load balance for each node. 

![Write log sequence](../../../../assets/write_log_sequence.jpg)

The above diagram encapsulates four components involved in the process of writing log sequence: proxy, log broker, data node, and object storage. The process involves four tasks: validation of DML requests, publication-subscription of log sequence, conversion from streaming log to log snapshots, and persistence of log snapshots. The four tasks are decoupled from each other to make sure each task is handled by its corresponding node type. Nodes of the same type are made equal and can be scaled elastically and independently to accommodate various data loads, massive and highly fluctuating streaming data in particular.

#### Index building

Index building is performed by index node. To avoid frequent index building for data updates, a collection in Milvus is divided further into segments, each with its own index.

![Index building](../../../../assets/index_building.jpg)

Milvus supports building index for each vector field, scalar field and primary field. Both the input and output of index building engage with object storage: The index node loads the log snapshots to index from a segment (which is in object storage) to memory, deserializes the corresponding data and metadata to build index, serializes the index when index building completes, and writes it back to object storage.

Index building mainly involves vector and matrix operations and hence is computation- and memory-intensive. Vectors cannot be efficiently indexed with traditional tree-based indexes due to their high-dimensional nature, but can be indexed with techniques that are more mature in this subject, such as cluster- or graph-based indexes. Regardless its type, building index involves massive iterative calculations for large-scale vectors, such as Kmeans or graph traverse.

Unlike indexing for scalar data, building vector index has to take full advantage of SIMD (single instruction, multiple data) acceleration. Milvus has innate support for SIMD instruction sets, e.g., SSE, AVX2, and AVX512. Given the "hiccup" and resource-intensive nature of vector index building, elasticity becomes crucially important to Milvus in economical terms. Future Milvus releases will further explorations in heterogeneous computing and serverless computation to bring down the related costs. 

Besides, Milvus also supports scalar filtering and primary field query. It has inbuilt indexes to improve query efficiency, e.g., Bloom filter indexes, hash indexes, tree-based indexes, and inverted indexes, and plans to introduce more external indexes, e.g., bitmap indexes and rough indexes. 

#### Data query

Data query refers to the process of searching a specified collection for *k* number of vectors nearest to a target vector or for *all* vectors within a specified distance range to the vector. Vectors are returned together with their corresponding rowID and fields. 

![Data query](../../../../assets/data_query.jpg)

A collection in Milvus is split into multiple segments, and the query nodes loads indexes by segment. When a search request arrives, it is broadcast to all query nodes for a concurrent search. Each node then prunes the local segments, searches for vectors meeting the criteria, and reduces and returns the search results. 

Query nodes are independent from each other in a data query. Each node is responsible only for two tasks: Load or release segments following the instructions from query coord; conduct a search within the local segments. And proxy is responsible for reducing search results from each query node and returning the final results to the client. 

![Handoff](../../../../assets/handoff.jpg)

There are two types of segments, growing segments (for incremental data), and sealed segments (for historical data). Query nodes subscribe to vchannel to receive recent updates (incremental data) as growing segments. When a growing segment reaches a predefined threshold, data coord seals it and index building begins. Then a *handoff* operation initiated by query coord turns incremental data to historical data. Query coord will distribute sealed segments evenly among all query nodes according to memory usage, CPU overhead, and segment number.

## System Configurations ##
### Milvus Stanalone ###


#### Milvus Standalone System Configurations

Milvus standalone maintains many system variables that configure the operation. All configurations can be set manually before server startup. Each configuration has a default value, which can be used directly.

<div class="alert note">
All parameters take effect only after being configured at the startup of Milvus.
</div>

<div class="tab-wrapper"><a href="configuration_standalone-basic.md" class='active '>Basic Configurations</a><a href="configuration_standalone-advanced.md" class=''>Advanced Configurations</a></div>


If you are an entry-level user of Milvus, you only need to change the following two configurations to primarily adapt Milvus to your test / development / production environment.

#### Log Configurations

This session configures the system log output. Using Milvus generates a collection of logs. By default, Milvus uses logs to record information at `debug` or even higher level for standard output (stdout) and standard error (stderr). You can set these configurations in [**milvus.yaml**](https://github.com/milvus-io/milvus/blob/master/configs/milvus.yaml) under **milvus/configs** directory.

<table id="casual_user">
<thead>
  <tr>     
    <th class="width20">Configuration</th>     
    <th class="width70">Description</th>     
    <th class="width10">Default Value</th>   
  </tr>
</thead>
<tbody>
  <tr>     
    <td><code>log.level</code></td>
    <td>
      <details>
       <summary>Log level in Milvus</summary>
        <li>
           You can configure this parameter as <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>, <code>panic</code>, or <code>fatal</code>.
        </li> 
        <li>
           We recommend using <code>debug</code> level under test and development environments, and <code>info</code> level in production environment.
         </li>
      </details>
    </td>     
    <td><code>debug</code></td>
  </tr>
  <tr>     
    <td><code>log.file.rootPath</code></td>
    <td>
      <details>
       <summary>Root path to the log files</summary>
        <li>
           The default value is set empty, indicating to output log files to standard output (stdout) and standard error (stderr).
        </li>
        <li>
           If this parameter is set to a valid local path, Milvus log will be written and stored in this path.
        </li>
        <li>
           Set this parameter as the path that you have permission to write. We recommend using <b>/tmp/milvus</b>.
         </li>
      </details>
    </td>     
    <td>""</td>
  </tr>
</tbody>
</table>

### Milvus Cluster ###

#### Milvus Cluster System Configurations

Milvus cluster maintains many system variables that configure the operation. All configurations can be set manually before server startup. Each configuration has a default value, which can be used directly.

<div class="alert note">
All parameters take effect only after being configured at the startup of Milvus.
</div>


<div class="tab-wrapper"><a href="configuration_cluster-basic.md" class='active '>Basic Configurations</a><a href="configuration_cluster-advanced.md" class=''>Advanced Configurations</a></div>


If you are an entry-level user of a Milvus Cluster, you only need to change the following two configurations to primarily adapt Milvus to your test / development / production environment.

#### Log Configurations

This session configures the system log output. Using Milvus generates a collection of logs. By default, Milvus uses logs to record information at `debug` or even higher level for standard output (stdout) and standard error (stderr). You can set these configurations in [**milvus.yaml**](https://github.com/milvus-io/milvus/blob/master/configs/milvus.yaml).

<table id="casual_user">
<thead>
  <tr>     
    <th class="width20">Configuration</th>     
    <th class="width70">Description</th>     
    <th class="width10">Default Value</th>   
  </tr>
</thead>
<tbody>
  <tr>     
    <td><code>log.level</code></td>
    <td>
      <details>
       <summary>Log level in Milvus</summary>
        <li>
           You can configure this parameter as <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>, <code>panic</code>, or <code>fatal</code>.
        </li> 
        <li>
           We recommend using <code>debug</code> level under test and development environments, and <code>info</code> level in production environment.
         </li>
      </details>
    </td>     
    <td><code>debug</code></td>
  </tr>
  <tr>     
    <td><code>log.file.rootPath</code></td>
    <td>
      <details>
       <summary>Root path to the log files</summary>
        <li>
           The default value is set empty, indicating to output log files to standard output (stdout) and standard error (stderr).
        </li>
        <li>
           If this parameter is set to a valid local path, Milvus log will be written and stored in this path.
        </li>
        <li>
           Set this parameter as the path that you have permission to write. We recommend using <b>/tmp/milvus</b>.
         </li>
      </details>
    </td>     
    <td>""</td>
  </tr>
</tbody>
</table>


## Similarity Metrics ##



In Milvus, similarity metrics are used to measure similarities among vectors. Choosing a good distance metric helps improve the classification and clustering performance significantly.

The following table shows how these widely used similarity metrics fit with various input data forms and Milvus indexes.


<div class="filter">
<a href="#floating">Floating point embeddings</a> <a href="#binary">Binary embeddings</a>

</div>

<div class="filter-floating table-wrapper" markdown="block">

<table class="tg">
<thead>
  <tr>
    <th class="tg-0pky" style="width: 204px;">Similarity Metrics</th>
    <th class="tg-0pky">Index Types</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky"><ul><li>Euclidean distance (L2)</li><li>Inner product (IP)</li></td>
    <td class="tg-0pky" rowspan="2"><ul><li>FLAT</li><li>IVF_FLAT</li><li>IVF_SQ8</li><li>IVF_PQ</li><li>HNSW</li><li>ANNOY</li></ul></td>
  </tr>
</tbody>
</table>

</div>

<div class="filter-binary table-wrapper" markdown="block">

<table class="tg">
<thead>
  <tr>
    <th class="tg-0pky" style="width: 204px;">Distance Metrics</th>
    <th class="tg-0pky">Index Types</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky"><ul><li>Jaccard</li><li>Tanimoto</li><li>Hamming</li></ul></td>
    <td class="tg-0pky"><ul><li>BIN_FLAT</li><li>BIN_IVF_FLAT</li></ul></td>
  </tr>
  <tr>
    <td class="tg-0pky"><ul><li>Superstructure</li><li>Substructure</li></ul></td>
    <td class="tg-0pky">BIN_FLAT</td>
  </tr>
</tbody>
</table>

</div>



#### Euclidean distance (L2)

Essentially, Euclidean distance measures the length of a segment that connects 2 points.

The formula for Euclidean distance is as follows:

![euclidean](../../../assets/euclidean_metric.png)

where **a** = (a1, a2,..., an) and **b** = (b1, b2,..., bn) are two points in n-dimensional Euclidean space

It's the most commonly used distance metric and is very useful when the data is continuous.

#### Inner product (IP)

The IP distance between two embeddings are defined as follows: 

![ip](../../../assets/IP_formula.png)

Where A and B are embeddings, `||A||` and `||B||` are the norms of A and B.

IP is more useful if you are more interested in measuring the orientation but not the magnitude of the vectors.

<div class="alert note">
 If you use IP to calculate embeddings similarities, you must normalize your embeddings. After normalization, the inner product equals cosine similarity.
</div>


Suppose X' is normalized from embedding X: 

![normalize](../../../assets/normalize_formula.png)

The correlation between the two embeddings is as follows: 

![normalization](../../../assets/normalization_formula.png)

#### Jaccard distance

Jaccard similarity coefficient measures the similarity between two sample sets and is defined as the cardinality of the intersection of the defined sets divided by the cardinality of the union of them. It can only be applied to finite sample sets.

![Jaccard similarity coefficient](../../../assets/jaccard_coeff.png)

Jaccard distance measures the dissimilarity between data sets and is obtained by subtracting the Jaccard similarity coefficient from 1. For binary variables, Jaccard distance is equivalent to the Tanimoto coefficient.

![Jaccard distance](../../../assets/jaccard_dist.png)

#### Tanimoto distance

For binary variables, the Tanimoto coefficient is equivalent to Jaccard distance:

![tanimoto coefficient](../../../assets/tanimoto_coeff.png)

In Milvus, the Tanimoto coefficient is only applicable for a binary variable, and for binary variables, the Tanimoto coefficient ranges from 0 to +1 (where +1 is the highest similarity).

For binary variables, the formula of Tanimoto distance is:

![tanimoto distance](../../../assets/tanimoto_dist.png)

The value ranges from 0 to +infinity.

#### Hamming distance

Hamming distance measures binary data strings. The distance between two strings of equal length is the number of bit positions at which the bits are different.

For example, suppose there are two strings, 1101 1001 and 1001 1101.

11011001 ⊕ 10011101 = 01000100. Since, this contains two 1s, the Hamming distance, d (11011001, 10011101) = 2.

#### Superstructure

The Superstructure is used to measure the similarity of a chemical structure and its superstructure. The less the value, the more similar the structure is to its superstructure. Only the vectors whose distance equals to 0 can be found now.

Superstructure similarity can be measured by:

![superstructure](../../../assets/superstructure.png)

Where

- B is the superstructure of A
- N<sub>A</sub> specifies the number of bits in the fingerprint of molecular A.
- N<sub>B</sub> specifies the number of bits in the fingerprint of molecular B.
- N<sub>AB</sub> specifies the number of shared bits in the fingerprint of molecular A and B.

#### Substructure

The Substructure is used to measure the similarity of a chemical structure and its substructure. The less the value, the more similar the structure is to its substructure. Only the vectors whose distance equals to 0 can be found now.

Substructure similarity can be measured by:

![substructure](../../../assets/substructure.png)

Where

- B is the substructure of A
- N<sub>A</sub> specifies the number of bits in the fingerprint of molecular A.
- N<sub>B</sub> specifies the number of bits in the fingerprint of molecular B.
- N<sub>AB</sub> specifies the number of shared bits in the fingerprint of molecular A and B.

#### FAQ

<details>
<summary><font color="#4fc4f9">Why is the top1 result of a vector search not the search vector itself, if the metric type is inner product?</font></summary>
This occurs if you have not normalized the vectors when using inner product as the distance metric.
</details>
<details>
<summary><font color="#4fc4f9">What is normalization? Why is normalization needed?</font></summary>
<p>Normalization refers to the process of converting an embedding (vector) so that its norm equals 1. If you use Inner Product to calculate embeddings similarities, you must normalize your embeddings. After normalization, inner product equals cosine similarity.
</p>
<p>
See <a href="https://en.wikipedia.org/wiki/Unit_vector">Wikipedia</a> for more information.
</p>
</details>
<details>
<summary><font color="#4fc4f9">Why do I get different results using Euclidean distance (L2) and inner product (IP) as the distance metric?</font></summary>
Check if the vectors are normalized. If not, you need to normalize the vectors first. Theoretically speaking, similarities worked out by L2 are different from similarities worked out by IP, if the vectors are not normalized.
</details>

## Vector Index ##
### Vector Index ###



Indexing, a process of organizing data, is a huge component of what makes it possible to efficiently query the million-, billion-, or even trillion-vector datasets that vector databases rely on. 

#### Accelerating vector similarity search

Similarity search engines work by comparing an input to the objects in a database to find those that are most similar to the input. Indexing is the process of efficiently organizing data, and it plays a major role in making similarity search useful by dramatically accelerating time-consuming queries on large datasets. After a massive vector dataset is indexed, queries can be routed to clusters, or subsets of data, that are most likely to contain vectors similar to an input query. In practice, this means a certain degree of accuracy is sacrificed to speed up queries on really large vector datasets.

To improve query performance, you can specify an [index type](index_selection.md) for each vector field. Currently, a vector field only supports one index type. Milvus automatically deletes the old index when switching the index type.

#### Create indexes

When the `create_index` method is called, Milvus synchronously indexes the existing data on this field. 

<div class="alert note">
By default, Milvus does not index a segment with less than 1,024 rows. To change this parameter, configure <a href="configuration_standalone-advanced.md#System-Behavior-Configurations"><code>minSegmentSizeToEnableIndex</code></a> in <code>root_coord.yaml</code>.
</div>


#### Index by segment

Milvus stores massive data in segments. When indexing, Milvus creates an index for each data segment separately.

#### Build indexes during free time

It is known that indexing is a resource-consuming and time-consuming task. When the query task and indexing task are concurrent, Milvus preferentially allocates computing resources to the query task, that is, any query command will interrupt the indexing task being executed in the background. After that, only when the user does not send the query task for 5 seconds, Milvus resumes the indexing task in the background. Besides, if the data segment specified by the query command has not been built into the specified index, Milvus will do an exhaustive search directly within the segment.

#### How to choose an index

To learn about the index types supported by Milvus and how to choose an appropriate index for your application scenarios, please read [How to Select an Index in Milvus](index_selection.md).

To learn how to choose an appropriate metric for an index, see [Similarity Metrics](metric.md).


### Select an Index ###


#### Selecting an Index Best Suited for Your Scenario

Most of the vector index types supported by Milvus use approximate nearest neighbors search (ANNS). Compared with accurate retrieval, which is usually very time-consuming, the core idea of ANNS is no longer limited to returning the most accurate result, but only searching for neighbors of the target. ANNS improves retrieval efficiency by sacrificing accuracy within an acceptable range.

According to the implementation methods, the ANNS vector index can be divided into four categories:

- Tree-based index
- Graph-based index
- Hash-based index
- Quantization-based index

The following table classifies the indexes that Milvus supports:

<table>
<thead>
  <tr>
    <th>Supported index</th>
    <th>Classification</th>
    <th>Scenario</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><a href="#FLAT">FLAT</a></td>
    <td>N/A</td>
    <td><ul>
        <li>Relatively small dataset</li>
        <li>Requires a 100% recall rate</li>
        </ul></td>
  </tr>
  <tr>
    <td><a href="#IVF_FLAT">IVF_FLAT</a></td>
    <td>Quantization-based index</td>
    <td><ul>
        <li>High-speed query</li>
        <li>Requires a recall rate as high as possible</li>
        </ul></td>
  </tr>
  <tr>
    <td><a href="#IVF_SQ8">IVF_SQ8</a></td>
    <td>Quantization-based index</td>
    <td><ul>
        <li>High-speed query</li>
        <li>Limited memory resources</li>
        <li>Accepts minor compromise in recall rate</li>
        </ul></td>
  </tr>  
  <tr>
    <td><a href="#IVF_PQ">IVF_PQ</a></td>
    <td>Quantization-based index</td>
    <td><ul>
        <li>Very high-speed query</li>
        <li>Limited memory resources</li>
        <li>Accepts substantial compromise in recall rate</li>
        </ul></td>
  </tr>
  <tr>
    <td><a href="#HNSW">HNSW</a></td>
    <td>Graph-based index</td>
    <td><ul>
        <li>High-speed query</li>
        <li>Requires a recall rate as high as possible</li>
        <li>Large memory resources</li>
        </ul></td>
  </tr>
  <tr>
    <td><a href="#ANNOY">ANNOY</a></td>
    <td>Tree-based index</td>
    <td><ul>
        <li>Low-dimensional vectors</li>
        </ul></td>
  </tr>
</tbody>
</table>



#### Supported vector indexes

#### FLAT

<a name="FLAT"></a>

For vector similarity search applications that require perfect accuracy and depend on relatively small (million-scale) datasets, the FLAT index is a good choice. FLAT does not compress vectors, and is the only index that can guarantee exact search results. Results from FLAT can also be used as a point of comparison for results produced by other indexes that have less than 100% recall.

FLAT is accurate because it takes an exhaustive approach to search, which means for each query the target input is compared to every vector in a dataset. This makes FLAT the slowest index on our list, and poorly suited for querying massive vector data. There are no parameters for the FLAT index in Milvus, and using it does not require data training or additional storage.

- Search parameters

  | Parameter     | Description                            | Range                               |
  | ------------- | -------------------------------------- | ----------------------------------- |
  | `metric_type` | [Optional] The chosen distance metric. | See [Supported Metrics](metric.md). |

#### IVF_FLAT

<a name="IVF_FLAT"></a>

IVF_FLAT divides vector data into `nlist` cluster units, and then compares distances between the target input vector and the center of each cluster. Depending on the number of clusters the system is set to query (`nprobe`), similarity search results are returned based on comparisons between the target input and the vectors in the most similar cluster(s) only — drastically reducing query time.

By adjusting `nprobe`, an ideal balance between accuracy and speed can be found for a given scenario. Results from the [IVF_FLAT performance test](https://zilliz.com/blog/Accelerating-Similarity-Search-on-Really-Big-Data-with-Vector-Indexing) demonstrate that query time increases sharply as both the number of target input vectors (`nq`), and the number of clusters to search (`nprobe`), increase.

IVF_FLAT is the most basic IVF index, and the encoded data stored in each unit is consistent with the original data.

 - Index building parameters

   | Parameter | Description             | Range      |
   | --------- | ----------------------- | ---------- |
   | `nlist`   | Number of cluster units | [1, 65536] |


- Search parameters

  | Parameter | Description              | Range                                           |
  | --------- | ------------------------ | ----------------------------------------------- |
  | `nprobe`  | Number of units to query | CPU: [1, nlist] <br> GPU: [1, min(2048, nlist)] |

#### IVF_SQ8

<a name="IVF_SQ8"></a>

IVF_FLAT does not perform any compression, so the index files it produces are roughly the same size as the original, raw non-indexed vector data. For example, if the original 1B SIFT dataset is 476 GB, its IVF_FLAT index files will be slightly larger (~470 GB). Loading all the index files into memory will consume 470 GB of storage.

When disk, CPU, or GPU memory resources are limited, IVF_SQ8 is a better option than IVF_FLAT. This index type can convert each FLOAT (4 bytes) to UINT8 (1 byte) by performing scalar quantization. This reduces disk, CPU, and GPU memory consumption by 70–75%. For the 1B SIFT dataset, the IVF_SQ8 index files require just 140 GB of storage.


 - Index building parameters

   | Parameter | Description             | Range      |
   | --------- | ----------------------- | ---------- |
   | `nlist`   | Number of cluster units | [1, 65536] |


- Search parameters

  | Parameter | Description              | Range                                           |
  | --------- | ------------------------ | ----------------------------------------------- |
  | `nprobe`  | Number of units to query | CPU: [1, nlist] <br> GPU: [1, min(2048, nlist)] |

#### IVF_PQ

<a name="IVF_PQ"></a>

`PQ` (Product Quantization) uniformly decomposes the original high-dimensional vector space into Cartesian products of `m` low-dimensional vector spaces, and then quantizes the decomposed low-dimensional vector spaces. Instead of calculating the distances between the target vector and the center of all the units, product quantization enables the calculation of distances between the target vector and the clustering center of each low-dimensional space and greatly reduces the time complexity and space complexity of the algorithm.

IVF\_PQ performs IVF index clustering before quantizing the product of vectors. Its index file is even smaller than IVF\_SQ8, but it also causes a loss of accuracy during searching vectors.

<div class="alert note">
Index building parameters and search parameters vary with Milvus distribution. Select your Milvus distribution first.
</div>

- Index building parameters

  | Parameter | Description                               | Range           |
  | --------- | ----------------------------------------- | --------------- |
  | `nlist`   | Number of cluster units                   | [1, 65536]      |
  | `m`       | Number of factors of product quantization | dim ≡ 0 (mod m) |
  | `nbits`   | [Optional] Number of bits in which each low-dimensional vector is stored. | [1, 16] (8 by default) |

- Search parameters

  | Parameter | Description              | Range      |
  | --------- | ------------------------ | ---------- |
  | `nprobe`  | Number of units to query | [1, nlist] |



#### HNSW

<a name="HNSW"></a>

HNSW (Hierarchical Navigable Small World Graph) is a graph-based indexing algorithm. It builds a multi-layer navigation structure for an image according to certain rules. In this structure, the upper layers are more sparse and the distances between nodes are farther; the lower layers are denser and the distances between nodes are closer. The search starts from the uppermost layer, finds the node closest to the target in this layer, and then enters the next layer to begin another search. After multiple iterations, it can quickly approach the target position.

In order to improve performance, HNSW limits the maximum degree of nodes on each layer of the graph to `M`. In addition, you can use `efConstruction` (when building index) or `ef` (when searching targets) to specify a search range.

- Index building parameters

  | Parameter        | Description                | Range    |
  | ---------------- | -------------------------- | -------- |
  | `M`              | Maximum degree of the node | [4, 64]  |
  | `efConstruction` | Search scope               | [8, 512] |


- Search parameters

  | Parameter | Description  | Range            |
  | --------- | ------------ | ---------------- |
  | `ef`      | Search scope | [`top_k`, 32768] |


#### ANNOY

<a name="ANNOY"></a>

ANNOY (Approximate Nearest Neighbors Oh Yeah) is an index that uses a hyperplane to divide a high-dimensional space into multiple subspaces, and then stores them in a tree structure.

When searching for vectors, ANNOY follows the tree structure to find subspaces closer to the target vector, and then compares all the vectors in these subspaces (The number of vectors being compared should not be less than `search_k`) to obtain the final result. Obviously, when the target vector is close to the edge of a certain subspace, sometimes it is necessary to greatly increase the number of searched subspaces to obtain a high recall rate. Therefore, ANNOY uses `n_trees` different methods to divide the whole space, and searches all the dividing methods simultaneously to reduce the probability that the target vector is always at the edge of the subspace.


- Index building parameters

  | Parameter | Description                              | Range     |
  | --------- | ---------------------------------------- | --------- |
  | `n_trees` | The number of methods of space division. | [1, 1024] |

- Search parameters

  | Parameter  | Description                                                  | Range                           |
  | ---------- | ------------------------------------------------------------ | ------------------------------- |
  | `search_k` | The number of nodes to search. -1 means 5% of the whole data. | {-1} ∪ [`top_k`, n × `n_trees`] |



#### FAQ


<details>
<summary><font color="#4fc4f9">What is the difference between FLAT index and IVF_FLAT index?</font></summary>
<p>IVF_FLAT index divides a vector space into <code>nlist</code> clusters. If you keep the default value of <code>nlist</code> as 16384, Milvus compares the distances between the target vector and the centers of all 16384 clusters to get <code>nprobe</code> nearest clusters. Then Milvus compares the distances between the target vector and the vectors in the selected clusters to get the nearest vectors. Unlike IVF_FLAT, FLAT directly compares the distances between the target vector and each and every vector.
</p>
<p>
Therefore, when the total number of vectors approximately equals <code>nlist</code>, IVF_FLAT and FLAT has little difference in the way of calculation required and search performance. But as the number of vectors grows to two times, three times, or n times of <code>nlist</code>, IVF_FLAT index begins to show increasingly greater advantages.
</p>
<p>
See <a href="https://medium.com/unstructured-data-service/how-to-choose-an-index-in-milvus-4f3d15259212">How to Choose an Index in Milvus</a> for more information.
</p>
</details>


#### Bibliography

- HNSW: <a href="https://arxiv.org/abs/1603.09320">Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</a>
- ANNOY: <a href="https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html">Nearest neighbors and vector models – part 2 – algorithms and data structures</a>


## Schema ##
### Field Schema ###



A field schema is the logical definition of a field. It is the first thing you need to define before defining a [collection schema](collection_schema.md) and [creating a collection](create.md). 

Milvus 2.0 supports a primary key field, a scalar field, and a vector field in a collection.

#### Field schema properties

<table class="properties">
	<thead>
	<tr>
		<th>Properties</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>name</td>
		<td>Name of the field in the collection to create</td>
		<td>Data type: String.<br/>Mandatory</td>
	</tr>
	<tr>
		<td>dtype</td>
		<td>Data type of the field</td>
		<td>Mandatory</td>
	</tr>
    <tr>
		<td>description</td>
		<td>Description of the field</td>
		<td>Data type: String.<br/>Optional</td>
	</tr>
    <tr>
		<td>is_primary</td>
		<td>Whether to set the field as the primary key field or not</td>
		<td>Data type: Boolean (<code>true</code> or <code>false</code>).<br/>Mandatory for the primary key field</td>
	</tr>
	<tr>
		<td>dim</td>
		<td>Dimension of the vector</td>
    <td>Data type: Integer &isin;[1, 32768].<br/>Mandatory for the vector field</td>
	</tr>
	</tbody>
</table>


#### Create a field schema

```python
from pymilvus import FieldSchema
id_field = FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, description="primary id")
age_field = FieldSchema(name="age", dtype=DataType.INT64, description="age")
embedding_field = FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128, description="vector")
```



#### Supported data type

`DataType` defines the kind of data a field contains. Different fields support different data types.

- Primary key field supports:
  - INT8: numpy.int8
  - INT16: numpy.int16
  - INT32: numpy.int32
  - INT64: numpy.int64
- Scalar field supports:
  - BOOL: Boolean (`true` or `false`)
  - INT8: numpy.int8
  - INT16: numpy.int16
  - INT32: numpy.int32
  - INT64: numpy.int64
  - FLOAT: numpy.float32
  - DOUBLE: numpy.double
- Vector field supports:
  - BINARY_VECTOR: Binary vector
  - FLOAT_VECTOR: Float vector


### Collection Schema ###



A collection schema is the logical definition of a collection. Usually you need to define the [field schema](field_schema.md) before defining a collection schema and [creating a collection](create.md). 


#### Collection schema properties

<table class="properties">
	<thead>
	<tr>
		<th>Properties</td>
		<th>Description</th>
		<th>Note</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>field</td>
		<td>Fields in the collection to create</td>
		<td>Mandatory</td>
	</tr>
    <tr>
		<td>description</td>
		<td>Description of the collection</td>
		<td>Data type: String.<br/>Optional</td>
	</tr>
    <tr>
		<td>auto_id</td>
		<td>Whether to enable Automatic ID allocation or not</td>
		<td>Data type: Boolean (<code>true</code> or <code>false</code>).<br/>Optional</td>
	</tr>
	</tbody>
</table>

#### Create a collection schema

<div class="alert note">
  Define the field schemas before defining a collection schema.
</div>

```python
from pymilvus import FieldSchema, CollectionSchema
id_field = FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, description="primary id")
age_field = FieldSchema(name="age", dtype=DataType.INT64, description="age")
embedding_field = FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128, description="vector")
schema = CollectionSchema(fields=[id_field, age_field, embedding_field], auto_id=False, description="desc of a collection")
```

Create a collection with the schema specified:

```python
from pymilvus import Collection
collection_name1 = "tutorial_1"
collection1 = Collection(name=collection_name1, schema=schema, using='default', shards_num=2)
```
<div class="alert note">
  You can define the shard number with <code>shards_num</code> and in which Milvus server you wish to create a collection by specifying the alias in <code>using</code>.
  </div>
  
<br/>
You can also create a collection with <code>Collection.construct_from_dataframe</code>, which automatically generates a collection schema from DataFrame and creates a collection.

```python
import pandas as pd
df = pd.DataFrame({
        "id": [i for i in range(nb)],
        "age": [random.randint(20, 40) for i in range(nb)],
        "embedding": [[random.random() for _ in range(dim)] for _ in range(nb)]
    })
collection, ins_res = Collection.construct_from_dataframe(
                                'my_collection',
                                df,
                                primary_field='id',
                                auto_id=False
                                )
```


## Boolean Expression Rules ##



#### Overview

A predicate expression outputs a boolean value. Milvus conducts scalar filtering by searching with predicates. A predicate expression, when evaluated, returns either TRUE or FALSE. View [Python SDK API Reference](/api-reference/pymilvus/v2.0.0rc8/api/collection.html) for instruction on using predicate expressions.

[EBNF](https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form) grammar rules describe boolean expressions rules:

```
Expr = LogicalExpr | NIL

LogicalExpr = LogicalExpr BinaryLogicalOp LogicalExpr 
              | UnaryLogicalOp LogicalExpr
              | "(" LogicalExpr ")"
              | SingleExpr;

BinaryLogicalOp = "&&" | "and" | "||" | "or";

UnaryLogicalOp = "not";

SingleExpr = TermExpr | CompareExpr;

TermExpr = IDENTIFIER "in" ConstantArray;

Constant = INTEGER | FLOAT

ConstantExpr = Constant
               | ConstantExpr BinaryArithOp ConstantExpr
               | UnaryArithOp ConstantExpr;
                                                          
ConstantArray = "[" ConstantExpr { "," ConstantExpr } "]";

UnaryArithOp = "+" | "-"

BinaryArithOp = "+" | "-" | "*" | "/" | "%" | "**";

CompareExpr = IDENTIFIER CmpOp IDENTIFIER
              | IDENTIFIER CmpOp ConstantExpr
              | ConstantExpr CmpOp IDENTIFIER
              | ConstantExpr CmpOpRestricted IDENTIFIER CmpOpRestricted ConstantExpr;

CmpOpRestricted = "<" | "<=";

CmpOp = ">" | ">=" | "<" | "<=" | "=="| "!=";
```

The following table lists the description of each symbol mentioned in the above Boolean expression rules.


| Notation      | Description |
| ----------- | ----------- |
| =      | Definition.       |
| ,      | Concatenation.       |
| ;      | Termination.        |
| \|      | Alternation.       |
| {...}   | Repetition.        |
| (...)      | Grouping.       |
| NIL   | Empty. The expression can be an empty string.        |
| INTEGER      | Integers such as 1, 2, 3.       |
| FLOAT   | Float numbers such as 1.0, 2.0.        |
| CONST      | Integers or float numbers.       |
| IDENTIFIER   | Identifier. In Milvus, the IDENTIFIER represents the field name.        |
| LogicalOp      | A LogicalOp is a logical operator that supports combining more than one relational operation in one comparison. Returned value of a LogicalOp is either TRUE (1) or FALSE (0). There are two types of LogicalOps, including BinaryLogicalOps and UnaryLogicalOps.    |
| UnaryLogicalOp   | UnaryLogicalOp refers to the unary logical operator "not".        |
| BinaryLogicalOp   |  Binary logical operators that perform actions on two operands. In a complex expression with two or more operands, the order of evaluation depends on precedence rules.       |
| ArithmeticOp   | An ArithmeticOp, namely an arithmetic operator, performs mathematical operations such as addition and subtraction on operands.         |
| UnaryArithOp      | A UnaryArithOp is an arithmetic operator that performs an operation on a single operand. The negative UnaryArithOp changes a positive expression into a negative one, or the other way round.      |
| BinaryArithOp   | A BinaryArithOp, namely a binary operator, performs operations on two operands. In a complex expression with two or more operands, the order of evaluation depends on precedence rules.        |
| CmpOp   | CmpOp is a relational operator that perform actions on two operands.        |
| CmpOpRestricted      |  CmpOpRestricted is restricted to "Less than" and "Equal".       |
| ConstantExpr   | ConstantExpr can be a Constant or a BinaryArithOp on two ConstExprs or a UnaryArithOp on a single ConstantExpr. It is defined recursively.        |
| ConstantArray      | ConstantArray is wrapped by square brackets, and ConstantExpr can be repeated in the square brackets. ConstArray must include at least one ConstantExpr.       |
| TermExpr   | TermExpr is used to check whether the value of an IDENTIFIER appears in a ConstantArray. TermExpr is represented by "in".        |
| CompareExpr      | A CompareExpr, namely comparison expression can be relational operations on two IDENTIFIERs, or relational operations on one IDENTIFIER and one ConstantExpr, or ternary operation on two ConstantExprs and one IDENTIFIER.       |
| SingleExpr   |  SingleExpr, namely single expression, can be either a TermExpr or a CompareExpr.      |
| LogicalExpr      | A LogicalExpr can be a BinaryLogicalOp on two LogicalExprs, or a UnaryLogicalOp on a single LogicalExpr, or a LogicalExpr grouped within parentheses, or a SingleExpr. The LogicalExpr is defined recursively.    |
| Expr   | Expr, an abbreviation meaning expression, can be LogicalExpr or NIL. |

#### Operators

#### Logical operators:

Logical operators perform a comparison between two expressions. 

| Symbol| Operation | Example | Description          |
| ----------| ------------- | ----------- | ------------------------- |
| 'and' &&  | and           | expr1 && expr2   | True if both expr1 and expr2 are true. |
| 'or' \|\|  | or           | expr1 \|\| expr2     | True if either expr1 or expr2 are true.  |




#### Binary arithmetic operators:

Binary arithmetic operators contain two operands and can perform basic arithmetic operations and return the corresponding result. 

| Symbol| Operation | Example | Description          |
| ----------| ------------- | ----------- | ------------------------- |
| +         | Addition      | a + b       | Add the two operands.     |
| -         | Subtraction   | a - b       | Subtract the second operand from the first operand.  |
| *         | Multiplication| a * b       | Multiply the two operands.     |
| /         | Division      | a / b       | Divide the first operand by the second operand.     |
| **        | Power         | a ** b      | Raise the first operand to the power of the second operand.     |
| %         | Modulo        | a % b       | Divide the first operand by the second operand and yield the remainder portion.    |


#### Relational operators:

Relational operators use symbols to check for equality, inequality, or relative order between two expressions. 

| Symbol| Operation | Example | Description         |
| ----------| ------------- | ----------- | ------------------------- |
| <         | Less than      | a < b      | True if a is less than b.     |
| >         | Greater than   | a > b       | True if a is greater than b.  |
| ==        | Equal          | a == b      | True if a is equal to b.    |
| !=        | Not equal       | a != b     | True if a is not equal to b.     |
| <=        | Less than or equal          | a <= b     | True if a is less than or equal to b.     |
| >=        | Greater than or equal         | a >= b      | True if a is greater than or equal to b.    |


#### Operator precedence and associativity

The following table lists the precedence and associativity of operators. Operators are listed top to bottom, in descending precedence.


| Precedence | Operator  | Description  | Associativity |
|------------|-----------|---------------|---------------|
| 1          | + -       | UnaryArithOp  | Left-to-right |
| 2          | not       | UnaryLogicOp  | Right-to-left |
| 3          | **        | BinaryArithOp | Left-to-right |
| 4          | * / %     | BinaryArithOp | Left-to-right |
| 5          | + -       | BinaryArithOp | Left-to-right |
| 6          | < <= > >= | CmpOp         | Left-to-right |
| 7          | == !=     | CmpOp         | Left-to-right |
| 8          | && and    | BinaryLogicOp | Left-to-right |
| 9          | \|\| or     | BinaryLogicOp | Left-to-right |


Expressions are normally evaluated from left to right. Complex expressions are evaluated one at a time. The order in which the expressions are evaluated is determined by the precedence of the operators used. 

If an expression contains two or more operators with the same precedence, the operator to the left is evaluated first. 

<div class="alert note">
For example, 10 / 2 * 5 will be evaluated as (10 / 2) and the result multiplied by 5. 
</div>

When a lower precedence operation should be processed first, it should be enclosed within parentheses. 

<div class="alert note">
For example, 30 / 2 + 8. This is normally evaluated as 30 divided by 2 then 8 added to the result. If you want to divide by 2 + 8, it should be written as 30 / (2 + 8). 
</div>


Parentheses can be nested within expressions. Innermost parenthetical expressions are evaluated first.

## Glossary ##



#### Collection
A collection in Milvus is equivalent to a table in a relational database management system (RDBMS). In Milvus, collections are used to store and manage entities.

#### Dependency
A dependency is a program that another program relies on to work. Milvus' dependencies include etcd (stores meta data), MinIO or S3 (object storage), and Pulsar (manages snapshot logs).

#### Entity
An entity consists of a group of fields that represent real world objects. Each entity in Milvus is represented by a unique row ID.

<div class="alert note">
You can customize row IDs. If you do not configure manually, Milvus automatically assigns row IDs to entities. If you choose to configure your own customized row IDs, note that Milvus does not support row ID de-duplication for now. Therefore, there can be duplicate row IDs in the same collection.
</div>

#### Field
Fields are the units that make up entities. Fields can be structured data (e.g., numbers, strings) or vectors.

<div class="alert note">
Scalar field filtering is now available in Milvus 2.0!
</div>

#### Log broker
The log broker is a publish-subscribe system that supports playback. It is responsible for streaming data persistence, execution of reliable asynchronous queries, event notification, and return of query results. It also ensures integrity of the incremental data when the worker nodes recover from system breakdown.

#### Log sequence
The log sequence records all operations that change collection states in Milvus.

#### Log subscriber
Log subscribers subscribe to the log sequence to update the local data and provides services in the form of read-only copies.

#### Milvus cluster
In a cluster deployment of Milvus, services are provided by a group of nodes to achieve high availability and easy scalability.

#### Milvus standalone
In a standalone deployment of Milvus, all operations including data insertion, index building, and vector similarity search are completed in one single process.

#### Normalization
Normalization refers to the process of converting an embedding (vector) so that its norm equals one. If inner product (IP) is used to calculate embeddings similarities, all embeddings must be normalized. After normalization, inner product equals cosine similarity.

#### Partition
A partition is a division of a collection. Milvus supports dividing collection data into multiple parts on physical storage. This process is called partitioning, and each partition can contain multiple segments.

#### PChannel
PChannel stands for physical channel. Each PChannel corresponds to a topic for log storage.  A group of 64 PChannels by default will be assigned to store logs that record data insertion, deletion, and update when the Milvus cluster is started.

#### Schema
Schema is the meta information that defines data type and data property. Each collection has its own collection schema that defines all the fields of a collection, automatic ID allocation enablement, and collection description. Also included in collection schemas are field schemas that defines the name, data type, and other properties of a field. 

#### Segment
A segment is a data file automatically created by Milvus for holding inserted data. A collection can have multiple segments and a segment can have multiple entities. During vector similarity search, Milvus scans each segment and returns the search results.

#### Sharding
Sharding refers to distributing write operations to different nodes to make the most of the parallel computing potential of a Milvus cluster for writing data. By default, a single collection contains two shards. Milvus adopts a sharding method based on primary key hashing. Milvus' development roadmap includes supporting more flexible sharding methods such as random and custom sharding.

<div class="alert note">
Partitioning works to reduce read load by specifying a partition name, while sharding spreads write load among multiple servers.
</div>

#### Unstructured data
Unstructured data, including images, video, audio, and natural language, is information that doesn't follow a predefined model or manner of organization. This data type accounts for ~80% of the world's data, and can be converted into vectors using various artificial intelligence (AI) and machine learning (ML) models.

#### VChannel
VChannel stands for logical channel. Each collection will be assigned a group of VChannels for recording data insertion, deletion, and update. VChannels are logically separated but physically share resources.


#### Vector
A vector represents the features of unstructured data. It is usually converted by an AI or ML model. A vector comes in the form of a numeric array of high dimensions. Each vector represents an object.

> Each entity can only contain one vector in the current version of Milvus.

#### Vector embedding
A vector embedding is a feature abstraction of unstructured data. Mathematically speaking, a vector embedding is an array of floating-point numbers or binaries. Modern embedding techniques are used to convert unstructured data to vector embeddings. 


#### Vector index
A vector index is a reorganized data structure derived from raw data that can greatly accelerate the process of vector similarity search. Milvus supports several [vector index types](index_selection.md).

#### Vector similarity search
Vector similarity search is the process of comparing a vector to a database to find vectors that are most similar to the target search vector. Approximate nearest neighbor (ANN) search algorithms are used to calculate [similarity](metric.md) between vectors. 


# Example Applications #
## Image Similarity Search ##



This tutorial demonstrates how to use Milvus, the open-source vector database, to build a reverse image search system.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/reverse_image_search/reverse_image_search.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/reverse_image_search/quick_deploy)
- [Try online demo](https://zilliz.com/milvus-demos/reverse-image-search)
The ML models and third-party software used include:
- YOLOv3
- ResNet-50
- MySQL

</br>

Major search engines like Google already give users the option to search by image. Additionally, e-commerce platforms have realized the benefits this functionality offers online shoppers, with Amazon incorporating image search into its smartphone applications.

</br>

In this tutorial, you will learn how to build a reverse image search system that can detect image patterns and return similar images to the one you upload. To build such an image similarity search system, download PASCAL VOC image set which contains 17125 images of 20 categories. Alternatively, you can prepare your own image datasets. Use YOLOv3 for object detection and ResNet-50 for image feature extraction. After going through the two ML models, images are converted into 256-dimensional vectors. Then store the vectors in Milvus and a unique ID for each vector is automatically generated by Milvus. MySQL is then used to map the vector IDs to the images in the dataset. Whenever you upload a new image to the image search system, it will be converted into a new vector and compared against the vectors previously stored in Milvus. Milvus then returns the IDs of the most similar vectors and you can query the corresponding images in MySQL.

</br>

![image_search](../../../assets/image_search.png)

![image_search_demo](../../../assets/image_search_demo.jpeg)

## Question Answering System ##



This tutorial demonstrates how to use Milvus, the open-source vector database, to build a question answering (QA) system.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/question_answering_system/question_answering.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/question_answering_system/quick_deploy) 
- [Try online demo](http://35.166.123.214:8005/)

The ML model and third-party software used include:
- BERT
- MySQL

</br>

Question answering system is a common real world application that belongs to the field of natural language processing. Typical QA systems include online customer service systems, QA chatbots, and more. Most question answering systems can be classified as: generative or retrieval, single-round or multi-round, open-domain or specific question answering systems.

</br>

In this tutorial, you will learn how to build a QA system that can link new user questions to massive answers previously stored in the vector database. To build such a chatbot, prepare your own dataset of questions and corresponding answers. Store the questions and answers in MySQL, a relational database. Then use BERT, the machine learning (ML) model for natural language processing (NLP) to convert questions into vectors. These question vectors are stored and indexed in Milvus.  When users input a new question, it is converted into a vector by the BERT model as well, and Milvus searches for the most similar question vector to this new vector. The QA system returns the corresponding answer to the most similar questions.

</br>

![QA_Chatbot](../../../assets/qa_chatbot.png)


![QA_chatbot_demo](../../../assets/qa_chatbot_demo.png)



## Recommender System ##



This tutorial demonstrates how to use Milvus, the open-source vector database, to build a recommendation system.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/recommender_system/recommender_system.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/recommender_system/quick_deploy)

The ML Model and third-party software used include:
- PaddlePaddle
- Redis or MySQL

</br>

The recommender system is a subset of the information filtering system, which can be used in various scenarios including personalized movie, music, product, and feed stream recommendation. Unlike search engines, recommender systems do not require users to accurately describe their needs but discover users' needs and interests by analyzing user behaviors.

</br>

In this tutorial, you will learn how to build a movie recommender system that can suggest movies meeting user interests. To build such a recommender system, first download a movie-related dataset. This tutorial uses MovieLens 1M. Alternatively, you can prepare your own datasets, which should include such information as users' ratings of movies, users' demographic characteristics, and movie description. Use PaddlePaddle to combine user IDs and features and convert them into 256-dimensional vectors. Convert movie IDs and features into vectors in a similar way. Store the movie vectors in Milvus and use user vectors for similarity search. If the user vector is similar to a movie vector, Milvus will return the movie vector and its ID as the recommendation result. Then query movie information using the movie vector ID stored in Redis or MySQL.

</br>

![recommender_system](../../../assets/recommendation_system.png)

## Video Similarity Search ##



This tutorial demonstrates how to use Milvus, the open-source vector database, to build a video similarity search system.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/video_similarity_search/video_similarity_search.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/video_similarity_search/quick_deploy)
The ML models and third-party software used include:
- OpenCV
- ResNet-50
- MySQL

<br/>

Nowadays, after watching a movie or video they like, people can easily take screenshots and share their thoughts by posting on various social networking platforms. When the followers see the screenshots, it can be really difficult for them to tell which movie it is if the movie name is not spelled out explicitly in the post. In order to figure out the name of the movie, people can take advantage of a video similarity search system. By using the system, users can upload an image and get videos or movies that contain key frames similar to the uploaded image.

<br/>

In this tutorial, you will learn how to build a video similarity search system. This tutorial uses approximately 100 animated gifs on Tumblr to build the system. However, you can also prepare your own video datasets. The system first uses OpenCV to extract key frames in videos and then obtains feature vectors of each key frame using ResNet-50. All vectors are stored and searched in Milvus, which will return the IDs of similar vectors. Then map the IDs to the corresponding video stored in MySQL.

<br/>

![video_search](../../../assets/video_search.png)
![video_search_demo](../../../assets/video_search_demo.gif)

## Audio Similarity Search ##



This tutorial demonstrates how to use Milvus, the open-source vector database to build an audio similarity search system.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/audio_similarity_search/audio_similarity_search.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/audio_similarity_search/quick_deploy)
The ML model and third-party software used include:
- PANNs (Large-Scale Pretrained Audio Neural Networks)
- MySQL

</br>

Speech, music, sound effects, and other types of audio search makes it possible to quickly query massive volumes of audio data and surface similar sounds. Applications of audio similarity search systems include identifying similar sound effects, minimizing IP infringement, and more. Audio retrieval can be used to search and monitor online media in real-time to crack down on infringement of intellectual property rights. It also assumes an important role in the classification and statistical analysis of audio data.

</br>

In this tutorial, you will learn how to build an audio similarity search system that can return similar sound clips. The uploaded audio clips are converted into vectors using PANNs. These vectors are stored in Milvus which automatically generates a unique ID for each vector. Then users can conduct a vector similarity search in Milvus and query the audio clip data path corresponding to th unique vector ID returned by Milvus.

<br/>

![Audio_search](../../../assets/audio_search.png)
![Audio_search_demo](../../../assets/audio_search_demo.png)

## Molecular Similarity Search ##



This tutorial demonstrates how to use Milvus, the open-source vector database, to build a molecular similarity search system.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/molecular_similarity_search/molecular_search.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/molecular_similarity_search/quick_deploy)
- [Try demo](http://35.166.123.214:8002/)
The third-party software used include:
- RDKit
- MySQL

<br/>

Drug discovery is an important part of new medicine research and development. The process of drug discovery includes target selection and confirmation. When fragments or lead compounds are discovered, researchers usually search for similar compounds in internal or commercial compound libraries in order to discover structure-activity relationship (SAR), compound availability. Ultimately, they will evaluate the potential of the lead compounds to be optimized to candidate compounds. In order to discover available compounds from billion-scale compound libraries, chemical fingerprint is usually retrieved for substructure search and molecule similarity search.

<br/>

In this tutorial, you will learn how to build a molecular similarity search system that can retrieve the substructure, superstructure, and similar structure of a particular molecule. RDKit is an open-source cheminformatics software that can convert molecule structures into vectors. Then, the vectors are stored in Milvus and Milvus can perform similarity search on vectors. Milvus also automatically generates a unique ID for each vector. The mapping of vector IDs and structure of molecules are stored in MySQL.

<br/>

![molecular](../../../assets/molecular.png)
![molecular](../../../assets/molecular_demo.jpeg)


## DNA Sequence Classification ##



This tutorial demonstrates how to use Milvus, the open-source vector database, to build a DNA sequence classification model.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/dna_sequence_classification/dna_sequence_classification.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/text_search_engine/quick_deploy)
The ML model and third-party software used include:
- CountVectorizer
- MySQL

<br/>

DNA sequence is a popular concept in gene traceability, species identification, disease diagnosis, and many more areas. Whereas all industries starve for a more intelligent and efficient research method, artificial intelligence has attracted much attention especially from biological and medical domains. More and more scientists and researchers are contributing to machine learning and deep learning in the field of bioinformatics. To make experimental results more convincing, one common option is to increase sample size. The collaboration with big data in genomics brings more possibilities of application in reality. However, the traditional sequence alignment has limitations, making it unsuitable for large datasets. In order to make less trade-off in reality, vectorization is a good choice for a large dataset of DNA sequences. 

<br/>

In this tutorial, you will learn how to build a DNA sequence classification model. This tutorial uses CountVectorizer to extract features of DNA sequences and convert them into vectors. Then, these vectors are stored in Milvus and their corresponding DNA classes are stored in MySQL. Users can conduct a vector similarity search in Milvus and recall the corresponding DNA classification from MySQL.

<br/>

![dna](../../../assets/dna.png)


## Text Search Engine ##



In this tutorial, you will learn how to use Milvus, the open-source vector database, to build a text search engine.
- [Open Jupyter notebook](https://github.com/milvus-io/bootcamp/blob/master/solutions/text_search_engine/text_search_engine.ipynb)
- [Quick deploy](https://github.com/milvus-io/bootcamp/blob/master/solutions/text_search_engine/quick_deploy)
The ML model and third-party software used include:
- BERT
- MySQL

<br/>

One major application of Milvus in the field of natural language processing (NLP) is text search engine. It is a great tool that can help users find the information they are looking for. It can even surface information that is hard to find. Text search engines compare the keywords or semantics users input against a database of texts, and then return the results that meet certain criteria. 

<br/>

In this tutorial, you will learn how to build a text search engine. This tutorial uses BERT to convert texts into fixed-length vectors. Milvus is used as a vector database for storage and vector similarity search. Then use MySQL to map the vector IDs generated by Milvus to the text data.

<br/>

![text_search_engine](../../../assets/text_search_engine.png)
![text_search_engine](../../../assets/text_search_engine_demo.png)

# FAQs #
## Performance FAQs ##


#### Performance FAQ

<!-- TOC -->


<!-- /TOC -->

##### How to set `nlist` and `nprobe` for IVF indexes?

Setting `nlist` is scenario-specific. As a rule of thumb, the recommended value of `nlist` is `4 × sqrt(n)`, where `n` is the total number of entities in a segment.

The size of each segment is determined by the `datacoord.segment.maxSize` parameter, which is set to 512 MB by default. The total number of entities in a segment n can be estimated by dividing `datacoord.segment.maxSize` by the size of each entity.

Setting `nprobe` is specific to the dataset and scenario, and involves a trade-off between accuracy and query performance. We recommend finding the ideal value through repeated experimentation.

The following charts are results from a test running on the sift50m dataset and IVF_SQ8 index, which compares recall and query performance of different `nlist`/`nprobe` pairs.

![Accuracy test](../../../../assets/accuracy_nlist_nprobe.png)
![Performance test](../../../../assets/performance_nlist_nprobe.png)

##### Why do queries sometimes take longer on smaller datasets?

Query operations are conducted on segments. indexes reduce the amount of time it takes to query a segment. If a segment has not been indexed, Milvus resorts to brute-force search on the raw data—drastically increasing query time.

Therefore, it usually takes longer to query on a small dataset (collection) because it has not built index. This is because the sizes of its segments have not reached the index-building threshold set by `rootCoord.minSegmentSizeToEnableindex`. Call `create_index()` to force Milvus to index segments that have reached the threshold but not yet been automatically indexed, significantly improving query performance.


##### What factors impact CPU usage?

CPU usage increases when Milvus is building indexes or running queries. In general, index building is CPU intensive except when using Annoy, which runs on a single thread.

When running queries, CPU usage is affected by `nq` and `nprobe`. When `nq` and `nprobe` are small, concurrency is low and CPU usage stays low.

##### Does simultaneously inserting data and searching impact query performance?

Insert operations are not CPU intensive. However, because new segments may not have reached the threshold for index building, Milvus resorts to brute-force search—significantly impacting query performance.

The `datacoord.segment.maxSize` parameter determines the index-building threshold for a segment, and is set to 512 MB by default.

##### Still have questions?

You can:

- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. Feel free to ask questions, share ideas, and help others.
- Join our [Slack Channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) to find support and engage with our open-source community.

## Product FAQs ##


#### Product FAQ

<!-- TOC -->



<!-- /TOC -->

##### How much does Milvus cost?

Milvus is a 100% free open-source project.

Please adhere to [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0) when using Milvus for production or distribution purposes.

Zilliz, the company behind Milvus, also offers a fully managed cloud version of the platform for those that don't want to build and maintain their own distributed instance. [Zilliz Cloud](https://zilliz.com/cloud) automatically maintains data reliability and allows users to pay only for what they use.

##### Does Milvus support non-x86 architectures?

Milvus cannot be installed or run on non-x86 platforms.

Your CPU must support one of the following instruction sets to run Milvus: SSE4.2, AVX, AVX2, AVX512. These are all x86-dedicated SIMD instruction sets.

##### What is the maximum dataset size Milvus can handle?

  
Theoretically, the maximum dataset size Milvus can handle is determined by the hardware it is run on, specifically system memory and storage:

- Milvus loads all specified collections and partitions into memory before running queries. Therefore, memory size determines the maximum amount of data Milvus can query.
- When new entities and and collection-related schema (currently only MinIO is supported for data persistence) are added to Milvus, system storage determines the maximum allowable size of inserted data.

#####  Where does Milvus store data?

Milvus deals with two types of data, inserted data and metadata. 

Inserted data, including vector data, scalar data, and collection-specific schema, is stored in persistent storage (for now MinIO only) as incremental log.

Metadata is generated within Milvus. Each Milvus module has its own metadata that is stored in etcd.

##### Why is there no vector data in etcd?

etcd stores Milvus module metadata; MinIO stores entities.

##### Does Milvus' Python SDK have a connection pool?

Python SDKs for Milvus v0.9.0 or higher have a connection pool. The number of connections in a connection pool has no upper limit.

##### Does Milvus support inserting and searching data simultaneously?

Yes. Insert operations and query operations are handled by two separate modules that are mutually independent. From the client’s perspective, an insert operation is complete when the inserted data enters the message queue. However, inserted data is unsearchable until it is loaded to the query node. If the segment size does not reach the index-building threshold (512 MB by default), Milvus resorts to brute-force search and query performance may be diminished.

##### Can vectors with duplicate IDs be inserted into Milvus?

Yes. Milvus does not check if vector IDs are duplicates.

##### When vectors with duplicate IDs are inserted, does Milvus treat it as an update operation?

No. Milvus does not currently support update operations and does not check if entity IDs are duplicates. You are responsible for ensuring entity IDs are unique, and if they aren't Milvus may contain multiple entities with duplicate IDs.

If this occurs, duplicate IDs may be returned from a search, causing confusion.

##### What is the maximum length of self-defined entity IDs?

Entity IDs must be non-negative 64-bit integers.

##### What is the maximum amount of data that can be added per insert operation?

An insert operation must not exceed 1,024 MB in size. This is a limit imposed by gRPC.

##### Does collection size impact query performance when searching in a specific partition?

No. If partitions for a search are specified, Milvus searches the specified partitions only.

##### Does Milvus load the entire collection when partitions are specified for a search?

No. Milvus v2.0 has varied behavior. Data must be loaded to memory before searching.

- If you know which partitions your data is located in, call `load_partition()` to load the intended partition(s) *then* specify partition(s) in the `search()` method call.
- If you do not know the exact partitions, call `load_collection()` before calling `search()`.
- If you fail to load collections or partitions before searching, Milvus returns an error.


##### Can indexes be created after inserting vectors?

Yes. If `create_index()` is called, Milvus builds an index for subsequently inserted vectors. However, Milvus does not build an index until the newly inserted vectors fill an entire segment and the newly created index file is separate from the previous one.



##### How are the FLAT and IVF_FLAT indexes different?

The IVF_FLAT index divides vector space into list clusters. At the default list value of 16,384, Milvus compares the distances between the target vector and the centroids of all 16,384 clusters to return probe nearest clusters. Milvus then compares the distances between the target vector and the vectors in the selected clusters to get the nearest vectors. Unlike IVF_FLAT, FLAT directly compares the distances between the target vector and every other vector.

When the total number of vectors approximately equals nlist, there is little distance between IVF_FLAT and FLAT in terms of calculation requirements and search performance. However, as the number of vectors exceeds nlist by a factor of two or more, IVF_FLAT begins to demonstrate performance advantages.

See [How to Choose an Index in Milvus](https://zilliz.com/blog/Accelerating-Similarity-Search-on-Really-Big-Data-with-Vector-Indexing) for more information.

##### How does Milvus flush data?

Milvus returns success when inserted data is loaded to the message queue. However, the data is not yet flushed to the disk. Then Milvus' data node writes the data in the message queue to persistent storage as incremental logs. If `flush()` is called, the data node is forced to write all data in the message queue to persistent storage immediately.

##### What is normalization? Why is normalization needed?

Normalization refers to the process of converting a vector so that its norm equals 1. If inner product is used to calculate vector similarity, vectors must be normalized. After normalization, inner product equals cosine similarity.

See [Wikipedia](https://en.wikipedia.org/wiki/Unit_vector) for more information.

##### Why do Euclidean distance (L2) and inner product (IP) return different results?

For normalized vectors, Euclidean distance (L2) is mathematically equivalent to inner product (IP). If these similarity metrics return different results, check to see if your vectors are normalized

##### Is there a limit to the total number of collections and partitions in Milvus?
There is no limit on the number of collections. However, the number of partitions in each collection must not exceed the value set by the parameter `master.maxPartitionNum`.

##### Why do I get fewer than k vectors when searching for `topk` vectors?

Among the indexes that Milvus supports, IVF_FLAT and IVF_SQ8 implement the k-means clustering method. A data space is divided into `nlist` clusters and the inserted vectors are distributed to these clusters. Milvus then selects the `nprobe` nearest clusters and compares the distances between the target vector and all vectors in the selected clusters to return the final results.

If `nlist` and `topk` are large and nprobe is small, the number of vectors in the nprobe clusters may be less than `k`. Therefore, when you search for the `topk` nearest vectors, the number of returned vectors is less than `k`.

To avoid this, try setting `nprobe` larger and `nlist` and `k` smaller.

See [Index Overview](index.md) for more information.

##### What is the maximum vector dimension supported in Milvus?

Milvus can manage vectors with up to 32,768 dimensions.

##### Does Milvus support Apple M1 CPU?

Current Milvus release does not support Apple M1 CPU.

##### What data types does Milvus support on the ID field?

In current release, Milvus only support INT64 on ID field. Both INT64 and string will be supported in the formal release of Milvus 2.0.0.

##### Is Milvus scalable?

Yes. You can deploy Milvus cluster with multiple nodes via Helm Chart on Kubernetes. Refer to [Scale Guide](https://zilliverse.feishu.cn/docs/scaleout.md) for more instruction.

##### Does the query perform in memory? What are incremental data and historical data?

Yes. When a query request comes, Milvus searches both incremental data and historical data by loading them into memory. Incremental data are data in the growing segments, which are buffered in memory before they reach the threshold to be persisted in storage engine, while historical data are from the sealed segments that are stored in the object storage. Incremental data and historical data together constitute the whole dataset to search.

##### Is Milvus 2.0 available for concurrent search?

Yes. For queries on the same collection, Milvus concurrently searches the incremental and historical data. However, queries on different collections are conducted in series. Whereas the historical data can be an extremely huge dataset, searches on the historical data are relatively more time-consuming and essentially performed in series. The formal release of Milvus 2.0 will improve this issue.

##### Why does the data in MinIO remain after the corresponding collection is dropped?

Data in MinIO is designed to remain for a certain period of time for the convenience of data rollback.

##### Does Milvus support message engines other than Pulsar?

Future release of Milvus 2.0 will support Kafka.

##### Still have questions?

You can:

- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. You're welcome to raise questions, share ideas, and help others.
- Join our [Slack community](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) to find support and engage with our open-source community.


## Operational FAQs ##


#### Operational FAQ

<!-- TOC -->


<!-- /TOC -->

##### What if I failed to pull the Milvus Docker image from Docker Hub?

If you failed to pull the Milvus Docker image from Docker Hub, try adding other registry mirrors. 

Users from Mainland China can add the URL "https://registry.docker-cn.com" to the registry-mirrors array in **/etc.docker/daemon.json**.

```
{
  "registry-mirrors": ["https://registry.docker-cn.com"]
}
```

##### Is Docker the only way to install and run Milvus?

Docker is an efficient way to deploy Milvus, but not the only way. You can also deploy Milvus from source code. This requires Ubuntu (18.04 or higher) or CentOS (7 or higher). See [Building Milvus from Source Code](https://github.com/milvus-io/milvus/blob/master/INSTALL.md) for more information.

##### What are the main factors affecting recall?

Recall is affected mainly by index type and search parameters.

For FLAT index, Milvus takes an exhaustive scan within a collection, with a 100% return.

For IVF indexes, the nprobe parameter determines the scope of a search within the collection. Increasing nprobe increases the proportion of vectors searched and recall, but diminishes query performance.

For HNSW index, the ef parameter determines the breadth of the graph search. Increasing ef increases the number of points searched on the graph and recall, but diminishes query performance.

For more information, see [Vector Indexing](https://www.zilliz.com/blog/Accelerating-Similarity-Search-on-Really-Big-Data-with-Vector-Indexing).

##### Why did my changes to the configuration files not take effect?

Milvus v2.0 does not support modification to configuration files during runtime. You must restart Milvus Docker for configuration file changes to take effect.

##### How do I know if Milvus has started successfully?

If Milvus is started using Docker Compose, run `docker ps` to observe how many Docker containers are running and check if Milvus services started correctly.

- For Milvus standalone, you should be able to observe at least three running Docker containers, one being the Milvus service and the other two being etcd management and storage service. For more information, see [Installing Milvus Standalone](install_standalone-docker.md).
- For Milvus Cluster, you should be able to observe at least twelve running Docker containers, nine for the Milvus service and three for basic services. For more information, see [Installing Milvus Cluster](install_cluster-docker.md).

##### Why is the time in the log files different from the system time?

The time difference is usually due to the fact that the host machine does not use Coordinated Universal Time (UTC).

The log files inside the Docker image use UTC by default. If your host machine does not use UTC, this issue may occur.


##### How do I know if my CPU supports Milvus?

Milvus' computing operations depend on CPU’s support for SIMD (Single Instruction, Multiple Data) extension instruction set. Whether your CPU supports SIMD extension instruction set is crucial to index building and vector similarity search within Milvus. Ensure that your CPU supports at least one of the following SIMD instruction sets:

- SSE4.2
- AVX
- AVX2
- AVX512

Run the lscpu command to check if your CPU supports the SIMD instruction sets mentioned above:

```
$ lscpu | grep -e sse4_2 -e avx -e avx2 -e avx512
```

##### Why does Milvus return `illegal instruction` during startup?

Milvus requires your CPU to support a SIMD instruction set: SSE4.2, AVX, AVX2, or AVX512. CPU must support at least one of these to ensure that Milvus operates normally. An `illegal instruction` error returned during startup suggests that your CPU does not support any of the above four instruction sets.

See [CPU’s support for SIMD Instruction Set](install_standalone-docker.md#before-you-begin).

##### Can I install Milvus on Windows?

If you try to deploy Milvus with Docker, Milvus only supports the deployment on [Windows Docker Desktop WSL 2 backend](https://docs.docker.com/docker-for-windows/wsl/).

Milvus cannot be built from source code on Windows or macOS. Use Ubuntu (18.04 or higher) or CentOS (7 or higher) to build Milvus from source code.

##### I got an error when installing pymilvus on Windows. What shall I do?

It is not recommended to install pymilvus on Windows. Try installing it in a Conda environment.

##### Can I deploy Milvus when disconnected from the Internet?

Milvus is available as a Docker image and allows offline deployment. Taking Milvus standalone as an example:

1. Pull the Docker images of MinIO, etcd, and Milvus when you have Internet access.
2. Run `docker save` to save the images as TAR files.
3. Save the **.TAR** files locally.
4. Run `docker load` to load the file as a Docker image.
5. Run `docker-compose` to start Milvus.
For more information about Docker, see [Installing Milvus Standalone](install_standalone-docker.md).

##### Where can I find the logs generated by Milvus?

The Milvus log is printed to stout (standard output) and stderr (standard error) by default, however we highly recommend redirecting your log to a persistent volume in production. To do so, update `log.file.rootPath` in **milvus.yaml**. 


##### Can I create index for a segment before inserting data into it?

Yes, you can. But we recommend inserting data in batches, each of which should not exceed 256 MB, before indexing each segment.

##### Still have questions?

You can:

- Check out [Milvus](https://github.com/milvus-io/milvus/issues) on GitHub. Feel free to ask questions, share ideas, and help others.
- Join our [Slack Channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) to find support and engage with our open-source community.

## Troubleshooting ##

This page lists common issues that may occur when running Milvus, as well as possible troubleshooting tips. Issues on this page fall into the following categories:

- [Boot issues](#boot_issues)
- [Runtime issues](#runtime_issues)
- [API issues](#api_issues)

<a href="#boot_issues"></a>
  #### Boot issues

  Boot errors are usually fatal. Run the following command to view error details:

  ```
  $ docker logs <your milvus container id>
  ```

<a href="#runtime_issues"></a>
  #### Runtime issues

  Errors that occur during runtime may cause service breakdown. To troubleshoot this issue, check compatibility between the server and your client before moving forward.

<a href="#api_issues"></a>
  #### API issues

  These issues occur during API method calls between the Milvus server and your client. They will be returned to the client synchronously or asynchronously.

<br/>

  If you need help solving a problem, feel free to:

  - Join our [Slack channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk) and reach out for support from the Milvus team.
  - [File an Issue](https://github.com/milvus-io/milvus/issues/new/choose) on GitHub that includes details about your problem.

